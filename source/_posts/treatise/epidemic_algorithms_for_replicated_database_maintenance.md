---
title: "Epidemic Algorithms For Replicated Database Maintenance 中文翻译版"
date: 2025-02-26 22:26:13
tags:
- "论文"
- "Gossip"
id: epidemic_algorithms_for_replicated_database_maintenance
no_word_count: true
no_toc: false
categories: 大数据
math: true
---

## Epidemic Algorithms For Replicated Database Maintenance 中文翻译版

作者：Alan Demers, Mark Gealy, Dan Greene, Carl Hauser, Wes Irish, John Larson, Sue Manning, Scott Shenker, Howard Sturgis, Dan Swinehart, Doug Terry, and Don Woods

[英文原文](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf)

### 摘要

当在多个站点上复制数据库时，保持相互一致性的更新是一个重大问题。本文描述了一些随机的算法来实现分布式的更新和驱动副本的一致性。算法非常简单，只需要底层通讯上一点小小的保证，但它们可以确保每次更新的效果最终都能体现在所有副本中。此算法的耗费和性能可以通过调节随机化步骤的合适的分布来实现。算法与流行病非常相似，阅读流行病学的文献有助于理解它们的行为。其中一种算法已在 Xerox Corporate Internet的 Clearinghouse 服务器中实现，解决了长期存在的高流量和数据库不一致问题。

### 0. 引言

考虑到在一个由数百或数千个站点组成的大型、异构、稍不可靠且变化缓慢的网络中的许多站点复制的数据库，我们研究了实现和维护站点之间一致性的几种方法。
每个数据库更新操作都从某一个站点注入，必须传播到所有其他站点，或者被以后的更新所取代。
只有当所有更新活动都停止并且系统处于静止状态时，这些站点才能变得完全一致。
在另一方面，假设有一个合理的更新频率，在给定某个站点时它上面的数据大多都是当前状态。
这种较为宽松的一致性形式已被证明在实践中非常有用 `[Bi]`。我们的目标是设计一种高效且强大的算法，并随着站点数量的增加而优雅地扩展。

在研究解决此问题的算法时要考虑的重要因素包括：

- 更新传播到所有站点所花费的时间
- 更新所花费的网络流量。理想情况下，网络流量与更新大小和服务器数量成正比，但是某些算法会产生更多流量。

在本文中，我们使用几种扩展更新的策略介绍了分析，仿真结果和实践经验。检查的方法包括：

1. 直接发送(Direct mail)：每个更新都立即从进入站点发送到其他所有站点。这是非常节省时间和理论上效果最好的，但并不完全可靠，因为各个站点并不总是了解所有其他站点，并且有时会丢失报文。

2. 反熵(Anti-entropy)：每个站点通常选择一个随机的其他站点，然后交换数据库中的差异数据。由于反熵及其可靠但是需要检查数据库中的数据内容，所以这种做法不能频繁执行。分析和模拟表明，反熵虽然可靠，但是传播更新的速度要比直接发送慢得多。

3. 谣言传播算法(Rumor mongering)：站点的初始状态是空白的；当站点接收到一个新的更新时会变成 "热点谣言"；当站点持有一个热点谣言，它会周期性的选择一个另外的站点并让另一个站点观测到此次更新；当某个站点试图与太多已经看到它的站点共享热门谣言时，该站点将停止将该谣言视为热点，并保留更新，而不会进一步传播。谣言周期可能比反熵周期更频繁，因为它们在每个站点所需要的资源更少，但是有可能更新不会到达所有站点。

反熵和谣言传播都是流行过程的例子，流行理论[Ba]的结果也适用。尽管我们的目标有所不同，但我们对这些机制的理解极大地受益于现有的流行病学数学理论(我们将对更新的迅速而全面的传播感到满意)。
此外，我们可以自由设计流行病机制，而不必设计现有疾病的模型。
我们采用流行病学文献的术语，并称其为一个愿意与之分享感染性的更新。
如果站点尚未收到更新，则该站点很容易受到攻击；如果某个站点已经收到更新但不再愿意共享该更新，则将其删除。
反熵是一种简单的流行病示例：一个站点总是易受感染的站点。

统一选择合作伙伴会导致相当高的网络流量，这促使我们考虑空间分布，在这种分布中，选择往往有利于附近的服务器。
对 Xerox Corporate Internet 实际拓扑结构的分析和模拟揭示了反熵和谣言传播的分布，这些分布的收敛速度几乎与均匀分布一样快，同时降低了每条链路的平均和最大流量。
产生的反熵算法已安装在 Xerox Corporate Internet 上，并显着提高了性能。

我们应该指出，数据库的大量复制非常昂贵。
应尽可能通过数据库的层次分解或缓存来避免这种情况。
即便如此，我们的论文结果还是很有趣的，因为它们表明可以使用简单的算法在层次结构的每个级别或在缓存方案的主干中实现显着的复制。

> 注：此处的数据库层次分解和数据分层的概念是不同的。前者侧重于数据库内部的组织和优化，后者侧重于软件架构中的数据管理和交互方式。数据库层次分解是将同类数据按照不同需求进行分解，数据分层是将同种数据分配到特定的功能和用途。

### 0.1 动机

本项工作源自我们对于 Xerox Corporate Internet(CIN) 的 Clearinghouse servers `[Op]` 。
全球 CIN 包含数百个通过网关(在CIN上称为互联路由器)和许多不同容量的电话线连接的以太网。
数千台工作站，服务器和计算主机已连接到 CIN。
从日本的一台机器到欧洲的一台机器的数据包可能会经过多达 14 个网关和 7 条电话线。

Clearinghouse servers 维护了三种层级的转化关系，层级名称到机器地址，用户身份等。
层次结构的前两层将命名空间划分为一组域。
每个域可以存储（复制）到最少或全部的 Clearinghouse servers 中，其中有数百个。

几个域实际上是存储在 CIN 中的 Clearinghouse servers 里。
在 1986 年初，网络上许多可观察到的性能问题都可以追溯到，因为维持域的高度复制域的一致性从而产生的流量问题。
随着网络规模的增加，即使只有几台服务器存储的域在更新时的传播也非常缓慢。

当我们初次接近此问题的时候，Clearinghouse servers 正在同时使用直接发送和反熵方法。
反熵在每个域中执行，在理论上来说本地时间每一天的午夜到早上 6 点(每台服务器)。
事实上，由于网络负载过重服务器通常不能按时完整的完成反熵逻辑。

我们的第一个发现是，在发生分歧后，反熵步骤之后会跟着一个重新邮寄的步骤：当两个反熵参与者之前存在不同意见时，正确的数据库值会被发送到所有站点。
更多的站点间不一致会导致更多的通信量。
对于存储在300个站点上的一个域，每晚可能会产生多达90,000封邮件消息。
这远远超出了网络的承载能力，导致所有网络服务（如邮件、文件传输、名称查找等）出现故障。

由于在大规模网络中重新邮寄步骤明显不可行，我们的第一个观察结果是必须禁用这一功能。
进一步的分析表明，仅禁用重新邮寄步骤还不够：网络中的某些关键链接仍会因为反熵通信量而过载。
我们对空间分布和流言传播的探索源于试图进一步减少由 Clearinghouse 更新过程给网络带来的负载。

### 0.2 相关工作

本文的主要目的是维护一个广泛复制的目录，或是根据名称查找的数据库。
相较于使用基于事务的机制来实现单次拷贝序列化(例如: `[Gi]` )，而是使用副本驱动实现最终一致性的方法。
这种机制显然是由 Johnson 等人 `[Jo]` 首次提出的，并已在 Grapevine `[Bi]` 和 Clearinghouse `[Op]` 中使用。
这些系统在使用上仍然存在一些问题；特别是一些更新(概率较低)不会到达所有站点。
Lampson `[La]` 提出了一种分层数据结构，避免了高复制，但仍然需要对每个组件进行一些复制，比如六到十几台服务器。
已经提出了用于复制数据库的主站点更新算法，通过要求将更新应用于单个站点来同步更新；然后，更新站点负责将更新传播到所有副本。
例如，DARPA领域系统采用了这种算法 `[Mo]` 。
主站点更新避免了本文所述算法所解决的更新分布问题，但受到集中控制的影响。

我们的算法与之前的机制有两个区别。
首先，之前的机制依赖于底层通信协议的各种保证，以及维护一致的分布式控制结构。
例如，在 Clearinghouse 中，更新的初始分发取决于底层的保证邮件协议，即使邮件队列在磁盘存储上维护，该协议在实践中也会因物理队列溢出而不时失败。
Sarin 和 Lynch `[Sa]` 提出了一种分布式算法，用于丢弃过时的数据，该算法依赖于有保证的、有序的消息传递，以及每个服务器(大小为 $O(n^2)$ )的详细数据结构，描述了其他服务器也持有的同一数据库。
Lampson 等人 `[La]` 设想了一种确定性地围绕一圈服务器移动的扫描，这些服务器由从一个服务器到另一个服务器的指针连接在一起。
本文中的算法仅依赖于重复消息的最终传递，而不需要一个服务器上的数据结构来描述其他服务器持有的信息。

其次，本文描述的算法是随机化的；也就是说，在算法中，每个服务器都会做出独立的随机选择 `[Ra，Be85]` 。
不同的是，前面的机制是确定性的。
例如，在反熵和谣言传播算法中，服务器随机选择一个合作伙伴。
在某些版本的谣言传播算法中，服务器会随机选择保持感染性或被删除。
随机选择的使用阻止了我们做出这样的声明：“信息将在与网络直径成比例的时间内收敛。”
我们能说的最好的情况是，在没有进一步更新的情况下，信息未收敛的概率随时间呈指数级下降。
另一方面，我们认为，使用随机协议使算法能够使用简单的数据结构简单直接的实现正确性。

### 0.3 本文的计划

第 1 节正式描述了复制数据库的概念，并介绍了实现一致性的基本技术。
第 2 节介绍了一种从数据库中删除项目的技术。
删除操作比其他更改更为复杂，因为删除的项目必须由代理代表，直到删除的消息传播到所有站点为止。
第三部分介绍了在选择反熵和谣言传播者时非均匀空间分布的模拟和分析结果。

### 1. 基本技巧

本节介绍了复制数据库的概念，并介绍了基本的直接发送，反熵和复杂的流行病协议以及它们的分析。

#### 1.1 符号

考虑一个由一组 n 个站点组成的网络，每个站点存储一个数据库的副本。
数据库拷贝在站点 s $\in$ S 是一个微小变化的偏函数。

$$s.\text{ValueOf}: K \rightarrow (v : V \times t : T)$$

> 注：s 是个服务器，K 是个存储 key 里面是对应时间的值

K 是名称的集合，V 是值的集合，T 是时间戳的集合。
V 保存了可分辨元素 NIL，但在其他方面则没有指定内容。
T 完全由 < 排序。
解释下 `s.ValueOf[k]=(NIL,t)` 这段代码的意思是 k 作为键的数据在数据库中被删除。
即从数据库客户端的角度来看 `s.ValueOf[k]=(NIL,t)` 与 `s.ValueOf[k] is undefined` 是相同的。

对于分发规则的阐述会在 1.2 和 1.3 章节以一个数据库值存储了一个值，一个时间和一个键的情况进行介绍。这是在不丧失通用性的情况下完成的，因为算法分别处理每个名称。所以我们会说

$$s.\text{ValueOf} \in (v : V \times t : T)$$

> 注：值都存储在服务器中不会丢失

也就是说，`s.ValueOf` 就是一组排序过的由值和时间戳组成的键值对。
如前所述，第一个组件可能是 NIL，这意味着该项目在第二个组件指示的时间已被删除。

更新分发过程的目标是推动系统朝着

$$\forall s, s' \in S : s.\text{ValueOf} = s'.\text{ValueOf}$$

> 注：对于每个 s 来说数据是一样的。

客户端可以调用一个操作来更新任何给定站点的数据库：

$\text{Update}[v : V] \equiv s.\text{ValueOf} \leftarrow (v, \text{Now}[])$

> 注：插入数据写入默认时间。

其中 Now 是一个返回全局唯一时间戳的函数。
希望 `Now[]` 返回的时间戳将大约是当前的格林尼治标准时间，如果不是的话算法在形式上有效，但在实践中无效。
感兴趣的读者可以参考 Clearinghouse `[Op]` 和Grapevine `[Bi]` 论文，以进一步了解时间戳在构建可用数据库中的作用。
对于此处我们的目的来说，只需知道时间戳较大的一对总是会取代时间戳较小的一对就足够了。

#### 1.2 直接发送

直接发送策略会在变更完成后第一时间尝试通知其他所有的站点。在发生更新的站点上执行的基本算法是：

$$
\begin{aligned}
&\text{FOR EACH } s' \in S \text{ DO} \\
&\quad \text{PostMail}[\text{to}:s', \text{msg}: (\text{"Update"}, s.\text{ValueOf})] \\
&\text{ENDLOOP}
\end{aligned}
$$
