---
title: "Epidemic Algorithms For Replicated Database Maintenance 中文翻译版"
date: 2025-02-26 22:26:13
tags:
- "论文"
- "Gossip"
id: epidemic_algorithms_for_replicated_database_maintenance
no_word_count: true
no_toc: false
categories: 大数据
math: true
---

## Epidemic Algorithms For Replicated Database Maintenance 中文翻译版

作者：Alan Demers, Mark Gealy, Dan Greene, Carl Hauser, Wes Irish, John Larson, Sue Manning, Scott Shenker, Howard Sturgis, Dan Swinehart, Doug Terry, and Don Woods

[英文原文](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf)

### 摘要

当在多个站点上复制数据库时，保持相互一致性的更新是一个重大问题。本文描述了一些随机的算法来实现分布式的更新和驱动副本的一致性。算法非常简单，只需要底层通讯上一点小小的保证，但它们可以确保每次更新的效果最终都能体现在所有副本中。此算法的耗费和性能可以通过调节随机化步骤的合适的分布来实现。算法与流行病非常相似，阅读流行病学的文献有助于理解它们的行为。其中一种算法已在 Xerox Corporate Internet的 Clearinghouse 服务器中实现，解决了长期存在的高流量和数据库不一致问题。

### 0. 引言

考虑到在一个由数百或数千个站点组成的大型、异构、稍不可靠且变化缓慢的网络中的许多站点复制的数据库，我们研究了实现和维护站点之间一致性的几种方法。
每个数据库更新操作都从某一个站点注入，必须传播到所有其他站点，或者被以后的更新所取代。
只有当所有更新活动都停止并且系统处于静止状态时，这些站点才能变得完全一致。
在另一方面，假设有一个合理的更新频率，在给定某个站点时它上面的数据大多都是当前状态。
这种较为宽松的一致性形式已被证明在实践中非常有用 `[Bi]`。我们的目标是设计一种高效且强大的算法，并随着站点数量的增加而优雅地扩展。

在研究解决此问题的算法时要考虑的重要因素包括：

- 更新传播到所有站点所花费的时间
- 更新所花费的网络流量。理想情况下，网络流量与更新大小和服务器数量成正比，但是某些算法会产生更多流量。

在本文中，我们使用几种扩展更新的策略介绍了分析，仿真结果和实践经验。检查的方法包括：

1. 直接发送(Direct mail)：每个更新都立即从进入站点发送到其他所有站点。这是非常节省时间和理论上效果最好的，但并不完全可靠，因为各个站点并不总是了解所有其他站点，并且有时会丢失报文。

2. 反熵(Anti-entropy)：每个站点通常选择一个随机的其他站点，然后交换数据库中的差异数据。由于反熵及其可靠但是需要检查数据库中的数据内容，所以这种做法不能频繁执行。分析和模拟表明，反熵虽然可靠，但是传播更新的速度要比直接发送慢得多。

3. 谣言传播算法(Rumor mongering)：站点的初始状态是空白的；当站点接收到一个新的更新时会变成 "热点谣言"；当站点持有一个热点谣言，它会周期性的选择一个另外的站点并让另一个站点观测到此次更新；当某个站点试图与太多已经看到它的站点共享热门谣言时，该站点将停止将该谣言视为热点，并保留更新，而不会进一步传播。谣言周期可能比反熵周期更频繁，因为它们在每个站点所需要的资源更少，但是有可能更新不会到达所有站点。

反熵和谣言传播都是流行过程的例子，流行理论 `[Ba]` 的结果也适用。尽管我们的目标有所不同，但我们对这些机制的理解极大地受益于现有的流行病学数学理论(我们将对更新的迅速而全面的传播感到满意)。
此外，我们可以自由设计流行病机制，而不必设计现有疾病的模型。
我们采用流行病学文献的术语，并称其为一个愿意与之分享感染性的更新。
如果站点尚未收到更新，则该站点很容易受到攻击；如果某个站点已经收到更新但不再愿意共享该更新，则将其删除。
反熵是一种简单的流行病示例：一个站点总是易受感染的站点。

统一选择合作伙伴会导致相当高的网络流量，这促使我们考虑空间分布，在这种分布中，选择往往有利于附近的服务器。
对 Xerox Corporate Internet 实际拓扑结构的分析和模拟揭示了反熵和谣言传播的分布，这些分布的收敛速度几乎与均匀分布一样快，同时降低了每条链路的平均和最大流量。
产生的反熵算法已安装在 Xerox Corporate Internet 上，并显着提高了性能。

我们应该指出，数据库的大量复制非常昂贵。
应尽可能通过数据库的层次分解或缓存来避免这种情况。
即便如此，我们的论文结果还是很有趣的，因为它们表明可以使用简单的算法在层次结构的每个级别或在缓存方案的主干中实现显着的复制。

> 注：此处的数据库层次分解和数据分层的概念是不同的。前者侧重于数据库内部的组织和优化，后者侧重于软件架构中的数据管理和交互方式。数据库层次分解是将同类数据按照不同需求进行分解，数据分层是将同种数据分配到特定的功能和用途。

### 0.1 动机

本项工作源自我们对于 Xerox Corporate Internet(CIN) 的 Clearinghouse servers `[Op]` 。
全球 CIN 包含数百个通过网关(在CIN上称为互联路由器)和许多不同容量的电话线连接的以太网。
数千台工作站，服务器和计算主机已连接到 CIN。
从日本的一台机器到欧洲的一台机器的数据包可能会经过多达 14 个网关和 7 条电话线。

Clearinghouse servers 维护了三种层级的转化关系，层级名称到机器地址，用户身份等。
层次结构的前两层将命名空间划分为一组域。
每个域可以存储（复制）到最少或全部的 Clearinghouse servers 中，其中有数百个。

几个域实际上是存储在 CIN 中的 Clearinghouse servers 里。
在 1986 年初，网络上许多可观察到的性能问题都可以追溯到，因为维持域的高度复制域的一致性从而产生的流量问题。
随着网络规模的增加，即使只有几台服务器存储的域在更新时的传播也非常缓慢。

当我们初次接近此问题的时候，Clearinghouse servers 正在同时使用直接发送和反熵方法。
反熵在每个域中执行，在理论上来说本地时间每一天的午夜到早上 6 点(每台服务器)。
事实上，由于网络负载过重服务器通常不能按时完整的完成反熵逻辑。

我们的第一个发现是，在发生分歧后，反熵步骤之后会跟着一个重新邮寄的步骤：当两个反熵参与者之前存在不同意见时，正确的数据库值会被发送到所有站点。
更多的站点间不一致会导致更多的通信量。
对于存储在300个站点上的一个域，每晚可能会产生多达90,000封邮件消息。
这远远超出了网络的承载能力，导致所有网络服务（如邮件、文件传输、名称查找等）出现故障。

由于在大规模网络中重新邮寄步骤明显不可行，我们的第一个观察结果是必须禁用这一功能。
进一步的分析表明，仅禁用重新邮寄步骤还不够：网络中的某些关键链接仍会因为反熵通信量而过载。
我们对空间分布和流言传播的探索源于试图进一步减少由 Clearinghouse 更新过程给网络带来的负载。

### 0.2 相关工作

本文的主要目的是维护一个广泛复制的目录，或是根据名称查找的数据库。
相较于使用基于事务的机制来实现单次拷贝序列化(例如: `[Gi]` )，而是使用副本驱动实现最终一致性的方法。
这种机制显然是由 Johnson 等人 `[Jo]` 首次提出的，并已在 Grapevine `[Bi]` 和 Clearinghouse `[Op]` 中使用。
这些系统在使用上仍然存在一些问题；特别是一些更新(概率较低)不会到达所有站点。
Lampson `[La]` 提出了一种分层数据结构，避免了高复制，但仍然需要对每个组件进行一些复制，比如六到十几台服务器。
已经提出了用于复制数据库的主站点更新算法，通过要求将更新应用于单个站点来同步更新；然后，更新站点负责将更新传播到所有副本。
例如，DARPA领域系统采用了这种算法 `[Mo]` 。
主站点更新避免了本文所述算法所解决的更新分布问题，但受到集中控制的影响。

我们的算法与之前的机制有两个区别。
首先，之前的机制依赖于底层通信协议的各种保证，以及维护一致的分布式控制结构。
例如，在 Clearinghouse 中，更新的初始分发取决于底层的保证邮件协议，即使邮件队列在磁盘存储上维护，该协议在实践中也会因物理队列溢出而不时失败。
Sarin 和 Lynch `[Sa]` 提出了一种分布式算法，用于丢弃过时的数据，该算法依赖于有保证的、有序的消息传递，以及每个服务器(大小为 $O(n^2)$ )的详细数据结构，描述了其他服务器也持有的同一数据库。
Lampson 等人 `[La]` 设想了一种确定性地围绕一圈服务器移动的扫描，这些服务器由从一个服务器到另一个服务器的指针连接在一起。
本文中的算法仅依赖于重复消息的最终传递，而不需要一个服务器上的数据结构来描述其他服务器持有的信息。

其次，本文描述的算法是随机化的；也就是说，在算法中，每个服务器都会做出独立的随机选择 `[Ra，Be85]` 。
不同的是，前面的机制是确定性的。
例如，在反熵和谣言传播算法中，服务器随机选择一个合作伙伴。
在某些版本的谣言传播算法中，服务器会随机选择保持感染性或被删除。
随机选择的使用阻止了我们做出这样的声明：“信息将在与网络直径成比例的时间内收敛。”
我们能说的最好的情况是，在没有进一步更新的情况下，信息未收敛的概率随时间呈指数级下降。
另一方面，我们认为，使用随机协议使算法能够使用简单的数据结构简单直接的实现正确性。

### 0.3 本文的计划

第 1 节正式描述了复制数据库的概念，并介绍了实现一致性的基本技术。
第 2 节介绍了一种从数据库中删除项目的技术。
删除操作比其他更改更为复杂，因为删除的项目必须由代理代表，直到删除的消息传播到所有站点为止。
第 3 部分介绍了在选择反熵和谣言传播者时非均匀空间分布的模拟和分析结果。

### 1. 基本技巧

本节介绍了复制数据库的概念，并介绍了基本的直接发送，反熵和复杂流行病协议以及它们的分析。

#### 1.1 符号

考虑一个由一组 n 个站点组成的网络，每个站点存储一个数据库的副本。
数据库拷贝在站点 s $\in$ S 是一个微小变化的偏函数。

$$s.\text{ValueOf}: K \rightarrow (v : V \times t : T)$$

> 注：s 是个服务器，K 是个存储 key 里面是对应时间的值

K 是名称的集合，V 是值的集合，T 是时间戳的集合。
V 保存了可分辨元素 NIL，但在其他方面则没有指定内容。
T 完全由 < 排序。
解释下 `s.ValueOf[k]=(NIL,t)` 这段代码的意思是 k 作为键的数据在数据库中被删除。
即从数据库客户端的角度来看 `s.ValueOf[k]=(NIL,t)` 与 `s.ValueOf[k] is undefined` 是相同的。

对于分发规则的阐述会在 1.2 和 1.3 章节以一个数据库值存储了一个值，一个时间和一个键的情况进行介绍。这是在不丧失通用性的情况下完成的，因为算法分别处理每个名称。所以我们会说

$$s.\text{ValueOf} \in (v : V \times t : T)$$

> 注：值都存储在服务器中不会丢失

也就是说，`s.ValueOf` 就是一组排序过的由值和时间戳组成的键值对。
如前所述，第一个组件可能是 NIL，这意味着该项目在第二个组件指示的时间已被删除。

更新分发过程的目标是推动系统朝着

$$\forall s, s' \in S : s.\text{ValueOf} = s'.\text{ValueOf}$$

> 注：对于每个 s 来说数据是一样的。

客户端可以调用一个操作来更新任何给定站点的数据库：

$\text{Update}[v : V] \equiv s.\text{ValueOf} \leftarrow (v, \text{Now}[])$

> 注：插入数据写入默认时间。

其中 Now 是一个返回全局唯一时间戳的函数。
希望 `Now[]` 返回的时间戳将大约是当前的格林尼治标准时间，如果不是的话算法在形式上有效，但在实践中无效。
感兴趣的读者可以参考 Clearinghouse `[Op]` 和Grapevine `[Bi]` 论文，以进一步了解时间戳在构建可用数据库中的作用。
对于此处我们的目的来说，只需知道时间戳较大的一对总是会取代时间戳较小的一对就足够了。

#### 1.2 直接发送

直接发送策略会在变更完成后第一时间尝试通知其他所有的站点。在发生更新的站点上执行的基本算法是：

$$
\begin{aligned}
&\text{FOR EACH } s' \in S \text{ DO} \\
&\quad \text{PostMail}[\text{to}:s', \text{msg}: (\text{"Update"}, s.\text{ValueOf})] \\
&\quad \text{ENDLOOP}
\end{aligned}
$$

在接收到更新消息 `("Update",(v,t))` 时站点会执行如下逻辑

$$
\begin{aligned}
&\text{IF s.ValueOf.t < t THEN} \\
&\quad \text{s.ValueOf} \leftarrow \text{(v,t)} \\
\end{aligned}
$$

PostMail 操作预计几乎可靠，但并非完全可靠。
它将报文缓存到队列中，因此发送端不会延迟。
队列保存在邮件服务器上的稳定存储中，因此它们不受服务器崩溃的影响。
但是，PostMail 也会出错，消息可能会在队列溢出或目标地址长时间网络不可达的情况下被丢弃。
除了这种报文系统基本的错误之外，直接发送方式也会在更新操作的源站点不具有正确的站点集合 S 时发生。

在 Grapevine 系统 `[Bi]` 中，检测和纠正直接发送策略失败的责任由管理网络的人员承担。
在只有几十台服务器的网络中，这被证明是足够的。

直接发送每次更新会生成 n 条消息；每条消息都会遍历其源和目标之间的所有网络链接。
因此，以（链接·消息）为单位，流量与站点数乘以站点之间的平均距离成正比。

#### 1.3 反熵

Grapevine 的设计者意识到，在大型网络中处理直接发送的故障将超出人的处理能力。
他们提出反熵作为一种可以在后台运行的机制，以自动从此类故障中恢复 `[Bi]` 。
Grapevine 没有实现反熵，但该设计交易所中基本上没有改变。

在反熵最基本的形式是在每个站点定期执行的以下算法：

$$
\begin{aligned}
&\text{FOR SOME s'} \in \text{S DO} \\
&\quad \text{ResloveDifference[s,s']} \\
&\quad \text{ENDLOOP}
\end{aligned}
$$

`ResloveDifference[s,s']` 程序由两个服务器协同执行。
基于设计来说，共有三种结果，分别是 `push`, `pull` 和 `push-pull` ：

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- push } \\
&\quad \text{IF s.ValueOf.t > s'.ValueOf.t THEN} \\
&\quad \quad \text{s'ValueOf} \leftarrow \text{s.ValueOf} \\
&\quad \}
\end{aligned}
$$

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- pull } \\
&\quad \text{IF s.ValueOf.t < s'.ValueOf.t THEN} \\
&\quad \quad \text{s.ValueOf} \leftarrow \text{s'.ValueOf} \\
&\quad \}
\end{aligned}
$$

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- push-pull } \\
&\quad \text{SELECT TRUE FROM} \\
&\quad \quad \text{sValueOf.t} > \text{s'.ValueOf.t} $\Rightarrow$ \text{s'.ValueOf} \leftarrow \text{s.ValueOf;} \\
&\quad \quad \text{sValueOf.t} < \text{s'.ValueOf.t} $\Rightarrow$ \text{s.ValueOf} \leftarrow \text{s'.ValueOf;} \\
&\quad \quad \text{EMDECASE} $\Rightarrow$ \text{NULL} \\
&\quad \}
\end{aligned}
$$

目前我们假设从 S 站点集合中均匀随机选出 s' 站点，并且每个周期执行一次反熵算法。

流行病理论的一个基本结果是，简单的流行病(反熵就是其中之一)最终会感染所有人。
这个理论同时也说明从单独一个站点收到影响开始，可以在与站点总规模的对数成比例的预期时间内实现这一目标。
比例常数对于使用哪个 ResolveDifference 程序很敏感。
对于 `push` 来说对于大小为 n 的集合提取出的公式是 $\log_2(n) + \ln(n) + O(1)$ `[Pi]` 。

令人欣慰的是，即使邮件无法将更新传播到单个站点之外，反熵最终也会将其分发到整个网络。
然而，通常情况下，我们预计反熵只会将更新分发到少数站点，假设大多数站点通过直接邮件接收更新。
因此，重要的是要考虑当只有少数站点仍然易受影响时会发生什么。
在这种情况下，行为上的巨大差异在于 `push` 和 `pull` ， 推拉 `push-pull` 的行为本质上类似于 `pull`。
设 $p_i$ 为站点 s 在第 $i^th$ 个反熵循环之后仍然“易受影响”的概率。
对于 `pull` 来说站点在第 $i^th$ 个循环后处于 “易受影响” 状态，并且在第 $i + 1^{\text{st}}$ 个循环中接触到一个“传染”站点，那么该位点在第 $i + 1^{\text{st}}$ 个循环后仍然保持“易受影响”状态。
因此我们得到了公式：

$$
\begin{aligned}
& p_{\text{i+1}} = (p_i)^2
\end{aligned}
$$

这说明了当 $p_i$ 很小时结果会趋于 0。
对于 `push` 来说，如果某个站点在第 i$i^th$ 个循环后处于“易受影响”状态，并且没有“传染”站点选择在第 $i + 1^{\text{st}}$ 个循环内与其接触，则该站点在第 $i + 1^{\text{st}}$ 个周期后仍然处于“易受影响”状态。
因此，推的类似递归关系为：

$$
\begin{aligned}
& p_{\text{i+1}} = p_i(1-\frac{1}{n})^{n(1-p_i)}
\end{aligned}
$$

它也收敛到 0，但速度慢得多，因为对于非常小的 $p_i$ (和很大的 n)，它大约是


$$
\begin{aligned}
& p_{i+1} = p_ie^{-1}
\end{aligned}
$$

这有力地表明，在实践中，当反熵被用作其他传播机制(如直接发送)的备份时，`pull` 或 `push-pull` 都比 `push` 更可取，因为 `push` 在预期情况下表现不佳。
正如本文所述，反熵算法非常昂贵，因为它需要比较数据库的两个完整副本，让一个副本发送其中的内容。
通常情况下，数据库的副本几乎完全一致，因此大部分工作都白费了。
基于此观察，一个可能的性能改进方法是让每个站点维护其数据库内容的校验和，并在数据库更新时逐步重新计算校验和。
执行反熵算法的站点首先交换校验和，只有当校验和不一致时才比较它们的完整数据库。
假设校验和在大多数情况下一致，此方案可以节省大量网络流量。
不幸的是，最近的更新通常只被部分站点而非所有站点知道。
除非将更新发送到所有站点所需的时间相对于新更新之间的预期很短，否则不同站点的校验和可能会不一致。
随着网络规模的增加，向所有站点分发更新所需的时间也会增加，因此上述校验和的简单使用变得越来越没用。

一种更复杂的校验和使用方法是定义一个足够大的时间窗口 $\tau$ ，以便更新能够在时间 $\tau$ 内到达所有站点。
与简单方案一样，每个站点都维护其数据库的校验和。
此外，站点还维护一个最近更新列表，其中包含其数据库中所有年龄(以时间戳值与站点本地时钟之间的差值来衡量)小于 $\tau$ 的条目。
两个站点通过首先交换最近更新列表，使用这些列表更新各自的数据库和校验和，然后比较校验和来实现反熵。
只有当校验和不一致时，站点才会比较它们的整个数据库。

在比较校验和之前交换最近更新列表，可以确保如果一个站点最近收到更改或删除，则相应的过时条目不会影响另一个站点的校验和。
因此，校验和方法很可能成功，无需进行完整的数据库比较。
在这种情况下，反熵比较产生的预期流量恰好是最近更新列表的预期大小，该大小受时间 $\tau$ 内网络上发生的更新预期数量限制。
请注意，$\tau$ 的选择应超过更新的预期分发时间；如果 $\tau$ 选择不当，或者网络增长导致预期更新分发时间超过 $\tau$ ，则校验和通常会失败，网络流量将上升到略高于不使用校验和的反熵产生的流量的水平。

如果每个站点都能按时间戳维护其数据库的倒排索引，则可以对上述方案进行简单的变体处理，该变体无需事先选择 $\tau$ 的值。
两个站点通过按时间戳的逆序交换更新，逐步重新计算校验和，直到校验和一致，从而实现反熵。
虽然从网络流量的角度来看，这种方案近乎理想，但这种方案（下文中我们将称之为“剥离”）在实践中可能并不理想，因为在每个站点维护额外的倒排索引需要一定的开销。

#### 1.4 复杂流行病协议

正如我们已经看到的，直接发送更新存在几个问题：它可能由于消息丢失而失败，或者由于发起者对其他数据库站点的信息不完整而失败，并且它会在发起站点导致 O(n) 瓶颈。
其中一些问题可以通过广播邮件机制来解决，但该机制本身很可能依赖于分布式信息。
我们即将描述的流行病机制确实避免了这些问题，但它们具有不同的、明确的失败概率，必须通过分析和模拟进行仔细研究。
幸运的是，这种失败概率可以任意减小。
我们将这些机制称为“复杂”流行病，只是为了将它们与反熵流行病（一种简单的流行病）区分开来；复杂流行病仍然有简单的实现。

回想一下，对于单个更新，数据库要么是易受攻击的（它不知道该更新），要么是具有感染性的（它知道该更新并主动与他人共享），要么是已被删除的（它知道该更新但并未传播）。
实现这一点相对容易，因此共享步骤不需要完全“遍历”数据库。
发送者会保存一个感染性更新列表，而接收者会尝试将每个更新插入到自己的数据库中，并将所有新更新添加到其感染列表中。
唯一的复杂之处在于决定何时从感染列表中删除更新。

在我们讨论“良好”流行病的设计之前，让我们看一个在流行病学文献中通常被称为谣言传播的例子。

谣言传播基于以下场景：有 n 个个体，最初处于非活跃状态（易感）。
我们先散布一个谣言，其中一人变得活跃（具有传染性），随机给其他人打电话并分享谣言。
每个听到谣言的人也会变得活跃，并同样分享谣言。
当一个活跃的个体拨打了不必要的电话（接收者已经知道谣言）时，该活跃个体有 1/k 的概率失去分享谣言的兴趣（该个体被移除）。
我们想知道系统收敛到非活跃状态（无人具有传染性的状态）的速度，以及达到此状态时知道谣言（被移除）的人的百分比。

根据流行病学文献，谣言传播可以用一对微分方程来确定性地建模。
我们设 s、i 和 r 分别代表易感、感染和被移除个体的比例，因此 s + i + r = 1：

$$
\begin{aligned}
\frac{ds}{dt} &= -si & \\
\frac{di}{dt} &= +si - \frac{1}{k}(1-s)i
\end{aligned}
$$

(*)

第一个方程表明，根据乘积 si，易感人群将被感染。
第二个方程增加了一个项，表示个人拨打不必要的电话造成的损失。
第三个关于 r 的方程是多余的。

处理像 (*) 这样的方程的标准技巧是使用比率 `[Ba]` 。
这样就消去了 t，让我们求解 i 作为 s 的函数：

$$
\begin{aligned}
\frac{di}{ds} &= - \frac{k+1}{k} + \frac{1}{ks} \\
i(s) &= - \frac{k+1}{k} s + \frac{1}{k} \log s + c
\end{aligned}
$$

其中 c 是积分常数，可由初始条件确定：$i(1- \epsilon) = \epsilon $
当 n 较大时，$\epsilon$ 趋于零，得出：

$$
\begin{aligned}
c = \frac{k+1}{k}
\end{aligned}
$$

以及一个解决方案

$$
\begin{aligned}
i(s)= \frac{k+1}{k} (1-s)+ \frac{1}{k} \log s.
\end{aligned}
$$

此方程中 $i(s)$ 会在当前情况下为 0

$$
\begin{aligned}
s = e^{-(k+1)(1-s)}.
\end{aligned}
$$

这是关于 s 的一个隐式方程，但主要项表明 s 随 k 呈指数下降。
因此，增加 k 是确保几乎每个人都能听到谣言的有效方法。
例如，当 k = 1 时，该公式表明 20% 的人会错过该谣言，而当 k = 2 时，只有 6% 的人会听到。

**变体**

到目前为止，我们只见过一例基于谣言传播技巧的复杂流行病。
总的来说，我们希望了解如何设计一场“良好”的流行病，因此现在值得停下来回顾一下评判流行病的标准。
我们主要关注的是：

1. **残差** 这是当 i 为零时 s 的值，即疫情结束时剩余的易感人群。我们希望残差尽可能小，正如上述分析所示，使残差任意小都是可行的。
2. **流量** 目前，我们正在测量站点之间发送的数据库更新流量，而不考虑网络拓扑结构。使用起来很方便。平均 m，即从典型站点发送的消息数量：

$$
\begin{aligned}
m = \frac{\text{Total update traffic}}{ \text{Number of sites} }
\end{aligned}
$$

在第 3 部分中，我们将完善此指标，以纳入各个链接的流量

3. **延迟** 平均延迟是指更新首次更新的时间与更新到达给定站点的时间之差，取所有站点的平均值。我们将其称为 $t_{ave}$。一个类似的量 $t_{last}$，是指在疫情期间，到最后一个接收更新的站点接收到更新为止的延迟时间。在 $t_{last}$ 之后，更新消息可能会继续出现在网络中，但它们永远不会到达易感的站点。我们发现有必要引入两个时间，因为它们的行为通常不同，而设计者对这两个时间都有合理的担忧。

接下来，我们来探讨几种简单的谣言传播变体。
首先，我们将描述这些变体的实际应用，之后再讨论残差、流量和延迟。

**盲目型(Blind) vs. 响应型(Feedback)** 响应型使用了接收者的反馈；只有当接收者已经知道谣言时，发送者才会失去兴趣。
无论接收者是谁，盲目变体都会以 1/k 的概率失去兴趣。
这消除了接收者需要位向量响应的需要。

**计数型(Counter) vs. 硬币型(Coin)** 计数型的逻辑是只有在进行过 k 次不必要的接触后才会失去兴趣，而不是以 1/k 的概率失去兴趣。
计数型需要为感染列表中的元素保存额外的状态。
注意，我们可以将计数型与盲目型作结合起来，这样即使没有任何反馈，也能在 k 次循环中保持感染性。

上述变化的一个令人惊讶的方面是，它们在流量和残差之间具有相同的基本关系：

$$
\begin{aligned}
s = e^{-m}
\end{aligned}
$$

这一点很容易理解，因为有 nm 个更新被发送，单个站点错过所有更新的概率为 $(1- \frac{1}{n})^{nm}$ 。
（由于 m 不是常数，因此这种关系取决于当 $n \to \infty$ 时，m 分布均值附近的矩趋于零，这是我们通过经验观察到的，但尚未证实。）
延迟是区分上述可能性的唯一考虑因素：模拟表明，计数型和响应型可以改善延迟，其中计数的作用比响应更为显著。

> 表 1. 使用响应型和计数型在 1000 个站点上进行流行病方式模拟的表现。

| Counter $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|-----------------|------------------|-----------------|----------------------------------|------------------------------------|
| 1               | 0.18             | 1.7             | 11.0                             | 16.8                               |
| 2               | 0.037            | 3.3             | 12.1                             | 16.9                               |
| 3               | 0.011            | 4.5             | 12.5                             | 17.4                               |
| 4               | 0.0036           | 5.6             | 12.7                             | 17.5                               |
| 5               | 0.0012           | 6.7             | 12.8                             | 17.7                               |

> 表 2. 使用盲目型和硬币在 1000 个站点进行流行病方式模拟的表现。

| Coin $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|----------|-------------|-------------|----------------------|--------------------|
| 1        | 0.96        | 0.04        | 19                   | 38                 |
| 2        | 0.20        | 1.6         | 17                   | 33                 |
| 3        | 0.060       | 2.8         | 15                   | 32                 |
| 4        | 0.021       | 3.9         | 14.1                 | 32                 |
| 5        | 0.008       | 4.9         | 13.8                 | 32                 |

**Push vs. Pull**
到目前为止，我们假设所有站点都会随机选择目标站点，并将具有感染性的更新推送到这些目标站点。
我们已经对反熵理论做出的 push vs. pull 的区分也适用于谣言传播。
pull 有一些优势，但主要的实际考虑因素是更新注入分布式数据库的速率。
如果存在大量独立更新，pull 请求很可能会找到一个具有非空谣言列表的源，从而触发有用的信息流。
相比之下，如果数据库处于静止状态，push 算法将不再引入流量开销，而 pull 算法则会继续注入无效的更新请求。
我们自己的 CIN 应用程序具有足够高的更新速率，足以保证使用拉取。

pull 策略的主要优势在于，它比 push 策略的 $s=e^{-m}$ 关系表现得更好。
在这里，盲目型与响应行以及计数型与硬币型的变化非常重要。
模拟表明，计数型和反馈型的变化改善了剩余效果，其中计数型比反馈型更重要。
我们有一个递归关系，用于模拟计数型与反馈型的情况，其表现出 $s=e^{- \Theta (m^3)}$ 。

> 表 3. 使用反馈型和计数型在 1000 个站点上执行流行病方式模拟(拉取)的表现。

| Counter $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|-------------|------------------------|-------------|-----------------------|--------------------|
| 1           | $ 3.1 \times 10^{-2} $ | 2.7         | 9.97                  | 17.6               |
| 2           | $ 5.8 \times 10^{-4} $ | 4.5         | 10.07                 | 15.4               |
| 3           | $ 4.0 \times 10^{-6} $ | 6.1         | 10.08                 | 14.0               |

如果在一个周期内有多个接收者从站点拉取数据，那么在周期结束时对计数器的影响如下：如果有任何接收者需要更新，则计数器将重置；如果所有接收者都不需要更新，则计数器将累加。

**最小残留量(Minimization)** 
也可以利用交换双方的计数器来做出移除决策。
其思路是同时使用推送和拉取操作，如果两个站点都已获知更新，则只有计数器较小的站点才会递增（如果相等，则两个站点都必须递增）。
这需要通过网络发送计数器，但这会导致我们迄今为止看到的最小残留量。

**连接限制(Connection Limit)**
目前尚不清楚连接限制应该被视为难点还是优势。
到目前为止，我们忽略了连接限制。
例如，在推送模式下，我们假设一个站点可以在一个周期内接收多个推送；在拉取模式下，我们假设一个站点可以处理无限数量的请求。
由于我们计划频繁运行谣言传播算法，因此出于现实考虑，我们不得不使用连接限制。
连接限制对推送和拉取机制的影响不同：拉取会显著恶化，而推送则会显著改善，这很矛盾。

为了理解推送效果为何会更好，假设数据库几乎处于静止状态，即只有一个更新正在传播，并且连接数限制为 1。
如果两个站点联系同一个接收者，则其中一个联系会被拒绝。
接收者仍然可以收到更新，但流量单位会减少一个。
（我们选择仅根据发送的更新来衡量流量。
尝试被拒绝的连接时会产生一些网络流量，但这比传输更新所涉及的流量要少。
本质上，我们缩短了原本无用的连接。）
有多少连接被拒绝？
由于发送呈指数级增长，我们假设大部分流量发生在几乎每个人都具有传染性的最后阶段，此时被拒绝的概率接近 
 $e^{-1}$ 。
因此，我们预期带有连接数限制的推送会表现为：

$$
\begin{aligned}
s = e^{- \lambda m} \quad \quad \lambda = \frac{1}{1-e^{-1}}
\end{aligned}
$$

模拟表明，计数型变体最接近这种行为（带反馈的计数型最有效）。
硬币型变体不符合上述假设，因为它们的大部分流量并非发生在几乎所有站点都具有感染性的情况下。
尽管如此，它们仍然比 $s = e^{-m}$ 表现更好。
在所有变体中，由于在几乎静止的网络上推送时，连接限制为 1 时效果最佳，因此即使可以有更多连接，似乎也值得强制执行此限制。

连接数限制会导致拉取性能下降，因为其良好性能依赖于每个站点在每个周期内都作为接收者。
若连接失败概率为 $\delta$ ，拉取性能的渐近线就会发生变化。
假设几乎所有流量都发生在几乎所有站点都处于感染状态时，那么在此活跃期间站点错过更新的概率大致为：

$$
\begin{aligned}
s = \delta ^m = e^{- \lambda m} \quad \quad \lambda = - \ln \delta
\end{aligned}
$$