---
title: "Epidemic Algorithms For Replicated Database Maintenance 中文翻译版"
date: 2025-02-26 22:26:13
tags:
- "论文"
- "Gossip"
id: epidemic_algorithms_for_replicated_database_maintenance
no_word_count: true
no_toc: false
categories: 大数据
math: true
---

## Epidemic Algorithms For Replicated Database Maintenance 中文翻译版

作者：Alan Demers, Mark Gealy, Dan Greene, Carl Hauser, Wes Irish, John Larson, Sue Manning, Scott Shenker, Howard Sturgis, Dan Swinehart, Doug Terry, and Don Woods

[英文原文](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf)

### 摘要

当在多个站点上复制数据库时，保持相互一致性的更新是一个重大问题。本文描述了一些随机的算法来实现分布式的更新和驱动副本的一致性。算法非常简单，只需要底层通讯上一点小小的保证，但它们可以确保每次更新的效果最终都能体现在所有副本中。此算法的耗费和性能可以通过调节随机化步骤的合适的分布来实现。算法与流行病非常相似，阅读流行病学的文献有助于理解它们的行为。其中一种算法已在 Xerox Corporate Internet的 Clearinghouse 服务器中实现，解决了长期存在的高流量和数据库不一致问题。

### 0. 引言

考虑到在一个由数百或数千个站点组成的大型、异构、稍不可靠且变化缓慢的网络中的许多站点复制的数据库，我们研究了实现和维护站点之间一致性的几种方法。
每个数据库更新操作都从某一个站点注入，必须传播到所有其他站点，或者被以后的更新所取代。
只有当所有更新活动都停止并且系统处于静止状态时，这些站点才能变得完全一致。
在另一方面，假设有一个合理的更新频率，在给定某个站点时它上面的数据大多都是当前状态。
这种较为宽松的一致性形式已被证明在实践中非常有用 `[Bi]`。我们的目标是设计一种高效且强大的算法，并随着站点数量的增加而优雅地扩展。

在研究解决此问题的算法时要考虑的重要因素包括：

- 更新传播到所有站点所花费的时间
- 更新所花费的网络流量。理想情况下，网络流量与更新大小和服务器数量成正比，但是某些算法会产生更多流量。

在本文中，我们使用几种扩展更新的策略介绍了分析，仿真结果和实践经验。检查的方法包括：

1. 直接发送(Direct mail)：每个更新都立即从进入站点发送到其他所有站点。这是非常节省时间和理论上效果最好的，但并不完全可靠，因为各个站点并不总是了解所有其他站点，并且有时会丢失报文。

2. 反熵(Anti-entropy)：每个站点通常选择一个随机的其他站点，然后交换数据库中的差异数据。由于反熵及其可靠但是需要检查数据库中的数据内容，所以这种做法不能频繁执行。分析和模拟表明，反熵虽然可靠，但是传播更新的速度要比直接发送慢得多。

3. 谣言传播算法(Rumor mongering)：站点的初始状态是空白的；当站点接收到一个新的更新时会变成 "热点谣言"；当站点持有一个热点谣言，它会周期性的选择一个另外的站点并让另一个站点观测到此次更新；当某个站点试图与太多已经看到它的站点共享热门谣言时，该站点将停止将该谣言视为热点，并保留更新，而不会进一步传播。谣言周期可能比反熵周期更频繁，因为它们在每个站点所需要的资源更少，但是有可能更新不会到达所有站点。

反熵和谣言传播都是流行过程的例子，流行理论 `[Ba]` 的结果也适用。尽管我们的目标有所不同，但我们对这些机制的理解极大地受益于现有的流行病学数学理论(我们将对更新的迅速而全面的传播感到满意)。
此外，我们可以自由设计流行病机制，而不必设计现有疾病的模型。
我们采用流行病学文献的术语，并称其为一个愿意与之分享感染性的更新。
如果站点尚未收到更新，则该站点很容易受到攻击；如果某个站点已经收到更新但不再愿意共享该更新，则将其删除。
反熵是一种简单的流行病示例：一个站点总是易受感染的站点。

统一选择合作伙伴会导致相当高的网络流量，这促使我们考虑空间分布，在这种分布中，选择往往有利于附近的服务器。
对 Xerox Corporate Internet 实际拓扑结构的分析和模拟揭示了反熵和谣言传播的分布，这些分布的收敛速度几乎与均匀分布一样快，同时降低了每条链路的平均和最大流量。
产生的反熵算法已安装在 Xerox Corporate Internet 上，并显着提高了性能。

我们应该指出，数据库的大量复制非常昂贵。
应尽可能通过数据库的层次分解或缓存来避免这种情况。
即便如此，我们的论文结果还是很有趣的，因为它们表明可以使用简单的算法在层次结构的每个级别或在缓存方案的主干中实现显着的复制。

> 注：此处的数据库层次分解和数据分层的概念是不同的。前者侧重于数据库内部的组织和优化，后者侧重于软件架构中的数据管理和交互方式。数据库层次分解是将同类数据按照不同需求进行分解，数据分层是将同种数据分配到特定的功能和用途。

### 0.1 动机

本项工作源自我们对于 Xerox Corporate Internet(CIN) 的 Clearinghouse servers `[Op]` 。
全球 CIN 包含数百个通过网关(在CIN上称为互联路由器)和许多不同容量的电话线连接的以太网。
数千台工作站，服务器和计算主机已连接到 CIN。
从日本的一台机器到欧洲的一台机器的数据包可能会经过多达 14 个网关和 7 条电话线。

Clearinghouse servers 维护了三种层级的转化关系，层级名称到机器地址，用户身份等。
层次结构的前两层将命名空间划分为一组域。
每个域可以存储（复制）到最少或全部的 Clearinghouse servers 中，其中有数百个。

几个域实际上是存储在 CIN 中的 Clearinghouse servers 里。
在 1986 年初，网络上许多可观察到的性能问题都可以追溯到，因为维持域的高度复制域的一致性从而产生的流量问题。
随着网络规模的增加，即使只有几台服务器存储的域在更新时的传播也非常缓慢。

当我们初次接近此问题的时候，Clearinghouse servers 正在同时使用直接发送和反熵方法。
反熵在每个域中执行，在理论上来说本地时间每一天的午夜到早上 6 点(每台服务器)。
事实上，由于网络负载过重服务器通常不能按时完整的完成反熵逻辑。

我们的第一个发现是，在发生分歧后，反熵步骤之后会跟着一个重新邮寄的步骤：当两个反熵参与者之前存在不同意见时，正确的数据库值会被发送到所有站点。
更多的站点间不一致会导致更多的通信量。
对于存储在300个站点上的一个域，每晚可能会产生多达90,000封邮件消息。
这远远超出了网络的承载能力，导致所有网络服务（如邮件、文件传输、名称查找等）出现故障。

由于在大规模网络中重新邮寄步骤明显不可行，我们的第一个观察结果是必须禁用这一功能。
进一步的分析表明，仅禁用重新邮寄步骤还不够：网络中的某些关键链接仍会因为反熵通信量而过载。
我们对空间分布和流言传播的探索源于试图进一步减少由 Clearinghouse 更新过程给网络带来的负载。

### 0.2 相关工作

本文的主要目的是维护一个广泛复制的目录，或是根据名称查找的数据库。
相较于使用基于事务的机制来实现单次拷贝序列化(例如: `[Gi]` )，而是使用副本驱动实现最终一致性的方法。
这种机制显然是由 Johnson 等人 `[Jo]` 首次提出的，并已在 Grapevine `[Bi]` 和 Clearinghouse `[Op]` 中使用。
这些系统在使用上仍然存在一些问题；特别是一些更新(概率较低)不会到达所有站点。
Lampson `[La]` 提出了一种分层数据结构，避免了高复制，但仍然需要对每个组件进行一些复制，比如六到十几台服务器。
已经提出了用于复制数据库的主站点更新算法，通过要求将更新应用于单个站点来同步更新；然后，更新站点负责将更新传播到所有副本。
例如，DARPA领域系统采用了这种算法 `[Mo]` 。
主站点更新避免了本文所述算法所解决的更新分布问题，但受到集中控制的影响。

我们的算法与之前的机制有两个区别。
首先，之前的机制依赖于底层通信协议的各种保证，以及维护一致的分布式控制结构。
例如，在 Clearinghouse 中，更新的初始分发取决于底层的保证邮件协议，即使邮件队列在磁盘存储上维护，该协议在实践中也会因物理队列溢出而不时失败。
Sarin 和 Lynch `[Sa]` 提出了一种分布式算法，用于丢弃过时的数据，该算法依赖于有保证的、有序的消息传递，以及每个服务器(大小为 $O(n^2)$ )的详细数据结构，描述了其他服务器也持有的同一数据库。
Lampson 等人 `[La]` 设想了一种确定性地围绕一圈服务器移动的扫描，这些服务器由从一个服务器到另一个服务器的指针连接在一起。
本文中的算法仅依赖于重复消息的最终传递，而不需要一个服务器上的数据结构来描述其他服务器持有的信息。

其次，本文描述的算法是随机化的；也就是说，在算法中，每个服务器都会做出独立的随机选择 `[Ra，Be85]` 。
不同的是，前面的机制是确定性的。
例如，在反熵和谣言传播算法中，服务器随机选择一个合作伙伴。
在某些版本的谣言传播算法中，服务器会随机选择保持感染性或被删除。
随机选择的使用阻止了我们做出这样的声明：“信息将在与网络直径成比例的时间内收敛。”
我们能说的最好的情况是，在没有进一步更新的情况下，信息未收敛的概率随时间呈指数级下降。
另一方面，我们认为，使用随机协议使算法能够使用简单的数据结构简单直接的实现正确性。

### 0.3 本文的计划

第 1 节正式描述了复制数据库的概念，并介绍了实现一致性的基本技术。
第 2 节介绍了一种从数据库中删除项目的技术。
删除操作比其他更改更为复杂，因为删除的项目必须由代理代表，直到删除的消息传播到所有站点为止。
第 3 部分介绍了在选择反熵和谣言传播者时非均匀空间分布的模拟和分析结果。

### 1. 基本技巧

本节介绍了复制数据库的概念，并介绍了基本的直接发送，反熵和复杂流行病协议以及它们的分析。

#### 1.1 符号

考虑一个由一组 n 个站点组成的网络，每个站点存储一个数据库的副本。
数据库拷贝在站点 s $\in$ S 是一个微小变化的偏函数。

$$s.\text{ValueOf}: K \rightarrow (v : V \times t : T)$$

> 注：s 是个服务器，K 是个存储 key 里面是对应时间的值

K 是名称的集合，V 是值的集合，T 是时间戳的集合。
V 保存了可分辨元素 NIL，但在其他方面则没有指定内容。
T 完全由 < 排序。
解释下 `s.ValueOf[k]=(NIL,t)` 这段代码的意思是 k 作为键的数据在数据库中被删除。
即从数据库客户端的角度来看 `s.ValueOf[k]=(NIL,t)` 与 `s.ValueOf[k] is undefined` 是相同的。

对于分发规则的阐述会在 1.2 和 1.3 章节以一个数据库值存储了一个值，一个时间和一个键的情况进行介绍。这是在不丧失通用性的情况下完成的，因为算法分别处理每个名称。所以我们会说

$$s.\text{ValueOf} \in (v : V \times t : T)$$

> 注：值都存储在服务器中不会丢失

也就是说，`s.ValueOf` 就是一组排序过的由值和时间戳组成的键值对。
如前所述，第一个组件可能是 NIL，这意味着该项目在第二个组件指示的时间已被删除。

更新分发过程的目标是推动系统朝着

$$\forall s, s' \in S : s.\text{ValueOf} = s'.\text{ValueOf}$$

> 注：对于每个 s 来说数据是一样的。

客户端可以调用一个操作来更新任何给定站点的数据库：

$\text{Update}[v : V] \equiv s.\text{ValueOf} \leftarrow (v, \text{Now}[])$

> 注：插入数据写入默认时间。

其中 Now 是一个返回全局唯一时间戳的函数。
希望 `Now[]` 返回的时间戳将大约是当前的格林尼治标准时间，如果不是的话算法在形式上有效，但在实践中无效。
感兴趣的读者可以参考 Clearinghouse `[Op]` 和Grapevine `[Bi]` 论文，以进一步了解时间戳在构建可用数据库中的作用。
对于此处我们的目的来说，只需知道时间戳较大的一对总是会取代时间戳较小的一对就足够了。

#### 1.2 直接发送

直接发送策略会在变更完成后第一时间尝试通知其他所有的站点。在发生更新的站点上执行的基本算法是：

$$
\begin{aligned}
&\text{FOR EACH } s' \in S \text{ DO} \\
&\quad \text{PostMail}[\text{to}:s', \text{msg}: (\text{"Update"}, s.\text{ValueOf})] \\
&\quad \text{ENDLOOP}
\end{aligned}
$$

在接收到更新消息 `("Update",(v,t))` 时站点会执行如下逻辑

$$
\begin{aligned}
&\text{IF s.ValueOf.t < t THEN} \\
&\quad \text{s.ValueOf} \leftarrow \text{(v,t)} \\
\end{aligned}
$$

PostMail 操作预计几乎可靠，但并非完全可靠。
它将报文缓存到队列中，因此发送端不会延迟。
队列保存在邮件服务器上的稳定存储中，因此它们不受服务器崩溃的影响。
但是，PostMail 也会出错，消息可能会在队列溢出或目标地址长时间网络不可达的情况下被丢弃。
除了这种报文系统基本的错误之外，直接发送方式也会在更新操作的源站点不具有正确的站点集合 S 时发生。

在 Grapevine 系统 `[Bi]` 中，检测和纠正直接发送策略失败的责任由管理网络的人员承担。
在只有几十台服务器的网络中，这被证明是足够的。

直接发送每次更新会生成 n 条消息；每条消息都会遍历其源和目标之间的所有网络链接。
因此，以（链接·消息）为单位，流量与站点数乘以站点之间的平均距离成正比。

#### 1.3 反熵

Grapevine 的设计者意识到，在大型网络中处理直接发送的故障将超出人的处理能力。
他们提出反熵作为一种可以在后台运行的机制，以自动从此类故障中恢复 `[Bi]` 。
Grapevine 没有实现反熵，但该设计交易所中基本上没有改变。

在反熵最基本的形式是在每个站点定期执行的以下算法：

$$
\begin{aligned}
&\text{FOR SOME s'} \in \text{S DO} \\
&\quad \text{ResloveDifference[s,s']} \\
&\quad \text{ENDLOOP}
\end{aligned}
$$

`ResloveDifference[s,s']` 程序由两个服务器协同执行。
基于设计来说，共有三种结果，分别是 `push`, `pull` 和 `push-pull` ：

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- push } \\
&\quad \text{IF s.ValueOf.t > s'.ValueOf.t THEN} \\
&\quad \quad \text{s'ValueOf} \leftarrow \text{s.ValueOf} \\
&\quad \}
\end{aligned}
$$

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- pull } \\
&\quad \text{IF s.ValueOf.t < s'.ValueOf.t THEN} \\
&\quad \quad \text{s.ValueOf} \leftarrow \text{s'.ValueOf} \\
&\quad \}
\end{aligned}
$$

$$
\begin{aligned}
&\text{ResloveDiffreence: PROC[s,s'] = \{ -- push-pull } \\
&\quad \text{SELECT TRUE FROM} \\
&\quad \quad \text{sValueOf.t} > \text{s'.ValueOf.t} $\Rightarrow$ \text{s'.ValueOf} \leftarrow \text{s.ValueOf;} \\
&\quad \quad \text{sValueOf.t} < \text{s'.ValueOf.t} $\Rightarrow$ \text{s.ValueOf} \leftarrow \text{s'.ValueOf;} \\
&\quad \quad \text{EMDECASE} $\Rightarrow$ \text{NULL} \\
&\quad \}
\end{aligned}
$$

目前我们假设从 S 站点集合中均匀随机选出 s' 站点，并且每个周期执行一次反熵算法。

流行病理论的一个基本结果是，简单的流行病(反熵就是其中之一)最终会感染所有人。
这个理论同时也说明从单独一个站点收到影响开始，可以在与站点总规模的对数成比例的预期时间内实现这一目标。
比例常数对于使用哪个 ResolveDifference 程序很敏感。
对于 `push` 来说对于大小为 n 的集合提取出的公式是 $\log_2(n) + \ln(n) + O(1)$ `[Pi]` 。

令人欣慰的是，即使邮件无法将更新传播到单个站点之外，反熵最终也会将其分发到整个网络。
然而，通常情况下，我们预计反熵只会将更新分发到少数站点，假设大多数站点通过直接邮件接收更新。
因此，重要的是要考虑当只有少数站点仍然易受影响时会发生什么。
在这种情况下，行为上的巨大差异在于 `push` 和 `pull` ， 推拉 `push-pull` 的行为本质上类似于 `pull`。
设 $p_i$ 为站点 s 在第 $i^th$ 个反熵循环之后仍然“易受影响”的概率。
对于 `pull` 来说站点在第 $i^th$ 个循环后处于 “易受影响” 状态，并且在第 $i + 1^{\text{st}}$ 个循环中接触到一个“传染”站点，那么该位点在第 $i + 1^{\text{st}}$ 个循环后仍然保持“易受影响”状态。
因此我们得到了公式：

$$
\begin{aligned}
& p_{\text{i+1}} = (p_i)^2
\end{aligned}
$$

这说明了当 $p_i$ 很小时结果会趋于 0。
对于 `push` 来说，如果某个站点在第 i$i^th$ 个循环后处于“易受影响”状态，并且没有“传染”站点选择在第 $i + 1^{\text{st}}$ 个循环内与其接触，则该站点在第 $i + 1^{\text{st}}$ 个周期后仍然处于“易受影响”状态。
因此，推的类似递归关系为：

$$
\begin{aligned}
& p_{\text{i+1}} = p_i(1-\frac{1}{n})^{n(1-p_i)}
\end{aligned}
$$

它也收敛到 0，但速度慢得多，因为对于非常小的 $p_i$ (和很大的 n)，它大约是


$$
\begin{aligned}
& p_{i+1} = p_ie^{-1}
\end{aligned}
$$

这有力地表明，在实践中，当反熵被用作其他传播机制(如直接发送)的备份时，`pull` 或 `push-pull` 都比 `push` 更可取，因为 `push` 在预期情况下表现不佳。
正如本文所述，反熵算法非常昂贵，因为它需要比较数据库的两个完整副本，让一个副本发送其中的内容。
通常情况下，数据库的副本几乎完全一致，因此大部分工作都白费了。
基于此观察，一个可能的性能改进方法是让每个站点维护其数据库内容的校验和，并在数据库更新时逐步重新计算校验和。
执行反熵算法的站点首先交换校验和，只有当校验和不一致时才比较它们的完整数据库。
假设校验和在大多数情况下一致，此方案可以节省大量网络流量。
不幸的是，最近的更新通常只被部分站点而非所有站点知道。
除非将更新发送到所有站点所需的时间相对于新更新之间的预期很短，否则不同站点的校验和可能会不一致。
随着网络规模的增加，向所有站点分发更新所需的时间也会增加，因此上述校验和的简单使用变得越来越没用。

一种更复杂的校验和使用方法是定义一个足够大的时间窗口 $\tau$ ，以便更新能够在时间 $\tau$ 内到达所有站点。
与简单方案一样，每个站点都维护其数据库的校验和。
此外，站点还维护一个最近更新列表，其中包含其数据库中所有年龄(以时间戳值与站点本地时钟之间的差值来衡量)小于 $\tau$ 的条目。
两个站点通过首先交换最近更新列表，使用这些列表更新各自的数据库和校验和，然后比较校验和来实现反熵。
只有当校验和不一致时，站点才会比较它们的整个数据库。

在比较校验和之前交换最近更新列表，可以确保如果一个站点最近收到更改或删除，则相应的过时条目不会影响另一个站点的校验和。
因此，校验和方法很可能成功，无需进行完整的数据库比较。
在这种情况下，反熵比较产生的预期流量恰好是最近更新列表的预期大小，该大小受时间 $\tau$ 内网络上发生的更新预期数量限制。
请注意，$\tau$ 的选择应超过更新的预期分发时间；如果 $\tau$ 选择不当，或者网络增长导致预期更新分发时间超过 $\tau$ ，则校验和通常会失败，网络流量将上升到略高于不使用校验和的反熵产生的流量的水平。

如果每个站点都能按时间戳维护其数据库的倒排索引，则可以对上述方案进行简单的变体处理，该变体无需事先选择 $\tau$ 的值。
两个站点通过按时间戳的逆序交换更新，逐步重新计算校验和，直到校验和一致，从而实现反熵。
虽然从网络流量的角度来看，这种方案近乎理想，但这种方案（下文中我们将称之为“剥离”）在实践中可能并不理想，因为在每个站点维护额外的倒排索引需要一定的开销。

#### 1.4 复杂流行病协议

正如我们已经看到的，直接发送更新存在几个问题：它可能由于消息丢失而失败，或者由于发起者对其他数据库站点的信息不完整而失败，并且它会在发起站点导致 O(n) 瓶颈。
其中一些问题可以通过广播邮件机制来解决，但该机制本身很可能依赖于分布式信息。
我们即将描述的流行病机制确实避免了这些问题，但它们具有不同的、明确的失败概率，必须通过分析和模拟进行仔细研究。
幸运的是，这种失败概率可以任意减小。
我们将这些机制称为“复杂”流行病，只是为了将它们与反熵流行病（一种简单的流行病）区分开来；复杂流行病仍然有简单的实现。

回想一下，对于单个更新，数据库要么是易受攻击的（它不知道该更新），要么是具有感染性的（它知道该更新并主动与他人共享），要么是已被删除的（它知道该更新但并未传播）。
实现这一点相对容易，因此共享步骤不需要完全“遍历”数据库。
发送者会保存一个感染性更新列表，而接收者会尝试将每个更新插入到自己的数据库中，并将所有新更新添加到其感染列表中。
唯一的复杂之处在于决定何时从感染列表中删除更新。

在我们讨论“良好”流行病的设计之前，让我们看一个在流行病学文献中通常被称为谣言传播的例子。

谣言传播基于以下场景：有 n 个个体，最初处于非活跃状态（易感）。
我们先散布一个谣言，其中一人变得活跃（具有传染性），随机给其他人打电话并分享谣言。
每个听到谣言的人也会变得活跃，并同样分享谣言。
当一个活跃的个体拨打了不必要的电话（接收者已经知道谣言）时，该活跃个体有 1/k 的概率失去分享谣言的兴趣（该个体被移除）。
我们想知道系统收敛到非活跃状态（无人具有传染性的状态）的速度，以及达到此状态时知道谣言（被移除）的人的百分比。

根据流行病学文献，谣言传播可以用一对微分方程来确定性地建模。
我们设 s、i 和 r 分别代表易感、感染和被移除个体的比例，因此 s + i + r = 1：

$$
\begin{aligned}
\frac{ds}{dt} &= -si & \\
\frac{di}{dt} &= +si - \frac{1}{k}(1-s)i
\end{aligned}
$$

(*)

第一个方程表明，根据乘积 si，易感人群将被感染。
第二个方程增加了一个项，表示个人拨打不必要的电话造成的损失。
第三个关于 r 的方程是多余的。

处理像 (*) 这样的方程的标准技巧是使用比率 `[Ba]` 。
这样就消去了 t，让我们求解 i 作为 s 的函数：

$$
\begin{aligned}
\frac{di}{ds} &= - \frac{k+1}{k} + \frac{1}{ks} \\
i(s) &= - \frac{k+1}{k} s + \frac{1}{k} \log s + c
\end{aligned}
$$

其中 c 是积分常数，可由初始条件确定：$i(1- \epsilon) = \epsilon $
当 n 较大时，$\epsilon$ 趋于零，得出：

$$
\begin{aligned}
c = \frac{k+1}{k}
\end{aligned}
$$

以及一个解决方案

$$
\begin{aligned}
i(s)= \frac{k+1}{k} (1-s)+ \frac{1}{k} \log s.
\end{aligned}
$$

此方程中 $i(s)$ 会在当前情况下为 0

$$
\begin{aligned}
s = e^{-(k+1)(1-s)}.
\end{aligned}
$$

这是关于 s 的一个隐式方程，但主要项表明 s 随 k 呈指数下降。
因此，增加 k 是确保几乎每个人都能听到谣言的有效方法。
例如，当 k = 1 时，该公式表明 20% 的人会错过该谣言，而当 k = 2 时，只有 6% 的人会听到。

**变体**

到目前为止，我们只见过一例基于谣言传播技巧的复杂流行病。
总的来说，我们希望了解如何设计一场“良好”的流行病，因此现在值得停下来回顾一下评判流行病的标准。
我们主要关注的是：

1. **残差** 这是当 i 为零时 s 的值，即疫情结束时剩余的易感人群。我们希望残差尽可能小，正如上述分析所示，使残差任意小都是可行的。
2. **流量** 目前，我们正在测量站点之间发送的数据库更新流量，而不考虑网络拓扑结构。使用起来很方便。平均 m，即从典型站点发送的消息数量：

$$
\begin{aligned}
m = \frac{\text{Total update traffic}}{ \text{Number of sites} }
\end{aligned}
$$

在第 3 部分中，我们将完善此指标，以纳入各个链接的流量

3. **延迟** 平均延迟是指更新首次更新的时间与更新到达给定站点的时间之差，取所有站点的平均值。我们将其称为 $t_{ave}$。一个类似的量 $t_{last}$，是指在疫情期间，到最后一个接收更新的站点接收到更新为止的延迟时间。在 $t_{last}$ 之后，更新消息可能会继续出现在网络中，但它们永远不会到达易感的站点。我们发现有必要引入两个时间，因为它们的行为通常不同，而设计者对这两个时间都有合理的担忧。

接下来，我们来探讨几种简单的谣言传播变体。
首先，我们将描述这些变体的实际应用，之后再讨论残差、流量和延迟。

**盲目型(Blind) vs. 响应型(Feedback)** 响应型使用了接收者的反馈；只有当接收者已经知道谣言时，发送者才会失去兴趣。
无论接收者是谁，盲目变体都会以 1/k 的概率失去兴趣。
这消除了接收者需要位向量响应的需要。

**计数型(Counter) vs. 硬币型(Coin)** 计数型的逻辑是只有在进行过 k 次不必要的接触后才会失去兴趣，而不是以 1/k 的概率失去兴趣。
计数型需要为感染列表中的元素保存额外的状态。
注意，我们可以将计数型与盲目型作结合起来，这样即使没有任何反馈，也能在 k 次循环中保持感染性。

上述变化的一个令人惊讶的方面是，它们在流量和残差之间具有相同的基本关系：

$$
\begin{aligned}
s = e^{-m}
\end{aligned}
$$

这一点很容易理解，因为有 nm 个更新被发送，单个站点错过所有更新的概率为 $(1- \frac{1}{n})^{nm}$ 。
（由于 m 不是常数，因此这种关系取决于当 $n \to \infty$ 时，m 分布均值附近的矩趋于零，这是我们通过经验观察到的，但尚未证实。）
延迟是区分上述可能性的唯一考虑因素：模拟表明，计数型和响应型可以改善延迟，其中计数的作用比响应更为显著。

> 表 1. 使用响应型和计数型在 1000 个站点上进行流行病方式模拟的表现。

| Counter $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|-----------------|------------------|-----------------|----------------------------------|------------------------------------|
| 1               | 0.18             | 1.7             | 11.0                             | 16.8                               |
| 2               | 0.037            | 3.3             | 12.1                             | 16.9                               |
| 3               | 0.011            | 4.5             | 12.5                             | 17.4                               |
| 4               | 0.0036           | 5.6             | 12.7                             | 17.5                               |
| 5               | 0.0012           | 6.7             | 12.8                             | 17.7                               |

> 表 2. 使用盲目型和硬币在 1000 个站点进行流行病方式模拟的表现。

| Coin $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|----------|-------------|-------------|----------------------|--------------------|
| 1        | 0.96        | 0.04        | 19                   | 38                 |
| 2        | 0.20        | 1.6         | 17                   | 33                 |
| 3        | 0.060       | 2.8         | 15                   | 32                 |
| 4        | 0.021       | 3.9         | 14.1                 | 32                 |
| 5        | 0.008       | 4.9         | 13.8                 | 32                 |

**Push vs. Pull**
到目前为止，我们假设所有站点都会随机选择目标站点，并将具有感染性的更新推送到这些目标站点。
我们已经对反熵理论做出的 push vs. pull 的区分也适用于谣言传播。
pull 有一些优势，但主要的实际考虑因素是更新注入分布式数据库的速率。
如果存在大量独立更新，pull 请求很可能会找到一个具有非空谣言列表的源，从而触发有用的信息流。
相比之下，如果数据库处于静止状态，push 算法将不再引入流量开销，而 pull 算法则会继续注入无效的更新请求。
我们自己的 CIN 应用程序具有足够高的更新速率，足以保证使用拉取。

pull 策略的主要优势在于，它比 push 策略的 $s=e^{-m}$ 关系表现得更好。
在这里，盲目型与响应行以及计数型与硬币型的变化非常重要。
模拟表明，计数型和反馈型的变化改善了剩余效果，其中计数型比反馈型更重要。
我们有一个递归关系，用于模拟计数型与反馈型的情况，其表现出 $s=e^{- \Theta (m^3)}$ 。

> 表 3. 使用反馈型和计数型在 1000 个站点上执行流行病方式模拟(拉取)的表现。

| Counter $ k $ | Residue $ s $ | Traffic $ m $ | Convergence $ t_{\text{ave}} $ | Convergence $ t_{\text{last}} $ |
|-------------|------------------------|-------------|-----------------------|--------------------|
| 1           | $ 3.1 \times 10^{-2} $ | 2.7         | 9.97                  | 17.6               |
| 2           | $ 5.8 \times 10^{-4} $ | 4.5         | 10.07                 | 15.4               |
| 3           | $ 4.0 \times 10^{-6} $ | 6.1         | 10.08                 | 14.0               |

如果在一个周期内有多个接收者从站点拉取数据，那么在周期结束时对计数器的影响如下：如果有任何接收者需要更新，则计数器将重置；如果所有接收者都不需要更新，则计数器将累加。

**最小残留量(Minimization)** 
也可以利用交换双方的计数器来做出移除决策。
其思路是同时使用推送和拉取操作，如果两个站点都已获知更新，则只有计数器较小的站点才会递增（如果相等，则两个站点都必须递增）。
这需要通过网络发送计数器，但这会导致我们迄今为止看到的最小残留量。

**连接限制(Connection Limit)**
目前尚不清楚连接限制应该被视为难点还是优势。
到目前为止，我们忽略了连接限制。
例如，在推送模式下，我们假设一个站点可以在一个周期内接收多个推送；在拉取模式下，我们假设一个站点可以处理无限数量的请求。
由于我们计划频繁运行谣言传播算法，因此出于现实考虑，我们不得不使用连接限制。
连接限制对推送和拉取机制的影响不同：拉取会显著恶化，而推送则会显著改善，这很矛盾。

为了理解推送效果为何会更好，假设数据库几乎处于静止状态，即只有一个更新正在传播，并且连接数限制为 1。
如果两个站点联系同一个接收者，则其中一个联系会被拒绝。
接收者仍然可以收到更新，但流量单位会减少一个。
（我们选择仅根据发送的更新来衡量流量。
尝试被拒绝的连接时会产生一些网络流量，但这比传输更新所涉及的流量要少。
本质上，我们缩短了原本无用的连接。）
有多少连接被拒绝？
由于发送呈指数级增长，我们假设大部分流量发生在几乎每个人都具有传染性的最后阶段，此时被拒绝的概率接近 
 $e^{-1}$ 。
因此，我们预期带有连接数限制的推送会表现为：

$$
\begin{aligned}
s = e^{- \lambda m} \quad \quad \lambda = \frac{1}{1-e^{-1}}
\end{aligned}
$$

模拟表明，计数型变体最接近这种行为（带反馈的计数型最有效）。
硬币型变体不符合上述假设，因为它们的大部分流量并非发生在几乎所有站点都具有感染性的情况下。
尽管如此，它们仍然比 $s = e^{-m}$ 表现更好。
在所有变体中，由于在几乎静止的网络上推送时，连接限制为 1 时效果最佳，因此即使可以有更多连接，似乎也值得强制执行此限制。

连接数限制会导致拉取性能下降，因为其良好性能依赖于每个站点在每个周期内都作为接收者。
若连接失败概率为 $\delta$ ，拉取性能的渐近线就会发生变化。
假设几乎所有流量都发生在几乎所有站点都处于感染状态时，那么在此活跃期间站点错过更新的概率大致为：

$$
\begin{aligned}
s = \delta ^m = e^{- \lambda m} \quad \quad \lambda = - \ln \delta
\end{aligned}
$$

幸运的是，由于连接限制适中，失败的概率变得非常小，因为一个站点在一个周期内有 j 个连接的概率是 $e^{-1}/j!$ 。

**搜索节点(Hunting)**
如果连接被拒绝，则选择站点可以“搜索”替代站点。
搜索成本相对较低，并且似乎可以改善所有连接受限的情况。
在极端情况下，连接限制为 1，搜索限制为无限，则会导致完全排列。
此时，推和拉变得等价，剩余部分非常小。

#### 1.5 用反熵支持复杂的流行病

我们已经看到，复杂的流行病算法可以在非常低的网络流量下快速传播更新。
不幸的是，复杂的流行病可能会失败；也就是说，感染站点的数量可能会降至零，而某些站点仍然易受感染，这种概率并非为零。
这种情况可以极小地避免；然而，如果发生，系统将处于稳定状态，只有部分站点（而非所有站点）知道更新。
为了消除这种可能性，可以不频繁地运行反熵算法来支持复杂的流行病，就像信息交换中心用它来支持直接发送一样。
这确保每个更新最终都会以概率 1 到达（或被取代）每个站点。

当使用反熵作为备用机制时，使用诸如谣言散播之类的复杂流行方式进行初始更新分发，比使用直接发送进行更新分发具有显著优势。
试想一下，如果两个站点执行反熵时发现缺失更新，应该如何处理。
保守的应对措施是不采取任何措施（当然，除了确保两个站点的数据库一致之外），最终依靠反熵将更新分发到所有站点。
更积极的应对措施是重新分发更新，使用初始分发所使用的任何机制；例如，将其发送到所有其他站点，或使其再次成为热门谣言。
在通常情况下，即除了少数站点之外，所有站点都已知更新的情况下，保守的方法是足够的。
但是，为了应对初始分发偶尔完全失败的情况，重新分发步骤是可取的。

不幸的是，通过直接发送进行重新分发的成本可能非常高昂。
最糟糕的情况是，初始分发成功将更新分发到大约一半的站点，因此在下一个反熵循环中，$O(n)$ 个站点中的每一个都会尝试通过邮寄方式将更新分发到所有 n 个站点，从而生成 $O(n^2)$ 封邮件。
在数据清理处最初实现了重新分发，但由于成本高昂，我们被迫取消了它。

使用谣言传播代替直接发送可以大大降低重新分发的预期成本。
对于只有少数网站未能收到更新的简单情况，谣言传播是理想的选择，因为几乎所有网站都已知的热门谣言会很快消失，而不会产生太多网络流量。
它在上述最坏情况下也表现良好：如果更新分发到大约一半的网站，那么在下一轮反熵中，$O(n)$ 个更新副本将作为热门谣言被引入。
这实际上比在单个网站上引入谣言产生的网络流量更少。

这为我们提供了一种将谣言传播与反熵相结合的有趣方法。
回想一下，我们之前描述过一种名为“剥离”的反熵变体，它需要按时间戳顺序对数据库进行额外的索引。
其想法是让站点按时间戳的逆序交换更新，直到它们就整个数据库的校验和达成一致。
通过将更新保存在双向链表中而不是搜索树中，可以将剥离和谣言传播结合起来。
之前我们需要搜索树来维护时间戳的逆序，而现在我们使用双向链表来维护本地活动顺序：站点根据其本地链表顺序发送更新，并接收常规的谣言反馈，告知它们更新何时有用。
有用的更新会被移至各自链表的前端，而无用的更新则会逐渐在链表中向下移动。
这种组合变体比单独的剥离方法更好，因为： 1) 它避免了额外的索引，2) 在网络分区和重新加入时表现良好。
它比单独的谣言传播更好，因为它没有失败概率。
在实践中，人们可能不会一次发送一个更新，而是从列表头部开始批量发送一系列更新。
这个集合类似于谣言传播中的热门谣言列表，但成员资格不再是二进制的，因为如果第一批更新未能达成校验和一致，则会发送更多批次。
如有必要，数据库中的任何更新都可以再次成为热门谣言。

### 2. 删除和终止证明

无论是使用反熵还是谣言传播，我们都无法通过简单地删除项目的本地副本来从数据库中删除该项目，并期望该项目的消失会传播到其他站点。
恰恰相反：传播机制会将该项目的旧副本从数据库的其他地方传播回我们删除它的站点。
除非我们能够同时从数据库中删除过时项目的所有副本，否则它最终会以这种方式“复活”。

为了解决这个问题，我们用终止证明替换已删除的项目，终止证明带有时间戳，可以像普通数据一样传播。
在传播过程中，当已删除项目的旧副本与终止证明相遇时，旧项目就会被删除。
如果我们保留终止证明的时间足够长，它最终会取消其关联项目的所有旧副本。
不幸的是，这并不能完全解决问题。
我们仍然必须决定何时删除终止证明本身，否则它们最终会耗尽站点上所有可用的存储空间。

一种策略是保留每份终止证明，直到确定所有站点都已收到为止。
Sarin 和 Lynch `[Sa]` 描述了一种用于进行此确定的协议，该协议基于 Chandy 和 Lamport `[Ch]` 的分布式快照算法。
添加和删除站点需要单独的协议（Sarin 和 Lynch 未详细描述站点添加协议）。
如果在创建终止证明和完成分布式快照之间任何站点永久故障，则在运行站点删除协议之前，无法删除该终止证明。
对于包含数百个站点的网络来说，这一点可能非常重要。
根据我们的经验，任何时候都有可能出现某个站点宕机（或无法访问）数小时甚至数天，从而阻止分布式快照或站点删除算法完成。

一种更简单的策略是将终止证明保存一段时间，例如 30 天，然后丢弃。
如上所述，采用这种方案，我们面临着超过阈值的过时项目被重新使用的风险。
用于存储终止证明的空间量和过时项目被重新使用的风险之间存在明显的权衡：提高时间阈值可以降低风险，但会增加终止证明占用的空间量。

#### 2.1 休眠终止证明

有一种分布式方法可以将时间阈值延伸到比任何服务器空间允许的更远的时间。
这个方案，我们称之为休眠终止证明，基于以下观察。
如果终止证明的年龄超过了将其传播到所有站点所需的预期时间，那么网络中任何地方都不太可能存在相应数据项的过时副本。
我们可以在大多数站点删除非常旧的终止证明，只在少数站点保留“休眠”副本。
当过时的更新遇到休眠终止证明时，该终止证明可以被“唤醒”并再次传播到所有站点。
此操作成本高昂，但很少发生。
通过这种方式，我们可以确保，如果终止证明存在于网络中的任何站点，相关数据项的复活不会持续很长时间。
请注意与免疫反应的类比，唤醒的终止证明表现得像抗体。

该实现使用两个阈值：$\tau _1$ 和 $\tau _2$，并将 $\tau$ 个保留站点名称列表附加到每份终止证明。
创建终止证明时，其保留站点是随机选择的。
终止证明的传播机制与普通更新相同。
每台服务器都会保留所有时间戳在当前时间 $\tau _1$ 以内的终止证明。
一旦达到 $\tau _1$，大多数服务器都会删除该终止证明，但终止证明保留站点列表上的每台服务器都会保存一份休眠副本。
当达到 $\tau _1 + \tau _2$ 时，休眠的终止证明将被丢弃。

（为简单起见，我们忽略了站点之间本地时钟的差异。
可以假设时钟同步误差最多为 $\epsilon < < \tau _1$ 。
这对参数没有显著影响。）

由于永久性服务器故障，休眠的终止证明偶尔会丢失。
例如，在一个服务器半衰期后，所有保存特定终止证明休眠副本的服务器都发生故障的概率为 $ 2^{-r} $ 。
可以选择 r 的值，以使该概率足够小。

为了将此方案与使用单个固定阈值 $\tau$ 的方案进行比较，假设删除率随时间保持稳定。
对于相同的空间使用率，假设 $\tau > \tau _1$，我们得到

$$
\begin{aligned}
\tau _2 = (\tau - \tau _1)n/r
\end{aligned}
$$

也就是说，我们可以维护的历史记录量提升了 $O(n)$ 。
在我们现有的系统中，这将使我们能够将有效历史记录从 30 天延长到数年。

初次看，休眠终止证明算法似乎可以无限扩展。
不幸的是，事实并非如此。
问题在于，将新的终止证明传播到所有站点的预期时间（随 n 的增长而增长）最终将超过阈值 $\tau _1$，而该阈值不随 n 的增长而增长。
当传播时间小于 $\tau _1$ 时，很少需要重新激活旧的终止证明；当传播时间超过 $\tau _1$ 时，重新激活旧终止证明的频率会越来越高。
这会给网络带来额外的负载来传播旧的终止证明，从而进一步延长传播时间。
最终的结果是灾难性的故障。
为了避免此类故障，必须选择合适的系统参数，以使预期传播时间低于 $\tau _1$ 。
如上所述，使用反熵算法，新更新在网络中传播所需的时间预计为 $O( \log n)$ 。

#### 2.2 具有休眠终止证明的反熵

如果使用反熵机制分发更新，则休眠的终止证明通常不应在反熵交换期间传播。
然而，每当休眠的终止证明遇到过时的数据项时，该终止证明必须以某种方式被“激活”，因此它会传播到所有站点并取消过时的数据项。


激活终止证明的显而易见的方法是将其时间戳向前设置为当前时钟值。
这种方法在不允许“恢复”已删除数据项的系统中可能是可以接受的。
通常情况下，这是不正确的，因为网络中的某个地方可能存在合法的更新，其时间戳介于终止证明的原始时间戳和修订时间戳之间（例如，恢复已删除数据的更新）。
此类更新会被重新激活的终止证明错误地取消。

为了避免这个问题，我们为每份终止证明存储第二个时间戳，称为激活时间戳。
最初，普通时间戳和激活时间戳相同。
如果终止证明的普通时间戳大于相应数据项的时间戳，则该数据项仍会被取消。
但是，激活时间戳控制着终止证明是否被视为休眠状态以及如何传播。
具体来说，当终止证明的激活时间戳超 $\tau _1$ 时(或被其站点列表中的站点视为休眠状态)，它会被删除；当终止证明的激活时间戳超过 $\tau _1 + \tau _2$ 时，它会被删除；只有当终止证明不处于休眠状态时，它才会通过反熵传播。
要重新激活终止证明，我们将其激活时间戳设置为当前时间，而普通时间戳保持不变。
这达到了预期的效果，即在不取消更多更新的情况下传播重新激活的终止证明。

#### 2.3 利用休眠终止证明散布谣言

如果使用谣言传播来分发更新，上述用于反熵的激活时间戳机制同样有效。
每份终止证明都会被创建为一个活跃的谣言。
最终，它会在网络中传播，并在所有站点变为非活跃状态。
每当休眠的终止证明在某个站点遇到过时的数据项时，就会通过将其激活时间戳设置为当前时间来激活该终止证明。
此外，它会再次成为活跃的谣言。
然后，正常的谣言传播机制会将重新激活的终止证明在整个网络中传播。

### 3. 空间分布

到目前为止，我们一直认为网络成本是一样的，但实际上，向附近站点发送更新的成本远低于向远处站点发送更新的成本。
为了降低通信成本，我们希望我们的协议能够优先考虑附近的站点，但过多的局部偏向性会带来一些弊端。
最简单的方法是从一条线路开始探索这种权衡。

假设数据库站点排列在一个线性网络中，每个站点与其最近邻站点之间只有一个链接。
如果我们仅使用最近邻进行反熵交换，则每个链接每个周期的流量将为 $O(1)$，但传播更新需要 $O(n)$ 个周期。
在另一个极端，如果我们使用均匀随机连接，则连接的平均距离将为 $O(n)$，因此即使收敛时间为 $O(\log n)$，每个链接每个周期的流量也将为 $O(n)$。
通常，假设连接到距离 $d$ 的站点的概率与 $d^{-a}$ 成正比，其中 a 是待确定的参数。
分析表明，每个链接的预期流量为：

$$
T(n) = \begin{cases}
O(n), & a < 1; \\
O(n / \log n), & a = 1; \\
O(n^{2-a}), & 1 < a < 2; \\
O(\log n), & a = 2; \\
O(1), & a > 2.
\end{cases}
$$

$d^{-a}$ 分布的收敛时间更难准确计算。
非正式方程和模拟表明它们遵循相反的模式：对于 $a > 2$，收敛是 $n$ 的多项式，对于 $a < 2$，收敛是 $\log n$ 的多项式。
这强烈建议使用 $d^{-2}$ 分布来在线上传播更新，因为当 $n$ 趋于无穷大时，流量和收敛都会很好地扩展。

现实的网络与上面使用的线性示例几乎没有相似之处（令人惊讶的是，CIN 的一小部分实际上是线性的，但网络的大部分是高度连接的），因此如何推广 $d^{-2}$ 分布并不是显而易见的。
上述推理可以推广到更高维度的站点直线网格，表明良好的收敛性（多项式中的 $\log n$ ），分布紧密至 $d^{-2D}$，其中 D 是网格的维度。
此外，一旦分布为 $d^{-(D+1)}$，流量就会下降到 $O(\log n)$，因此我们拥有更广泛的良好行为区域，但这取决于网格的维度 $D$ 。
这一观察结果促使我们考虑让每个站点根据 $Q_s (d)$ 的函数分布独立地选择连接，其中 $Q_s (d)$ 是距离为 $d$ 时选择尽可能少的 $s$ 站点次通信。
在一个 $D$ 个维度的网格中，$Q_s (d)$ 是 $\Theta (d^D)$ ，所以分布会像是 $1/ Q_s (d)^2$ 等于 $\Theta (d^{-2D})$ 和维度数量无关。
我们推测 $Q_s (d)$ 函数适应网格维度的能力使其在任意网络中都能很好地工作，并且渐近性质使 $1/d Q_s (d)$ 和 $1/ Q_s (d)^2$ 之间的分布具有最佳的缩放行为。
下一节将进一步描述分布选择的实际考虑以及我们对 $1/ Q_s (d)^2$ 的经验。

#### 3.1 空间分布和反熵

我们上文已论证，非均匀空间分布可以显著减少反熵产生的流量，而不会不可接受地增加其收敛时间。
所考虑的网络拓扑结构非常规则：D 维度线性网格。

当我们考虑实际的 CIN 拓扑结构时，使用非均匀分布变得更具吸引力。
具体来说，CIN 包含一些关键链路的集合，例如一对跨大西洋链路，它们是连接欧洲 $n_1$ 个站点和北美 $n_2$ 个站点的唯一路由。
目前 $n_1$ 个站点有几十个，$n_2$ 个站点有几百个。
使用均匀分布，这些跨大西洋链路上每轮反熵计算的预期对话次数为 $2 n_1 n_2 /(n_1 + n_2)$。
这大约是 80 次对话，由两条链路实现。
相比之下，当对所有链路取平均值时，每条链路每周期的预期流量不到 6 次对话。
正是关键链路上令人无法接受的高流量，而不是每条链路的平均流量，使得均匀反熵在我们的系统中使用成本过高。
这一观察最初启发了我们对非均匀空间分布的研究。

为了了解如何减少网络流量，我们使用实际的 CIN 拓扑和许多不同的空间分布对反熵行为进行了广泛的模拟。

初步结果表明，由 $Q_s (d)$ 参数化的分布能够很好地适应网络的“局部维度”，正如第 3 节所述，并且其性能显著优于直接依赖于 $d$ 的分布。
具体而言，$1/ Q_s (d)^2$ 优于 $1/d Q_s (d)$。
使用 $Q_s (d)^{-a}$ 形式的空间分布进行反熵分析的结果非常令人鼓舞。
然而，早期对谣言传播的模拟揭示了使用空间分布时 CIN 拓扑中的一些问题点。

在检验了这些结果之后，我们开发了一类略有不同的分布，这些分布对 $Q_s (d)$ 的突​​然增加不太敏感。
事实证明，这些分布在 CIN 拓扑结构上对反熵和谣言传播都更为有效。
非正式地，让每个站点 s 构建一个按其与 s 的距离排序的其他站点列表，然后根据函数 $f(i)$ 从排序列表中选择反熵交换伙伴。
该函数给出了选择一个站点的概率，该概率是该站点在列表中位置 $i$ 的函数。
对于 $f$ ，我们可以使用均匀线性网络中使用的空间分布函数。
当然，在实际网络中，两个与 s 距离相同（但在列表中位置不同）的站点不应该以不同的概率被选中。
我们可以通过平均选择等距站点的概率来实现这一点；即通过选择距离 $d$ 处的每个站点，其概率成正比于

$$
p(d) = \frac{\sum_{i=Q(d-1)+1}^{Q(d)} f(i)}{Q(d) - Q(d-1)}
$$

令 $f = i^{-a}$，其中 $a$ 为待确定的参数，用积分近似求和，我们得到

$$
p(d) \approx \frac{Q(d - 1)^{-a + 1} - Q(d)^{-a + 1}}{Q(d) - Q(d - 1)}. \tag{3.1.1}
$$


