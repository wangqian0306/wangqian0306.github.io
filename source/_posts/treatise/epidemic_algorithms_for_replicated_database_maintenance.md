---
title: "Epidemic Algorithms For Replicated Database Maintenance 中文翻译版"
date: 2025-02-26 22:26:13
tags:
- "论文"
- "Gossip"
id: epidemic_algorithms_for_replicated_database_maintenance
no_word_count: true
no_toc: false
categories: 大数据
---

## Epidemic Algorithms For Replicated Database Maintenance 中文翻译版

作者：Alan Demers, Mark Gealy, Dan Greene, Carl Hauser, Wes Irish, John Larson, Sue Manning, Scott Shenker, Howard Sturgis, Dan Swinehart, Doug Terry, and Don Woods

[英文原文](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf)

### 摘要

当在多个站点上复制数据库时，保持相互一致性的更新是一个重大问题。本文描述了一些随机的算法来实现分布式的更新和驱动副本的一致性。算法非常简单，只需要底层通讯上一点小小的保证，但它们可以确保每次更新的效果最终都能体现在所有副本中。此算法的耗费和性能可以通过调节随机化步骤的合适的分布来实现。算法与流行病非常相似，阅读流行病学的文献有助于理解它们的行为。其中一种算法已在 Xerox Corporate Internet的 Clearinghouse 服务器中实现，解决了长期存在的高流量和数据库不一致问题。

### 0. 引言

考虑到在一个由数百或数千个站点组成的大型、异构、稍不可靠且变化缓慢的网络中的许多站点复制的数据库，我们研究了实现和维护站点之间一致性的几种方法。
每个数据库更新操作都从某一个站点注入，必须传播到所有其他站点，或者被以后的更新所取代。
只有当所有更新活动都停止并且系统处于静止状态时，这些站点才能变得完全一致。
在另一方面，假设有一个合理的更新频率，在给定某个站点时它上面的数据大多都是当前状态。
这种较为宽松的一致性形式已被证明在实践中非常有用 `[Bi]`。我们的目标是设计一种高效且强大的算法，并随着站点数量的增加而优雅地扩展。

在研究解决此问题的算法时要考虑的重要因素包括：

- 更新传播到所有站点所花费的时间
- 更新所花费的网络流量。理想情况下，网络流量与更新大小和服务器数量成正比，但是某些算法会产生更多流量。

在本文中，我们使用几种扩展更新的策略介绍了分析，仿真结果和实践经验。检查的方法包括：

1. 直接发送(Direct mail)：每个更新都立即从进入站点发送到其他所有站点。这是非常节省时间和理论上效果最好的，但并不完全可靠，因为各个站点并不总是了解所有其他站点，并且有时会丢失报文。

2. 反熵(Anti-entropy)：每个站点通常选择一个随机的其他站点，然后交换数据库中的差异数据。由于反熵及其可靠但是需要检查数据库中的数据内容，所以这种做法不能频繁执行。分析和模拟表明，反熵虽然可靠，但是传播更新的速度要比直接发送慢得多。

3. 谣言传播算法(Rumor mongering)：站点的初始状态是空白的；当站点接收到一个新的更新时会变成 "热点谣言"；当站点持有一个热点谣言，它会周期性的选择一个另外的站点并让另一个站点观测到此次更新；当某个站点试图与太多已经看到它的站点共享热门谣言时，该站点将停止将该谣言视为热点，并保留更新，而不会进一步传播。谣言周期可能比反熵周期更频繁，因为它们在每个站点所需要的资源更少，但是有可能更新不会到达所有站点。

反熵和谣言传播都是流行过程的例子，流行理论[Ba]的结果也适用。尽管我们的目标有所不同，但我们对这些机制的理解极大地受益于现有的流行病学数学理论(我们将对更新的迅速而全面的传播感到满意)。
此外，我们可以自由设计流行病机制，而不必设计现有疾病的模型。
我们采用流行病学文献的术语，并称其为一个愿意与之分享感染性的更新。
如果站点尚未收到更新，则该站点很容易受到攻击；如果某个站点已经收到更新但不再愿意共享该更新，则将其删除。
反熵是一种简单的流行病示例：一个站点总是易受感染的站点。

统一选择合作伙伴会导致相当高的网络流量，这促使我们考虑空间分布，在这种分布中，选择往往有利于附近的服务器。
对 Xerox Corporate Internet 实际拓扑结构的分析和模拟揭示了反熵和谣言传播的分布，这些分布的收敛速度几乎与均匀分布一样快，同时降低了每条链路的平均和最大流量。
产生的反熵算法已安装在 Xerox Corporate Internet 上，并显着提高了性能。

我们应该指出，数据库的大量复制非常昂贵。
应尽可能通过数据库的层次分解或缓存来避免这种情况。
即便如此，我们的论文结果还是很有趣的，因为它们表明可以使用简单的算法在层次结构的每个级别或在缓存方案的主干中实现显着的复制。

> 注：此处的数据库层次分解和数据分层的概念是不同的。前者侧重于数据库内部的组织和优化，后者侧重于软件架构中的数据管理和交互方式。数据库层次分解是将同类数据按照不同需求进行分解，数据分层是将同种数据分配到特定的功能和用途。

### 0.1 动机

本项工作源自我们对于 Xerox Corporate Internet(CIN) 的 Clearinghouse servers `[Op]` 。
全球 CIN 包含数百个通过网关(在CIN上称为互联路由器)和许多不同容量的电话线连接的以太网。
数千台工作站，服务器和计算主机已连接到 CIN。
从日本的一台机器到欧洲的一台机器的数据包可能会经过多达 14 个网关和 7 条电话线。

Clearinghouse servers 维护了三种层级的转化关系，层级名称到机器地址，用户身份等。
层次结构的前两层将命名空间划分为一组域。
每个域可以存储（复制）到最少或全部的 Clearinghouse servers 中，其中有数百个。

几个域实际上是存储在 CIN 中的 Clearinghouse servers 里。
在 1986 年初，网络上许多可观察到的性能问题都可以追溯到，因为维持域的高度复制域的一致性从而产生的流量问题。
随着网络规模的增加，即使只有几台服务器存储的域在更新时的传播也非常缓慢。

当我们初次接近此问题的时候，Clearinghouse servers 正在同时使用直接发送和反熵方法。
反熵在每个域中执行，在理论上来说本地时间每一天的午夜到早上 6 点(每台服务器)。
事实上，由于网络负载过重服务器通常不能按时完整的完成反熵逻辑。

我们的第一个发现是，在发生分歧后，反熵步骤之后会跟着一个重新邮寄的步骤：当两个反熵参与者之前存在不同意见时，正确的数据库值会被发送到所有站点。
更多的站点间不一致会导致更多的通信量。
对于存储在300个站点上的一个域，每晚可能会产生多达90,000封邮件消息。
这远远超出了网络的承载能力，导致所有网络服务（如邮件、文件传输、名称查找等）出现故障。

由于在大规模网络中重新邮寄步骤明显不可行，我们的第一个观察结果是必须禁用这一功能。
进一步的分析表明，仅禁用重新邮寄步骤还不够：网络中的某些关键链接仍会因为反熵通信量而过载。
我们对空间分布和流言传播的探索源于试图进一步减少由 Clearinghouse 更新过程给网络带来的负载。

### 0.2 相关工作


