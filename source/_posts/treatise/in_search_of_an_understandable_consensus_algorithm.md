---
title: In Search of an Understandable Consensus Algorithm 中文翻译
date: 2021-06-24 22:26:13
tags:
- "论文"
- "Raft"
id: in_search_of_an_understandable_consensus_algorithm
no_word_count: true
no_toc: false
categories: 大数据
---

## In Search of an Understandable Consensus Algorithm 中文翻译

作者：Diego Ongaro and John Ousterhout, Stanford University

[英文原文](https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf)

### 引言

Raft 是一种用于管理复制日志的共识算法。
它产生的结果等价于 (multi-)Paxos，和 Paxos 一样高效，但它的结构设计与 Paxos 不同；这使得 Raft 更易于理解，也为构建实用系统提供了更好的基础。
为了增强可理解性，Raft 将共识的关键要素(例如领导节点选举、日志复制和安全性)进行分离，并强制执行更强的一致性以减少必须判断的状态数量。
用户研究的结果表明，Raft 比 Paxos 更容易让学生学习。
Raft 还包括一种用于更改集群成员的新机制，该机制使用重叠多数来保证安全。

### 1 简介 

共识算法允许一组机器作为一个连贯的组进行工作，可以在其某些成员的失效的情况下继续工作。
因此，它们在构建可靠的大型软件系统方面发挥着关键作用。
Paxos `[13, 14]` 在过去十年中主导了共识算法的讨论：大多数共识的实现都是基于 Paxos 或受其影响，而 Paxos 已成为用于教授学生共识的主要工具。

不幸的是，Paxos 非常难以理解，尽管作者多次尝试使其更易于理解。
此外，其架构需要进行复杂的更改才能支持实际系统。
这样做结果是使的系统构建者和学生都在为 Paxos 苦苦挣扎。

在自己研读 Paxos 之后，我们着手寻找一种新的共识算法，可以为系统构建和教育提供更好的基石。
我们的方法非常独特，因为我们的主要目标是可理解性：我们能否为实际系统定义一个共识算法，并以比 Paxos 更容易学习的方式来描述它？
此外，我们希望该算法能够促进对系统构建者至关重要的直觉的成长。
重要的不仅是算法要起作用，而且要清楚它为什么起作用。

这项工作的结果是一种称为 Raft 的共识算法。
在设计 Raft 时，我们应用了特定的技术来提高可理解性，包括分解(Raft 将领导选举、日志复制和安全性分开)和状态空间缩减
(相对于 Paxos，Raft 降低了不确定性的程度以及服务器之间可能不一致的方式)。
对两所大学的 43 名学生进行的用户研究表明，Raft 比 Paxos 更容易理解：
在学习了这两种算法后，其中 33 名学生能够比关于 Paxos 的问题更好地回答有关 Raft 的问题。

Raft 在许多方面类似于现有的共识算法(最值得注意的是，Oki 和 Liskov 的 Viewstamped Replication `[27, 20]`)，但它有几个新颖的特点：

- **强领导**：Raft 使用比其他共识算法更强大的领导形式。例如，日志条目仅从领导节点流向其他服务器。这简化了复制日志的管理，让 Raft 更容易理解。
- **领导选举**：Raft 使用随机计时器来选举领导节点。这仅为任何共识算法已经需要的心跳增加了少量机制，同时简单快速地解决了冲突。
- **成员变更**：Raft 用于更改集群中服务器集的机制使用了一种新的联合共识方法，其中两种不同配置的大多数在转换期间重叠。这允许集群在配置更改期间继续正常运行。

我们相信 Raft 优于 Paxos 和其他共识算法，无论是出于教育目的还是作为实现的基础。
它比其他算法更简单易懂；描述完整，足以满足实际系统的需要；它有几个开源实现，被多家公司使用；其安全特性已得到正式规定和证明；其效率可与其他算法相媲美。

论文的其余部分介绍了复制状态机问题(第 2 节)，讨论了 Paxos 的优缺点(第 3 节)，描述了我们实现可理解性的一般方法(第 4 节)，
介绍了 Raft 共识算法(第 5-7 节)，评估 Raft 性能(第 8 节)，并讨论相关工作(第 9 节)。

### 2 复制状态机

共识算法通常出现在复制状态机的背景下 `[33]`。
在这种方法中，一组服务器上的状态机计算相同状态的相同副本，并且即使某些服务器关闭也可以继续运行。
复制状态机用于解决分布式系统中的各种容错问题。
例如，具有单个集群领导节点的大型系统，如 GFS `[7]`、HDFS `[34]` 和 RAMCloud `[30]`
通常使用单独的复制状态机来管理领导节点选举并存储必须生存的配置信息防止领导崩溃。
复制状态机的例子包括 Chubby `[2]` 和 ZooKeeper `[9]`。

![图 1：复制状态机架构](https://i.loli.net/2021/08/05/V8k2rEI1zJdPiLB.png)

> 注：共识算法管理包含来自客户端的状态机命令的复制日志。状态机处理来自日志的相同命令序列，因此它们产生相同的输出。

复制状态机通常使用复制日志来实现，如图 1 所示。
每个服务器存储一个包含一系列命令的日志，它的状态机按顺序执行这些命令。
每个日志以相同的顺序包含相同的命令，因此每个状态机处理相同的命令序列。
由于状态机是确定性的，每个状态机都计算相同的状态和相同的输出序列。

保持复制日志的一致性是一致性算法的工作。
服务器上的共识模块接收来自客户端的命令并将它们添加到其日志中。
它与其他服务器上的共识模块通信，以确保每个日志最终包含相同顺序的相同请求，即使某些服务器出现故障。
一旦命令被正确复制，每个服务器的状态机就会按日志顺序处理它们，并将输出返回给客户端。
结果，服务器似乎形成了一个单一的、高度可靠的状态机。

实际系统的共识算法通常具有以下特性：

- 它们在所有非拜占庭(non-Byzantine)条件下确保安全(从不返回错误结果)，包括网络延迟、分区和丢包、重复和重新排序。
- 只要任何大多数服务器都可以运行并且可以相互通信以及与客户端通信，它们就具有完整的功能(可用)。因此，一个典型的五台服务器集群可以容忍任意两台服务器的故障。假设服务器因停止而失效：他们稍后可能会从稳定存储的状态中恢复并重新加入集群。
- 它们不依赖于时间来确保日志的一致性：错误的时钟和极端的消息延迟在最坏的情况下会导致可用性问题。
- 在一般情况下，只要集群的大部分响应了一轮远程过程调用，命令就可以完成；少数慢速服务器不会影响整体系统性能。

### 3 Paxos 有什么问题？

在过去的十年中，Leslie Lamport 的 Paxos 协议 `[13]` 几乎成为共识的同义词：它是课程中最常教授的协议，大多数共识的实现都以它为起点。
Paxos 首先定义了一个能够就单个决策达成一致的协议，例如单个复制的日志条目。
我们将这个子集称为单法令 Paxos。
Paxos 然后将这个协议的多个实例组合起来，以促进一系列决策，例如日志(multi-Paxos)。
Paxos 确保安全性和生命监测，并且支持集群成员的更改。
其正确性已被证明，在正常情况下是有效的。

不幸的是，Paxos 有两个明显的缺点。
第一个缺点是 Paxos 异常难以理解。

众所周知，完整的解释 `[13]` 是不透明的。很少有人能够成功地理解它，而且只有付出巨大的努力的情况下才有可能。
因此，有几次尝试用更简单的术语来解释 Paxos `[14, 18, 19]`。
这些解释侧重于单法令子集，但它们仍然具有挑战性。
在 NSDI 2012 对与会者的非正式调查中，我们发现很少有人对 Paxos 感到满意，即使是经验丰富的研究人员也是如此。
我们自己也在与 Paxos 斗争；直到阅读了几个简化的解释并设计了我们自己的替代方案之后，我们才能够理解完整的方案，这个过程花了将近一年的时间。

我们假设 Paxos 的不透明性源于它选择单法令子集作为其基础。
单法令 Paxos 密集而微妙：它分为两个阶段，没有简单直观的解释，不能独立理解。
因此，很难对单法令协议的工作原理产生直觉。
multi-Paxos 的组合规则显着增加了复杂性和微妙性。
我们认为，就多个决策(即日志而不是单个条目)达成共识的整体问题可以用其他更直接、更明显的方式进行分解。

Paxos 的第二个问题是它没有为构建实际实现提供良好的基础。
原因之一是对于 multi-Paxos 没有广泛认可的算法。
Lamport 的描述主要是关于单法令 Paxos；他勾画了多 Paxos 的可能方法，但缺少许多细节。
已经有几次尝试充实和优化 Paxos，例如 `[24]、[35] 和 [11]`，但这些尝试彼此不同，也与 Lamport 的初始设计不同。
Chubby `[4]` 等系统已经实现了类似 Paxos 的算法，但在大多数情况下，它们的细节尚未公开。

此外，Paxos 架构对于构建实用系统来说是一种糟糕的架构；这是单法令分解的另一个结果。
例如，独立选择一组日志条目，然后将它们融合到一个顺序日志中几乎没有什么好处；这只会增加复杂性。
围绕日志设计一个系统会更简单、更有效，其中新条目以受约束的顺序进行追加。
另一个问题是 Paxos 在其核心使用对称的点对点方法(尽管它最终暗示了一种弱领导形式作为性能优化)。
这在一个只做出一个决定的简化世界中是有意义的，但很少有实际系统使用这种方法。
如果必须做出一系列决策，首先选举一个领导节点，然后让领导节点协调决策会更简单、更快捷。

因此，实际系统与 Paxos 几乎没有相似之处。
每个实现都从 Paxos 开始，发现实现它的困难，然后开发出截然不同的架构。
这既费时又容易出错，理解 Paxos 的困难加剧了这个问题。
Paxos 的公式可能是证明其正确性定理的好方法，但实际实现与 Paxos 如此不同，以至于证明没有什么价值。
以下来自 Chubby 实施者的评论是非常典型的：

```text
Paxos 算法的描述与现实世界系统的需求之间存在重大差距。......最终系统将基于未经证实的协议 [4]。
```

由于这些问题，我们得出结论，Paxos 没有为系统构建或教育提供良好的基础。
考虑到共识在大型软件系统中的重要性，我们决定看看是否可以设计一种替代的共识算法，其属性比 Paxos 更好。
Raft 是那个实验的结果。

### 4 设计可理解性

我们在设计 Raft 时有几个目标：
它必须为系统构建提供完整且实用的基础，从而显着减少开发人员所需的设计工作量；
它必须在所有条件下都是安全的，并且在典型的操作条件下可用；
并且它必须对常见操作有效。
但我们最重要的目标——也是最困难的挑战——是可理解性。
这种算法必须能被大部分的受众理解。
此外，必须让受众能够对算法产生直觉，以便系统构建者可以进行在现实世界实现中进行扩展(往往是不可避免的)。

在 Raft 的设计中有很多地方我们不得不在替代方法中进行选择。
在这些情况下，我们根据可理解性评估了备选方案：解释每个备选方案有多难(例如，它的状态空间有多复杂，是否有微妙的含义？)，以及读者完全理解的难易程度，用户了解该方法及其含义吗？

我们认识到这种分析具有高度的主观性；尽管如此，我们还是使用了两种普遍适用的技术。
第一种技术是众所周知的问题分解方法：在可能的情况下，我们将问题分成可以相对独立地解决、解释和理解的单独部分。
例如，在 Raft 中，我们将领导节点选举、日志复制、安全性和成员资格更改进行分离。

我们的第二种方法是通过减少要判断的状态数量来简化状态空间，使系统更加连贯并尽可能消除不确定性。
具体来说，日志是不允许有漏洞的，Raft 限制了日志彼此不一致的方式。
尽管在大多数情况下我们试图消除不确定性，但在某些情况下，不确定性实际上提高了可理解性。
特别是，随机方法引入了不确定性，但它们倾向于通过以类似的方式处理所有可能的选择来减少状态空间(“选择任何一个；无关紧要”)。
我们使用随机化来简化 Raft 领导节点选举算法。

### 5 Raft 共识算法

![图 2：Raft 共识算法的简要总结(不包括成员变更和日志压缩)](https://i.loli.net/2021/08/05/LqwCptXDksYQ6PS.png)

> 注：左上框中的服务器行为被描述为一组独立且重复触发的规则。诸如第 5.2 节之类的部分编号指示讨论特定功能的位置。正式的规范 `[28]` 更准确地描述了算法。

Raft 是一种用于管理第 2 节中描述的形式的复制日志的算法。
图 2 以简明的形式总结了算法以供参考，图 3 列出了算法的关键特性；这些图的元素将在本节的其余部分逐个讨论。

|特性|描述|
|:---:|:---:|
|安全选举|在给定的任期中至多会有一个节点被选举成为领导节点。(第 5.2 节)|
|只做追加的领导节点|领导节点不会重写或者删除条目日志，只会做追加操作。(第 5.3 节)|
|日志匹配|如果两个日志包含具有相同索引和任期号，则日志在给定索引之前的所有条目中都是相同的。(第 5.3 节)|
|领导节点完备|如果在给定的任期内提交了一个日志条目，那么该条目将出现在所有更高编号任期的领导节点的日志中。(第 5.4 节)|
|状态机安全|如果服务器已经通过了一项日志条目到索引对应的状态机上，则其他服务器将永远不会为同一索引通过不同的日志条目。(第 5.4 节)|

> 图 3：Raft 保证这些属性中的每一个在任何时候都是正确的。章节编号指示了每个属性对应描述的所处位置。

Raft 通过首先选举一个杰出的领导节点来实现共识，然后让领导节点完全负责管理复制日志。
领导节点接受来自客户端的日志条目，将它们复制到其他服务器上，并告诉服务器何时将日志条目应用到它们的状态机是安全的。
拥有领导节点简化了复制日志的管理。
例如，领导节点可以在不咨询其他服务器的情况下决定在日志中放置新条目的位置，并且数据以简单的方式从领导节点流向其他服务器。
领导节点可能会失败或与其他服务器断开连接，在这种情况下会选出新的领导节点

鉴于领导节点的实现思路，Raft 将共识问题分解为三个相对独立的子问题，这些子问题将在以下小节中讨论：

- 领导选举：在旧的领导节点故障或下线时，一个新的领导节点必须被选举出来(第 5.2 节)。
- 日志副本：领导节点必须从客户端接收日志条目，并且将它们进行复制并分发到集群中，使得其他节点的日志与领导节点的日志保持一致。
- 安全性：Raft 的关键安全属性是图 3 中的状态机的安全属性：如果任何服务器已将特定日志条目应用于其状态机，则其他服务器不能为相同的日志索引应用不同的命令。5.4 节描述了 Raft 如何保证这个属性；该解决方案涉及对第 5.2 节中描述的选举机制的额外限制。

在介绍了共识算法之后，本节将讨论可用性问题和时序在系统中的作用。

#### 5.1 Raft 基础知识

一个 Raft 集群包含多个服务器；五是一个典型的设置，它允许系统容忍两次故障。
在任何给定时间，每个服务器都处于以下三种状态之一：领导节点、从属节点或候选节点。
在正常操作中，只有一个领导节点，所有其他服务器都是从属节点。
从属节点是被动的：他们不会自己发出请求，而只是回应领导节点和候选节点的请求。
领导节点处理所有客户端请求(如果客户端联系从属节点，则将其重定向到领导节点)。
第三个状态，候选节点，用于选举一个新的领导者，如第 5.2 节所述。
图 4 显示了状态及其转换；下面将讨论这些转换。

![图 4：服务器状态](https://i.loli.net/2021/08/09/ZBwA2WQpxn7GIot.png)

> 注：从属节点只相应来自其他服务的请求，如果从属节点没有收到任何通信，它就会成为候选节点并发起选举。
> 从整个集群的大多数节点中获得选票的候选节点会成为新的领导者，领导者通常会运行到失败为止。

![图 5：时间被切分为任期，选举开始时就产生了一个任期](https://i.loli.net/2021/08/09/ZBwA2WQpxn7GIot.png)

> 注：选举成功后，由一个领导节点管理集群直到任期结束。若选举失败，在这种情况下，任期结束但是没有新的领导者。
> 我们可以在不同的时间和服务器上观测到任期的转换。

Raft 将时间划分为任意长度的任期，如图 5 所示。
任期使用连续整数进行编号。
每个任期都从选举开始，其中一个或多个候选节点尝试成为领导节点，如第 5.2 节所述。
如果一个候选节点赢得了选举，他就会在剩余的任期中持续作为领导节点。
在某些情况下选举会导致分裂投票。
在这种情况下，任期将在没有领导节点的情况下结束；新的任期(新的选举)将很快开始。
Raft 确保在给定的任期内最多有一个领导节点。

不同的服务器可能会在不同的时间观察任期之间的转换，在某些情况下，服务器可能不会观察到选举甚至整个任期。
任期在 Raft 中充当逻辑时钟 `[12]`，它们允许服务器检测过时的信息，例如过时的领导节点。
每个服务器存储一个当前的任期编号，随着时间的推移单调增加。
每当服务器通信时都会交换当前任期；如果一台服务器的当任期小于另一台服务器的当前任期，则它将其当前任期更新为较大的值。
如果候选节点或领导节点发现其任期已过时，它会立即恢复到从属节点状态。
如果服务器收到带有过期任期号的请求，它会拒绝该请求。

Raft 服务器使用远程过程调用(RPC) 进行通信，共识算法只需要两种类型的 RPC。
RequestVote RPC 由候选节点在选举期间发起(第 5.2 节)，而 AppendEntries RPC 由领导节点发起以复制日志条目并提供一种心跳监测的形式(第 5.3 节)。
如果服务器没有及时收到响应，它们会重试 RPC，并且它们并行发出 RPC 以获得最佳性能。

#### 5.2 领导选举

Raft 使用心跳机制来触发领导者选举。
当服务器启动时，它们从跟从属节点开始。
只要服务器从领导节点或候选节点那里接收到有效的 RPC，它就会保持从属节点状态。
领导节点定期向所有从属节点发送心跳(不携带日志条目的 AppendEntries RPC)以维护他们的权限。
如果从属节点在称为选举超时的一段时间内没有收到任何通信，则它假定没有可行的领导节点并开始选举以选择新的领导节点。

要开始选举，从属节点会增加其当前任期并转换到候选状态。
然后它为自己投票并并行地向集群中的每个其他服务器发出 RequestVote RPC。
候选人继续保持这种状态，直到发生以下三件事之一：(a) 赢得选举, (b) 另一个服务器将自己确立为领导节点, (c) 一段时间没有选中的领导节点。
这些结果将在以下段落中单独讨论。

候选节点会在获得集群内众多节点的同样任期的投票之后赢得选举。
每个服务器将在给定的任期内以先到先得的方式投票给至多一个候选节点(注：第 5.4 节增加了对投票的附加限制)。
多数规则确保至多一名候选节点可以赢得特定任期的选举(图 3 中的选举安全属性)。
一旦候选节点赢得选举，它就会变成领导节点。
然后它向所有其他服务器发送心跳消息以建立权限并防止产生新的选举。

在等待投票时，候选节点可能会收到来自另一台声称是领导节点服务器的 AppendEntries RPC。
如果领导节点的任期(包含在其 RPC 中)至少与候选节点的当前任期一样大，则候选节点将领导者视为合法并返回从属节点状态。
如果 RPC 中的任期小于候选节点的当前任期，则候选节点拒绝 RPC 并继续处于候选节点状态。

第三种可能的结果是候选节点既不赢也不输选举：如果许多从属节点同时成为候选节点，可能会分裂选票，从而没有候选节点获得多数票。
发生这种情况时，每个候选节点将超时并通过增加其任期并启动另一轮 RequestVote RPC 来开始新的选举。
然而，如果没有额外的措施，分裂选票可能会无限重复。

Raft 使用随机选举超时来确保分裂选票很少发生并且使它们能被快速解决。
为了首先防止分裂投票，选举超时是从固定间隔(例如，150-300 毫秒)中随机选择的。
这会分散服务器，以便在大多数情况下只有一个服务器会超时；它赢得了选举并在任何其他服务器超时之前发送心跳。
相同的机制用于处理分裂投票。
每个候选节点在选举开始时重新开始其随机选举超时，并在开始下一次选举之前等待该超时过去；这降低了在新选举中再次出现分裂投票的可能性。
8.3 节表明这种方法可以快速选举出一个领导节点。

选举过程只是一个样例，用于使我们更便于理解在设计思路上的取舍。
最初我们计划采用一个排名系统：每个候选节点都会分配一个唯一的排名，便于进行竞选。
如果一个候选节点发现另一个排名更高的候选节点那它会返回从属节点状态，这样排名更高的候选节点可以更轻松的赢得下一次选举。
我们发现这种方法在可用性方面产生了一些微妙的问题(如果排名较高的服务器出现故障，排名较低的服务器可以需要超时并再次成为候选节点，但如果这样做过早，它可以重置选举领导者的进度)。
我们对算法进行了多次调整，但每次调整后都会出现新的极端情况。
最终我们得出结论，随机重试方法更加明显和易于理解。

#### 5.3 日志副本

一旦领导节点被选举出来，它就会开始向客户端提供服务。
每个客户端发送的请求中都会包含一个命令，这个命令会在由复制状态机上执行。
领导节点会将命令追加到日志中并新增一个条目，然后并行触发 AppendEntries RPC 到其他节点，从而新增日志条目副本。
当日志条目被复制写入完成后(如同下面描述的一样)，领导节点就会将日志条目应用于其状态机并将该执行的结果返回给客户端。
如果从属节点崩溃或运行缓慢，或者网络数据包丢失，领导节点会无限期地重试 AppendEntries RPC (即使它已经响应了客户端)，直到所有从属节点最终存储所有日志条目。

![图 6：日志由按顺序编号的条目组成](https://i.loli.net/2021/08/10/mLZFaRUeJHr6tnh.png)

> 注：每个条目包含创建它的任期(每个框中的数字)和状态机的命令。如果该条目可以安全地应用于状态机，则该条目被视为已提交。

日志的组织方式如图 6 所示。
每个日志条目存储一个状态机命令以及领导者收到条目时的任期号。
日志条目中的术语编号用于检测日志之间的不一致并确保图 3 中的某些属性。
每个日志条目还有一个整数索引，用于标识其在日志中的位置。

领导节点决定何时将日志条目应用到状态机是安全的；这样的条目称为已提交。
Raft 保证提交的日志条目是持久的，并且最终会被所有可用的状态机执行。
一旦创建条目的领导者在大多数服务器上复制了它（例如，图 6 中的条目 7），就会提交一个日志条目。
这也会提交领导节点日志中的所有先前条目，包括由以前的领导者创建的条目。
第 5.4 节讨论了在领导节点变更后应用此规则时的一些微妙之处，并且还表明这种承诺的定义是安全的。
领导节点跟踪它知道要提交的最高索引，并将该索引包含在未来的 AppendEntries RPC(包括心跳)中，以便其他服务器最终发现。
一旦从属节点获悉日志条目已提交，它就会将该条目应用于其本地状态机(按日志顺序)。

我们设计了 Raft 日志机制来保持不同服务器上的日志之间的高度一致性。
这不仅简化了系统的行为并使其更具可预测性，而且还是确保安全的重要组成部分。
Raft 维护了以下属性，它们共同构成了图 3 中的日志匹配属性：

- 如果不同日志中的两个条目具有相同的索引和任期，则它们存储相同的命令。
- 如果不同日志中的两个条目具有相同的索引和任期，则日志在所有前面的条目中都是相同的。

第一个属性来自这样一个事实，即领导节点在给定期限内最多创建一个具有给定日志索引的条目，并且日志条目永远不会改变它们在日志中的位置。
第二个属性由 AppendEntries 执行的简单一致性检查保证。
在发送 AppendEntries RPC 时，领导节点在其日志中包含条目的索引和任期，该条目紧接在新条目之前。
如果从属节点在其日志中没有找到具有相同索引和任期的条目，则它拒绝新条目。
一致性检查作为一个归纳步骤：日志的初始空状态满足日志匹配属性，并且一致性检查在日志扩展时保留日志匹配属性。
结果，每当 AppendEntries 成功返回时，领导节点就知道从属节点的日志通过新条目与自己的日志保持同步。

![图 7：当顶部的领导节点选举成功时，任何场景(a-f)都可能发生在从属节点的日志中](https://i.loli.net/2021/08/10/4qAjsvHZGJWeQni.png)

> 注：每个框代表一个日志条目；框中的数字是它的任期。
> 从属节点可能缺少日志条目(a-b)，含有额外未提交的条目(c-d)，或两者都有(e-f)
> 例如：如果该服务器是第 2 任期的领导节点，在其日志中添加了几个条目，然后在提交任何条目之前崩溃，则可能会发生的场景如下(f) 它迅速重启，成为第 3 任期的领导节点，并在其日志中添加了更多的条目；在提交第 2 任期或第 3 任期中的任何条目之前，服务器再次崩溃并保持停机数个任期。

正常运行时，领导节点和从属节点的日志保持一致，因此 AppendEntries 进行的一致性检查永远不会失败。
然而，领导节点崩溃可能会造成日志不一致(旧的领导节点可能没有完全复制它日志中的所有条目)。
这些不一致可能会导致一系列领导节点和从属节点崩溃。
图 7 说明了从属节点日志可能与新领导节点日志不同的方式。
从属节点可能缺失领导节点上存在的日志条目，或可能有领导节点上不存在的额外条目又或者兼而有之。
日志中缺失和无关的条目可能跨越多个任期。

为了使从属节点的日志与自己的一致，领导节点必须找到两个日志一致的最新日志条目，删除该点之后从属节点日志中的任何条目，并将该点之后领导节点的所有条目发送给从属节点。
所有这些操作都是为了响应 AppendEntries RPC 执行的一致性检查而发生的。
领导节点为每个从属节点维护一个 nextIndex，这是领导节点将发送给该从属节点的下一个日志条目的索引。
当领导领导节点第一次选举成功时，它会将所有 nextIndex 值初始化为紧随其后的索引其日志中的最后一个(图 7 中的 11)。
如果一个从属节点的日志与领导节点不一致，则 AppendEntries 一致性检查将在下一次 AppendEntries RPC 中失败。
拒绝后，领导领导节点递减 nextIndex 并重试 AppendEntries RPC。
最终，nextIndex 将达到领导节点和从属节点日志匹配的点。
当这种情况发生时，AppendEntries 将成功，它会删除从属节点日志中的任何冲突条目，并从领导节点的日志中附加条目(如果有的话)。
一旦 AppendEntries 成功，从属节点的日志就会与领导节点的日志一致，并且在接下来的任期内都会保持这种状态。

可以优化协议以减少被拒绝的 AppendEntries RPC 的数量；详情见 `[29]`。

有了这种机制，领导节点在选举成功后不需要采取任何特殊的行动来恢复日志的一致性。
领导节点只需要正常启动，日志会自动进行收敛以响应 AppendEntries 一致性检查的失败。
领导节点永远不会覆盖或删除自己日志中的条目(图 3 中的领导节点仅附加属性)。

这种日志复制机制展示了第 2 节中描述的理想共识属性：只要大多数服务器都启动，Raft 就可以接受、复制和应用新的日志条目；在正常情况下，可以通过一轮 RPC 将新条目复制到集群中的大多数节点；并且单个慢从属节点不会影响整体性能。

#### 5.4 安全性

前面的部分描述了 Raft 如何选举领导节点和复制日志条目。
然而，到目前为止描述的机制还不足以确保每个状态机以相同的顺序执行完全相同的命令。
例如，当领导节点提交多个日志条目时，追随节点可能不可用，然后它可以被选为领导节点并用新的条目覆盖这些条目；因此，不同的状态机可能会执行不同的命令序列。

本节通过添加对哪些服务器可以被选为领导节点的限制来完成 Raft 算法。
该限制确保任何给定任期的领导节点都包含之前任期中提交的所有条目(图 3 中的领导者完整性属性)。
考虑到选举限制，我们然后使承诺规则更加精确。
最后，我们展示了领导节点完整性属性的证明草图，并展示了它如何导致复制状态机的正确行为。

##### 5.4.1 选举限制

在任何基于领导节点的共识算法中，领导节点最终必须存储所有提交的日志条目。
在一些共识算法中，例如 ViewSamped 复制算法 `[20]`，即使它不最初包含所有承载的条目，也可以选择领导节点。
这些算法包含额外的机制来识别丢失的条目并将它们传输给新的领导节点，无论是在选举过程中还是之后不久。
不幸的是，这会导致相当多的额外机制和复杂性。
Raft 使用一种更简单的方法，它保证从选举的那一刻起，每个新领导节点都存在以前任期的所有提交条目，而无需将这些条目传输给领导节点。
这意味着日志条目仅在一个方向上流动，从领导节点到从属节点，领导节点永远不会覆盖其日志中的现有条目。

Raft 使用投票过程来防止候选节点赢得选举，除非其日志包含所有承诺的条目。
候选节点必须联系集群的大多数成员才能当选，这意味着每个提交的条目必须至少出现在其中一个服务器中。
如果候选人的日志至少与该多数中的任何其他日志一样最新(“最新”定义如下)，那么它将保存所有提交的条目。
RequestVote RPC 实现了这个限制：RPC 包含有关候选节点日志的信息，如果从属节点自己的日志比候选节点的日志更新，则从属节点拒绝投票。

Raft 通过比较日志中最后一个条目的索引和任期来确定两个日志中的哪一个是最新的。
如果日志的最后条目具有不同的任期，则具有较晚任期的日志是最新的。
如果日志以相同的任期结束，则以更长的日志为准。

##### 5.4.2 提交以前任期的日志条目

![图 8：一个时间序列，显示了为什么领导者无法使用旧条款的日志条目来确定承诺](https://i.loli.net/2021/08/10/CNWm3xIYE4RoPkB.png)

> 注：在(a)中，S1 是领导节点，部分复制了索引 2 处的日志条目。
> 在(b)中 S1 崩溃；S5 被选为第 3 任期的领导节点，其投票来自 S3、S4 及其本身，并在日志索引 2 处接受不同的条目。
> 在(c)中 S5 崩溃；S1 重新启动，被选举成领导节点，并继续进行日志复制。此时，第 2 项的日志条目已在大多数服务器上复制，但尚未提交。
> 如果 S1 崩溃如 (d) 中，则 S5 可以是选举领导节点(来自 S2，S3 和 S4 的投票)，并从任期 3 中覆盖自己的日志条目。
> 然而，如果 S1 在崩溃之前在大多数服务器上复制了当前任期的条目，如(e)所示，则该条目已提交(S5 无法赢得选举)。
> 此时，日志中的所有先前条目也都已提交。

如第 5.3 节所述，一旦该日志条目存储在大多数服务器上，领导节点就知道其当前任期中的日志条目已提交。
如果领导节点在提交条目之前崩溃，未来的领导节点将尝试完成复制该条目。
然而，领导节点不能立即断定前一任期的条目一旦存储在大多数服务器上就已提交。
图 8 说明了一种情况，旧日志条目存储在大多数服务器上，但仍然可以被未来的领导者覆盖。

为了消除图 8 中的问题，Raft 从不通过计算副本数来提交前几项的日志条目。
通过计算副本数，仅提交来自领导者当前任期的日志条目；一旦以这种方式提交了当前术语中的条目，那么由于日志匹配属性，所有先前的条目都将被间接提交。
在某些情况下，领导节点可以安全地得出一个较旧的日志条目已提交的结论(例如，如果该条目存储在每个服务器上)，但 Raft 为简单起见采取了更保守的方法。

Raft 在提交规则中会产生这种额外的复杂性，因为当领导者从以前的任期复制条目时，日志条目会保留其原始任期号。
在其他共识算法中，如果一个新的领导节点从之前的“任期”中重新复制条目，它必须使用新的“任期号”这样做。
Raft 的方法使推理日志条目变得更容易，因为它们随着时间的推移和跨日志保持相同的术语编号。
此外，与其他算法相比，Raft 中的新领导节点发送的先前任期中的日志条目更少(其他算法必须发送冗余日志条目以重新编号，然后才能提交)。

### 6 



### 附录

#### 图 2 中文翻译

##### 状态 (State)

- 所有服务器上的持久状态

(在响应 RPC 之前更新稳定存储)

|特性|描述|
|:---:|:---:|
|currentTerm|服务器最后知道的任期号(从0开始递增)|
|votedFor|在当前任期内收到选票的候选人ID (如果没有就为 null)|
|log[]|日志条目；每个条目包含状态机的要执行命令和从领导节点处收到时的任期号|

- 所有服务器上的易失性状态

|特性|描述|
|:---:|:---:|
|commitIndex|已知的被提交的最大日志条目的索引值(从0开始递增)|
|lastApplied|被状态机执行的最大日志条目的索引值(从0开始递增)|

- 领导节点上的易失性状态

(选举后重新初始化)

|特性|描述|
|:---:|:---:|
|nextIndex[]|对于每一个服务器，记录需要发给它的下一个日志条目的索引(初始化为领导节点上一条日志的索引值 + 1)|
|matchIndex[]|对于每一个服务器，记录已经复制到该服务器的日志的最高索引值(从 0 开始递增)|

##### 附加内容 RPC (AppendEntries RPC)

此方法由领导节点调用并复制日志条目(第 5.3 节)；也用作心跳信号的传输(第 5.2 节)。

- 参数

|特性|描述|
|:---:|:---:|
|term|领导节点任期号|
|leaderId|领导节点 ID，为了其他服务器能重定向到客户端|
|prevLogIndex|紧接在新条目之前的日志条目的索引|
|prevLogTerm|最新日志之前的日志的 Leader 任期号|
|entries[]|将要存储的日志条目(表示心跳信息时为空，有时会为了效率发送超过一条)|
|leaderCommit|领导节点提交的日志条目索引|

- 结果

|特性|描述|
|:---:|:---:|
|term|目前的任期号，用于领导节点更新自己的任期号|
|success|如果其它服务器包含能够匹配上 prevLogIndex 和 prevLogTerm 的日志时为真|

- 接受者需要实现：

1. 如果 term < currentTerm返回 false(第 5.1 节)
2. 如果在 prevLogIndex 处的日志的任期号与 prevLogTerm 不匹配时，返回 false(第 5.3 节)
3. 如果一条已经存在的日志与新的冲突(index 相同但是任期号 term 不同)，则删除已经存在的日志和它之后所有的日志(第 5.3 节)
4. 添加任何在已有的日志中不存在的条目
5. 如果 leaderCommit > commitIndex，将 commitIndex 设置为 leaderCommit 和最新日志条目索引号中较小的一个

##### 投票请求 RPC (RequestVote RPC)

由候选人调用来收集选票(第 5.2 节)。

- 参数

|特性|描述|
|:---:|:---:|
|term|候选人任期|
|candidateId|要求投票的候选人|
|lastLogIndex|最后存储的候选人日志条目索引(第 5.4 节)|
|lastLogTerm|最后存储的候选人日志条目任期(第 5.4 节)|

- 结果

|特性|描述|
|:---:|:---:|
|term|目前的任期，让候选人可以更新自己|
|voteGranted|若候选人获取到了选票则为 true|

- 接收者要实现的内容

1. 如果任期 < 当前任期则返回 false(第 5.1 节)
2. 如果 votedFor 为 null 或是 CandidateId，并且候选人的日志至少与接收者的日志一样都处于最新，则批准投票(第 5.2 和 5.4 节)

##### 服务器要遵守的规则

所有服务器部分：

- 如果 commitIndex > lastApplied，就提升 lastApplied 然后接受 `log[lastApplied]` 至状态机(第 5.3 节)
- 如果 RPC 请求或相应内容中的 term T > currentTerm：就将 currentTerm = T，并转化为从属节点(第 5.1 节)

从属节点部分：

- 回应来自候选人和领导节点的 RPC 
- 如果选举超时之前没有收到来自当前领导节点的 Append Entries RPC 或候选人的投票请求：转化为候选人

候选人部分：

- 转变为候选人之后开始选举
    - 增加 currentTerm
    - 为自己投票
    - 重置选举定时器
    - 发送 RequestVote RPC 至其他节点
- 如果接收到了大多数节点的投票：转化为领导节点
- 如果接收到了新的领导节点的 AppendEntries RPC：转化为从属节点
- 如果选举超时：重新开始选举

领导节点部分：

- 一旦成为领导节点：向其他所有服务器发送空的 AppendEntries RPC(heartbeat)；在空闲时间重复发送以防止选举超时(第 5.2节)
- 如果收到来自客户端的请求：向本地日志增加条目，在该条目应用到状态机后响应客户端(第 5.3节)
- 如果从属节点最新一次的日志索引(lon index) >= nextIndex：通过 AppendEntries RPC 将 nextIndex 之后的所有日志条目发送出去
  - 如果发送成功：更新从属节点的 nextIndex 和 matchIndex 
  - 如果因为日志不一致导致 AppendEntries 发送失败：递减 nextIndex 然后进行重试
- 如果存在 N 使得 N > commitIndex，大部分 `matchIndex[i] ≥ N`，并且 `log[N].term == currentTerm`: 将 commitIndex 设置为 N(第 5.3 和 5.4 节)

