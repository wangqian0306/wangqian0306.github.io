---
title: "Large-scale cluster management at Google with Borg 中文翻译版"
date: 2021-12-28 22:26:13
tags:
- "论文"
- "Borg"
id: large-scale_cluster_management_at_google_with_borg
no_word_count: true
no_toc: false
categories: 大数据
---

## Large-scale cluster management at Google with Borg 中文翻译版

作者：

Abhishek Verma, Luis Pedrosa, Madhukar Korupolu, David Oppenheimer, Eric Tune, John Wilkes

### 原版的版权说明

```text
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice 
and the full citation the first page. Copyrights for third-party components of this work must be honored.For all other uses,
 contact the owner/author(s).EuroSys’15, April 21–24, 2015, Bordeaux, France.Copyright is held by the owner/author(s).
 ACM 978-1-4503-3238-5/15/04.http://dx.doi.org/10.1145/2741948.2741964
```

### 摘要

Google 的 Borg 系统是一个集群管理器，它在多个集群中运行数十万个作业，来自数千个不同的应用程序，每个集群都有多达数万台机器。

它通过将准入控制、高效任务打包、过度承诺(over-commit)和机器共享与进程级性能隔离相结合来实现高效利用资源。
它支持具有运行时功能的高可用性应用程序，这些功能可以最大限度地缩短故障恢复时间，以及减少相关故障概率的调度策略。
Borg 通过提供声明性的工作规范语言、名称服务集成、实时工作监控以及分析和模拟系统行为的工具来简化其用户的生活。

我们总结了 Borg 系统架构和特征、重要的设计决策、对其某些政策决策的定量分析，以及对从十年的操作经验中吸取的经验教训的定性检验。

### 1 引言

我们内部称为 Borg 的集群管理系统负责接纳、调度、启动、重启和监控 Google 运行的所有应用程序。这篇论文描述了它的工作方式。

Borg 提供了三个主要好处：(1) 隐藏了资源管理和故障处理的细节，因此它的用户可以专注于应用程序开发；(2) 以非常高的可靠性和可用性运行，并支持具有相同功能的应用程序；(3) 让我们有效地在数万台机器上运行工作负载。
Borg 不是第一个解决这些问题的系统，但它是为数不多的以这种规模运作的系统之一，具有这种程度的弹性和完整性。
本文围绕这些主题展开，最后总结了我们在生产环境中运行 Borg 十多年来所做的一系列定性观察。

### 2 用户视角

Borg 的用户是运行 Google 应用程序和服务的 Google 开发人员和系统管理员(站点可靠性工程师或 SRE)。
用户以作业的形式向 Borg 提交他们的工作，每个作业由一个或多个运行相同(二进制)程序的任务组成。
每个作业都在一个 Borg 单元中运行，这是一组作为一个单元进行管理的机器。
本节的其余部分描述了 Borg 用户视图中公开的主要功能。

#### 2.1 工作负载

Borg 单元运行具有两个主要部分的异构工作负载。
第一个是长期运行的服务，它们应该“永远”不停机，并处理短期的延迟敏感请求(几微秒到几百毫秒)。
此类服务用于面向最终用户的产品，例如 Gmail、Google Docs 和网络搜索，以及内部基础设施服务(例如 BigTable)。
第二种是需要几秒钟到几天才能完成的批处理作业；这些对短期业务波动的敏感性要低得多。
工作负载组合因单元而异，这些单元根据主要租户运行不同的应用程序组合(例如，某些单元是批量密集型的)，并且还会随时间变化：
批处理作业大量运行之后我们发现许多面向最终用户的服务中出现了日间使用的模式。
Borg 需要同样好地处理所有这些情况。

可以在 2011 年 5 月的公开可用的长达一个月的跟踪中找到具有代表性的 Borg 工作负载 `[80]`，该跟踪已被广泛分析(例如，`[68]` 和 `[1, 26, 27, 57]`)

在过去几年中，许多应用程序框架都建立在 Borg 之上，包括我们内部的 MapReduce 系统 `[23]`、FlumeJava `[18]`、Millwheel `[3]` 和 Pregel `[59]`。
其中大多数都有一个控制器，用于提交一个主作业和一个或多个工作作业； 前两个扮演与 YARN 的应用程序管理器类似的角色 `[76]`。 
我们的分布式存储系统，例如 GFS `[34]` 及其后继 CFS、Bigtable `[19]` 和 Megastore `[8]`，都在 Borg 上运行。

对于本文，我们将优先级较高的 Borg 工作归类为“生产”(prod)工作，其余归为 “非生产”(non-prod)工作。
大多数长时间运行的服务器作业都是生产工作；大多数批处理作业是非生产的。
在一个有代表性的运行单元中，生产作业分配了大约 70% 的总 CPU 资源和大约 60% 的总 CPU 使用率；它们被分配了大约 55% 的总内存并代表了大约 85% 的总内存使用量。
分配和使用之间的差异将在第 5.5 节中证明他们的重要性。

#### 2.2 集群和运行单元

运行单元中的机器属于单个集群，由连接它们的高性能数据中心规模的网络结构定义。
集群运行在一个数据中心大楼中，一组这样的基础设施构成了一个站点<sup>1</sup>。
一个集群通常承载一个大型单元，可能有一些较小规模的测试或专用单元。
我们努力避免任何单点故障。

> 注 1：每种关系都有一些例外。

排除测试用的运行单元后，我们的通常的运行单元大小约为 10k 台机器；有些要大得多。
运行单元中的机器在许多方面都是异构的：大小(CPU、RAM、磁盘、网络)、处理器类型、性能和功能，例如外部 IP 地址或闪存。
Borg 通过确定在单元中运行任务的位置、分配他们的资源、安装他们的程序和其他依赖项、监控他们的健康状况以及在失败时重新启动他们，将用户与大多数这些差异隔离开来。

#### 2.3 工作和任务

Borg 作业的属性包括它的名称、所有者和它拥有的任务数量。
作业可以有约束来强制其任务在具有特定属性的机器上运行，例如处理器架构、操作系统版本或外部 IP 地址。
约束可以是硬的，也可以是软的； 后者表现为偏好而不是要求。
一项工作的开始的方式可以是到前一项工作完成。一项作业仅在一个运行单元中运行。

每个任务都映射到在机器上的容器中运行的一组 Linux 进程 `[62]`。
绝大多数 Borg 工作负载不在虚拟机(VM)内运行，因为我们不想支付虚拟化成本。
此外，该系统是在我们对处理器进行大量投资的时候设计的，而硬件没有虚拟化支持。

任务也有属性，例如它的资源需求和任务在作业中的索引。
大多数任务属性在作业中的所有任务中都是相同的，但可以被覆盖——例如，提供特定于任务的命令行标志。
每个资源维度(CPU 内核、RAM、磁盘空间、磁盘访问速率、TCP 端口等)都是以细粒度独立指定的； 我们不强加固定大小的桶或槽(参见第 5.4 节)。
Borg 程序是静态链接的，以减少对其运行时环境的依赖，并将其结构化为二进制文件和数据文件的包，其安装由 Borg 编排。

用户通过向 Borg 发出远程过程调用(RPC)来操作作业，最常见的是来自命令行工具、其他 Borg 作业或我们的监控系统(参见第 2.6 节)。
大多数工作描述都是用声明性配置语言 BCL 编写的。
这是 GCL `[12]` 的变体，它生成 protobuf 文件 `[67]`，并扩展了一些 Borg 特定的关键字。
GCL 提供了 lambda 函数来允许计算，应用程序使用这些函数来调整它们的配置以适应它们的环境；成千上万的 BCL 文件都超过 1k 行，我们已经积累了数千万行的 BCL。
Borg 作业配置与 Aurora 配置文件有相似之处 `[6]`。

用户可以通过将新的作业配置推送到 Borg，然后指示 Borg 将任务更新配置来更改正在运行的作业中部分或全部任务的属性。
这是一个轻量级的非原子事务，在直到它关闭(提交)前都可以很容易地撤消。
更新通常以滚动方式完成，并且可以对更新导致的任务中断(重新安排或抢占)的数量施加限制；任何会导致更多中断的更改都会被跳过。

某些任务更新(例如，推送新的二进制文件)将始终需要重新启动任务；一些(例如，增加资源需求或改变约束)可能会使任务不再适合机器，并导致它被停止和重新安排；有些(例如，更改优先级)总是可以在不重新启动或移动任务的情况下完成。

任务可以在被 SIGKILL 抢占之前通过 Unix SIGTERM 信号请求通知，因此它们有时间清理、保存状态、完成任何当前正在执行的请求，并拒绝新的请求。
如果抢占者设置了延迟界限，则实际通知可能会更少。实际上，大约 80% 的时间都会发送通知。

#### 2.4 分配(alloc)

Borg alloc(分配的缩写)是机器上的一组保留资源，可以在其中运行一个或多个任务；无论是否使用，资源都保持分配状态。
Allocs 可用于为未来的任务留出资源，在停止任务和重新启动任务之间保留资源，以及将来自不同作业的任务收集到同一台机器上——例如，一个 web 服务器实例和一个复制保存其 URL 日志从到本地磁盘到分布式文件系统的任务。
alloc 的资源的处理方式与机器的资源类似；在一个内部运行的多个任务共享其资源。如果必须将 alloc 重新定位到另一台机器，则其任务将与它一起重新安排。

一个 alloc 集合就像一个作业：它是一组在多台机器上保留资源的 alloc。
创建 alloc 集合后，可以提交一个或多个作业以在其中运行。为简洁起见，我们通常使用“task”来指代一个 alloc 或顶层任务(一个在 alloc 之外的任务)，使用 “job” 来指代一个作业或 alloc 集合。

#### 2.5 优先级、配额和准入控制

当出现的工作量超过可容纳的量时会发生什么？我们对此的解决方案是优先级和配额。

每个工作都有一个优先级，一个小的正整数。高优先级任务可以以牺牲低优先级任务为代价获得资源，即使这涉及抢占(杀死)后者。
Borg 为不同的用途定义了不重叠的优先级带，包括(按优先级递减的顺序)：监控、生产、批处理和最佳努力(也称为测试或免费)。
对于本文，生产作业是监控和生产环境中的作业。

虽然被抢占的任务通常会被重新安排在运行单元的其他地方，但如果一个高优先级的任务与一个稍低优先级的任务相撞，又与另一个稍低优先级的任务相撞，依此类推，就会发生抢占级联。
为了消除大部分这种情况，我们不允许生产优先级范围内的任务相互抢占。
细粒度的优先级在其他情况下仍然有用——例如，MapReduce 主任务的运行优先级略高于他们控制的工作节点，以提高其可靠性。

优先级表示单元格中正在运行或等待运行的作业的相对重要性。配额用于决定允许调度哪些作业。
配额表示为一段时间(通常为几个月)内给定优先级的资源数量(CPU、RAM、磁盘等)向量。
这些数量指定了用户的作业请求一次可以请求的最大资源量(例如，“从现在到 7 月底，运行单元 xx 中的生产优先级为 20 TiB 的 RAM”)。
配额检查是准入控制的一部分，而不是调度：配额不足的作业在提交后会立即被拒绝。

高优先级配额的成本高于低优先级配额。生产优先配额仅限于单元中可用的实际资源，因此提交符合其配额的生产优先作业的用户可以期望它运行，模碎片和约束。
尽管我们鼓励用户购买的配额不要超过他们需要的数量，但许多用户还是会过度购买，因为当他们的应用程序的用户群增长时，这可以使他们免受未来短缺的影响。
我们通过在较低优先级的超额销售配额来对此做出回应：每个用户在优先级为零的情况下都有一个无限的配额，尽管这通常很难行使，因为资源被超额订阅。
低优先级的作业可能会被接纳但由于资源不足而保持挂起(未安排)。

配额分配在 Borg 之外处理，与我们的物理容量规划密切相关，其结果反映在不同数据中心的配额价格和可用性上。用户作业仅在具有所需优先级的足够配额时才被允许。
配额的使用减少了对显性资源公平(DRF)等政策的需求 `[29, 35, 36, 66]`。

Borg 有一个能力系统，赋予一些用户特殊的权限；例如，允许管理员删除或修改运行单元中的任何作业，或允许用户访问受限内核功能或 Borg 行为，例如禁用其作业的资源估计(参见第 5.5 节)。

#### 2.6 名称服务和监控

创建和放置任务是不够的：服务的客户端和其他系统需要能够找到它们，即使它们被重新定位到新机器上。
为了实现这一点，Borg 为每个包含单元名称、作业名称和任务编号的任务创建了一个稳定的“Borg 名称服务”(BNS)名称。
Borg 使用此名称将任务的主机名和端口写入 Chubby `[14]` 中一致的、高度可用的文件中，我们的 RPC 系统使用它来查找任务端点。
BNS 名称也构成了任务 DNS 名称的基础，因此运行单元 `cc` 中用户 `ubar` 所拥有的作业 `jfoo` 中的第 50 个任务将可以通过 `50.jfoo.ubar.cc.borg.google.com` 访问。
Borg 还会在发生变化时将作业大小和任务健康信息写入 Chubby，因此负载均衡器可以看到将请求路由到哪里。

几乎在 Borg 下运行的每个任务都包含一个内置的 HTTP 服务器，该服务器发布有关任务健康状况和数千个性能指标(例如，RPC 延迟)的信息。
Borg 监控健康检查 URL 并重新启动没有及时响应或返回 HTTP 错误代码的任务。其他数据由仪表板和服务级别目标 (SLO) 违规警报的监控工具跟踪。

名为 Sigma 的服务提供基于 Web 的用户界面 (UI)，用户可以通过该界面检查所有作业、特定运行单元的状态，或深入查看单个作业和任务以检查其资源行为、详细日志、执行历史记录，以及最终的状态。
我们的应用程序会生成大量日志；这些应用会自动轮换以避免磁盘空间不足，并在任务退出后保留一段时间以协助调试。
如果应用程序没有在运行，Borg 提供了一个”为什么等待”的注解，与如何修改作业的资源请求以更好地适应运行单元的指南。
我们发布了可能容易调度的“符合”资源形状的指南。

Borg 在 Infrastore 中记录了所有作业提交和任务事件，以及详细的每个任务资源使用信息，Infrastore 是一个可扩展的只读数据存储，通过 Dremel `[61]` 提供类似 SQL 的交互式界面。
此数据用于基于使用情况的计费、调试作业和系统故障以及长期容量规划。它还提供了 Google 集群工作负载跟踪的数据 `[80]`。

所有这些功能都可以帮助用户了解和调试 Borg 及其作业的行为，并帮助我们的 SRE 管理每人数万台机器。

### 3 Borg 的架构设计

![图 1：Borg 的高层架构。仅显示了数千个工作节点中的一小部分。](https://s2.loli.net/2021/12/28/i3jJ1DE2woGRkm7.png)

Borg 单元由一组机器、一个称为 Borgmaster 的逻辑集中控制器和一个称为 Borglet 的代理进程组成，该代理进程在单元中的每台机器上运行(参见图 1)。Borg 的所有组件都是用 C++ 编写的。

#### 3.1 Borgmaster

每个运行单元的 Borgmaster 由两个进程组成：主 Borgmaster 进程和一个单独的调度程序(参见第 3.2 节)。
主 Borgmaster 进程处理客户端 RPC，这些 RPC 要么改变状态(例如，创建作业)，要么提供对数据的只读访问(例如，查找作业)。
它还管理系统中所有对象(机器、任务、alloc 等)的状态机，与 Borglet 通信，并提供 Web UI 作为 Sigma 的备份。

Borgmaster 在逻辑上是一个单一的进程，但实际上被复制了五次。
每个副本都维护了大部分单元状态的内存副本，并且该状态也记录在副本本地磁盘上的高可用、分布式、基于 Paxos `[55]` 的存储中。
每个运行单元选出的单个 master 既充当 Paxos 的领导节点又充当状态修改器，处理所有改变运行单元状态的操作，例如提交作业或终止机器上的任务。
当运行单元被启动时以及当被选举的 master 失效时，一个 master 会被选举(使用 Paxos)；它会获取一个 Chubby 锁，以便其他系统可以找到它。
选举一个 master 并故障转移到新的 master 通常需要大约 10 秒，但在大的运行单元中可能需要长达一分钟的时间，因为必须重建一些内存中的状态。
当一个副本从中断中恢复时，它会从其他最新的 Paxos 副本动态地重新同步它的状态。

Borgmaster 在某个时间点的状态称为检查点，它采用定期快照和保存在 Paxos 存储中的更改日志的形式。
检查点有很多用途，包括将 Borgmaster 的状态恢复到过去的任意点(例如，就在接受触发 Borg 中软件缺陷的请求之前，以便对其进行调试)；在极端情况下手动修复；
为未来的查询建立一个持久的事件日志；和模拟离线情况。

一个名为 Fauxmaster 的高保真 Borgmaster 模拟器可用于读取检查点文件，并包含生产 Borgmaster 代码的完整副本，以及 Borglet 的存根接口。
它接受 RPC 以进行状态机更改并执行操作，例如“调度所有挂起的任务”，我们使用它来调试故障，方法是与它进行交互，就好像它是一个实时的 Borgmaster，模拟 Borglet 重放来自检查点文件的真实交互。
用户可以单步执行并观察过去实际发生的系统状态的变化。
Fauxmaster 还可用于容量规划(“这种类型的新工作有多少适合？”)，以及在对单元配置进行更改之前的健全性检查(“此更改会驱逐任何重要工作吗？”)

#### 3.2 定时任务


