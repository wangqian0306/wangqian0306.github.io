---
title: "Large-scale cluster management at Google with Borg 中文翻译版"
date: 2021-12-28 22:26:13
tags:
- "论文"
- "Borg"
id: large-scale_cluster_management_at_google_with_borg
no_word_count: true
no_toc: false
categories: 大数据
---

## Large-scale cluster management at Google with Borg 中文翻译版

作者：

Abhishek Verma, Luis Pedrosa, Madhukar Korupolu, David Oppenheimer, Eric Tune, John Wilkes

### 原版的版权说明

```text
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without 
fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice 
and the full citation the first page. Copyrights for third-party components of this work must be honored.For all other uses,
 contact the owner/author(s).EuroSys’15, April 21–24, 2015, Bordeaux, France.Copyright is held by the owner/author(s).
 ACM 978-1-4503-3238-5/15/04.http://dx.doi.org/10.1145/2741948.2741964
```

### 摘要

Google 的 Borg 系统是一个集群管理器，它在多个集群中运行数十万个作业，来自数千个不同的应用程序，每个集群都有多达数万台机器。

它通过将准入控制、高效任务打包、过度承诺(over-commit)和机器共享与进程级性能隔离相结合来实现高效利用资源。
它支持具有运行时功能的高可用性应用程序，这些功能可以最大限度地缩短故障恢复时间，以及减少相关故障概率的调度策略。
Borg 通过提供声明性的工作规范语言、名称服务集成、实时工作监控以及分析和模拟系统行为的工具来简化其用户的生活。

我们总结了 Borg 系统架构和特征、重要的设计决策、对其某些政策决策的定量分析，以及对从十年的操作经验中吸取的经验教训的定性检验。

### 1 引言

我们内部称为 Borg 的集群管理系统负责接纳、调度、启动、重启和监控 Google 运行的所有应用程序。这篇论文描述了它的工作方式。

Borg 提供了三个主要好处：(1) 隐藏了资源管理和故障处理的细节，因此它的用户可以专注于应用程序开发；(2) 以非常高的可靠性和可用性运行，并支持具有相同功能的应用程序；(3) 让我们有效地在数万台机器上运行工作负载。
Borg 不是第一个解决这些问题的系统，但它是为数不多的以这种规模运作的系统之一，具有这种程度的弹性和完整性。
本文围绕这些主题展开，最后总结了我们在生产环境中运行 Borg 十多年来所做的一系列定性观察。

### 2 用户视角

Borg 的用户是运行 Google 应用程序和服务的 Google 开发人员和系统管理员(站点可靠性工程师或 SRE)。
用户以作业的形式向 Borg 提交他们的工作，每个作业由一个或多个运行相同(二进制)程序的任务组成。
每个作业都在一个 Borg 单元中运行，这是一组作为一个单元进行管理的机器。
本节的其余部分描述了 Borg 用户视图中公开的主要功能。

#### 2.1 工作负载

Borg 单元运行具有两个主要部分的异构工作负载。
第一个是长期运行的服务，它们应该“永远”不停机，并处理短期的延迟敏感请求(几微秒到几百毫秒)。
此类服务用于面向最终用户的产品，例如 Gmail、Google Docs 和网络搜索，以及内部基础设施服务(例如 BigTable)。
第二种是需要几秒钟到几天才能完成的批处理作业；这些对短期业务波动的敏感性要低得多。
工作负载组合因单元而异，这些单元根据主要租户运行不同的应用程序组合(例如，某些单元是批量密集型的)，并且还会随时间变化：
批处理作业大量运行之后我们发现许多面向最终用户的服务中出现了日间使用的模式。
Borg 需要同样好地处理所有这些情况。

可以在 2011 年 5 月的公开可用的长达一个月的跟踪中找到具有代表性的 Borg 工作负载 `[80]`，该跟踪已被广泛分析(例如，`[68]` 和 `[1, 26, 27, 57]`)

在过去几年中，许多应用程序框架都建立在 Borg 之上，包括我们内部的 MapReduce 系统 `[23]`、FlumeJava `[18]`、Millwheel `[3]` 和 Pregel `[59]`。
其中大多数都有一个控制器，用于提交一个主作业和一个或多个工作作业； 前两个扮演与 YARN 的应用程序管理器类似的角色 `[76]`。 
我们的分布式存储系统，例如 GFS `[34]` 及其后继 CFS、Bigtable `[19]` 和 Megastore `[8]`，都在 Borg 上运行。

对于本文，我们将优先级较高的 Borg 工作归类为“生产”(prod)工作，其余归为 “非生产”(non-prod)工作。
大多数长时间运行的服务器作业都是生产工作；大多数批处理作业是非生产的。
在一个有代表性的运行单元中，生产作业分配了大约 70% 的总 CPU 资源和大约 60% 的总 CPU 使用率；它们被分配了大约 55% 的总内存并代表了大约 85% 的总内存使用量。
分配和使用之间的差异将在第 5.5 节中证明他们的重要性。

#### 2.2 集群和运行单元

运行单元中的机器属于单个集群，由连接它们的高性能数据中心规模的网络结构定义。
集群运行在一个数据中心大楼中，一组这样的基础设施构成了一个站点<sup>1</sup>。
一个集群通常承载一个大型单元，可能有一些较小规模的测试或专用单元。
我们努力避免任何单点故障。

> 注 1：每种关系都有一些例外。

排除测试用的运行单元后，我们的通常的运行单元大小约为 10k 台机器；有些要大得多。
运行单元中的机器在许多方面都是异构的：大小(CPU、RAM、磁盘、网络)、处理器类型、性能和功能，例如外部 IP 地址或闪存。
Borg 通过确定在单元中运行任务的位置、分配他们的资源、安装他们的程序和其他依赖项、监控他们的健康状况以及在失败时重新启动他们，将用户与大多数这些差异隔离开来。

#### 2.3 工作和任务

Borg 作业的属性包括它的名称、所有者和它拥有的任务数量。
作业可以有约束来强制其任务在具有特定属性的机器上运行，例如处理器架构、操作系统版本或外部 IP 地址。
约束可以是硬的，也可以是软的； 后者表现为偏好而不是要求。
一项工作的开始的方式可以是到前一项工作完成。一项作业仅在一个运行单元中运行。

每个任务都映射到在机器上的容器中运行的一组 Linux 进程 `[62]`。
绝大多数 Borg 工作负载不在虚拟机(VM)内运行，因为我们不想支付虚拟化成本。
此外，该系统是在我们对处理器进行大量投资的时候设计的，而硬件没有虚拟化支持。

任务也有属性，例如它的资源需求和任务在作业中的索引。
大多数任务属性在作业中的所有任务中都是相同的，但可以被覆盖——例如，提供特定于任务的命令行标志。
每个资源维度(CPU 内核、RAM、磁盘空间、磁盘访问速率、TCP 端口等)都是以细粒度独立指定的； 我们不强加固定大小的桶或槽(参见第 5.4 节)。
Borg 程序是静态链接的，以减少对其运行时环境的依赖，并将其结构化为二进制文件和数据文件的包，其安装由 Borg 编排。

用户通过向 Borg 发出远程过程调用(RPC)来操作作业，最常见的是来自命令行工具、其他 Borg 作业或我们的监控系统(参见第 2.6 节)。
大多数工作描述都是用声明性配置语言 BCL 编写的。
这是 GCL `[12]` 的变体，它生成 protobuf 文件 `[67]`，并扩展了一些 Borg 特定的关键字。
GCL 提供了 lambda 函数来允许计算，应用程序使用这些函数来调整它们的配置以适应它们的环境；成千上万的 BCL 文件都超过 1k 行，我们已经积累了数千万行的 BCL。
Borg 作业配置与 Aurora 配置文件有相似之处 `[6]`。

![图 2：作业和任务的状态图。用户可以触发提交、终止和更新操作。](https://s2.loli.net/2021/12/29/Gn6J9qwK3hLmUst.png)

图 2 说明了作业和任务在其生命周期中经历的状态。

用户可以通过将新的作业配置推送到 Borg，然后指示 Borg 将任务更新配置来更改正在运行的作业中部分或全部任务的属性。
这是一个轻量级的非原子事务，在直到它关闭(提交)前都可以很容易地撤消。
更新通常以滚动方式完成，并且可以对更新导致的任务中断(重新安排或抢占)的数量施加限制；任何会导致更多中断的更改都会被跳过。

某些任务更新(例如，推送新的二进制文件)将始终需要重新启动任务；一些(例如，增加资源需求或改变约束)可能会使任务不再适合机器，并导致它被停止和重新安排；有些(例如，更改优先级)总是可以在不重新启动或移动任务的情况下完成。

任务可以在被 SIGKILL 抢占之前通过 Unix SIGTERM 信号请求通知，因此它们有时间清理、保存状态、完成任何当前正在执行的请求，并拒绝新的请求。
如果抢占者设置了延迟界限，则实际通知可能会更少。实际上，大约 80% 的时间都会发送通知。

#### 2.4 分配(alloc)

Borg alloc(分配的缩写)是机器上的一组保留资源，可以在其中运行一个或多个任务；无论是否使用，资源都保持分配状态。
Allocs 可用于为未来的任务留出资源，在停止任务和重新启动任务之间保留资源，以及将来自不同作业的任务收集到同一台机器上——例如，一个 web 服务器实例和一个复制保存其 URL 日志从到本地磁盘到分布式文件系统的任务。
alloc 的资源的处理方式与机器的资源类似；在一个内部运行的多个任务共享其资源。如果必须将 alloc 重新定位到另一台机器，则其任务将与它一起重新安排。

一个 alloc 集合就像一个作业：它是一组在多台机器上保留资源的 alloc。
创建 alloc 集合后，可以提交一个或多个作业以在其中运行。为简洁起见，我们通常使用“task”来指代一个 alloc 或顶层任务(一个在 alloc 之外的任务)，使用 “job” 来指代一个作业或 alloc 集合。

#### 2.5 优先级、配额和准入控制

当出现的工作量超过可容纳的量时会发生什么？我们对此的解决方案是优先级和配额。

每个工作都有一个优先级，一个小的正整数。高优先级任务可以以牺牲低优先级任务为代价获得资源，即使这涉及抢占(杀死)后者。
Borg 为不同的用途定义了不重叠的优先级带，包括(按优先级递减的顺序)：监控、生产、批处理和最佳努力(也称为测试或免费)。
对于本文，生产作业是监控和生产环境中的作业。

虽然被抢占的任务通常会被重新安排在运行单元的其他地方，但如果一个高优先级的任务与一个稍低优先级的任务相撞，又与另一个稍低优先级的任务相撞，依此类推，就会发生抢占级联。
为了消除大部分这种情况，我们不允许生产优先级范围内的任务相互抢占。
细粒度的优先级在其他情况下仍然有用——例如，MapReduce 主任务的运行优先级略高于他们控制的工作节点，以提高其可靠性。

优先级表示单元格中正在运行或等待运行的作业的相对重要性。配额用于决定允许调度哪些作业。
配额表示为一段时间(通常为几个月)内给定优先级的资源数量(CPU、RAM、磁盘等)向量。
这些数量指定了用户的作业请求一次可以请求的最大资源量(例如，“从现在到 7 月底，运行单元 xx 中的生产优先级为 20 TiB 的 RAM”)。
配额检查是准入控制的一部分，而不是调度：配额不足的作业在提交后会立即被拒绝。

高优先级配额的成本高于低优先级配额。生产优先配额仅限于单元中可用的实际资源，因此提交符合其配额的生产优先作业的用户可以期望它运行，模碎片和约束。
尽管我们鼓励用户购买的配额不要超过他们需要的数量，但许多用户还是会过度购买，因为当他们的应用程序的用户群增长时，这可以使他们免受未来短缺的影响。
我们通过在较低优先级的超额销售配额来对此做出回应：每个用户在优先级为零的情况下都有一个无限的配额，尽管这通常很难行使，因为资源被超额订阅。
低优先级的作业可能会被接纳但由于资源不足而保持挂起(未安排)。

配额分配在 Borg 之外处理，与我们的物理容量规划密切相关，其结果反映在不同数据中心的配额价格和可用性上。用户作业仅在具有所需优先级的足够配额时才被允许。
配额的使用减少了对显性资源公平(DRF)等政策的需求 `[29, 35, 36, 66]`。

Borg 有一个能力系统，赋予一些用户特殊的权限；例如，允许管理员删除或修改运行单元中的任何作业，或允许用户访问受限内核功能或 Borg 行为，例如禁用其作业的资源估计(参见第 5.5 节)。

#### 2.6 名称服务和监控

创建和放置任务是不够的：服务的客户端和其他系统需要能够找到它们，即使它们被重新定位到新机器上。
为了实现这一点，Borg 为每个包含单元名称、作业名称和任务编号的任务创建了一个稳定的“Borg 名称服务”(BNS)名称。
Borg 使用此名称将任务的主机名和端口写入 Chubby `[14]` 中一致的、高度可用的文件中，我们的 RPC 系统使用它来查找任务端点。
BNS 名称也构成了任务 DNS 名称的基础，因此运行单元 `cc` 中用户 `ubar` 所拥有的作业 `jfoo` 中的第 50 个任务将可以通过 `50.jfoo.ubar.cc.borg.google.com` 访问。
Borg 还会在发生变化时将作业大小和任务健康信息写入 Chubby，因此负载均衡器可以看到将请求路由到哪里。

几乎在 Borg 下运行的每个任务都包含一个内置的 HTTP 服务器，该服务器发布有关任务健康状况和数千个性能指标(例如，RPC 延迟)的信息。
Borg 监控健康检查 URL 并重新启动没有及时响应或返回 HTTP 错误代码的任务。其他数据由仪表板和服务级别目标 (SLO) 违规警报的监控工具跟踪。

名为 Sigma 的服务提供基于 Web 的用户界面 (UI)，用户可以通过该界面检查所有作业、特定运行单元的状态，或深入查看单个作业和任务以检查其资源行为、详细日志、执行历史记录，以及最终的状态。
我们的应用程序会生成大量日志；这些应用会自动轮换以避免磁盘空间不足，并在任务退出后保留一段时间以协助调试。
如果应用程序没有在运行，Borg 提供了一个”为什么等待”的注解，与如何修改作业的资源请求以更好地适应运行单元的指南。
我们发布了可能容易调度的“符合”资源形状的指南。

Borg 在 Infrastore 中记录了所有作业提交和任务事件，以及详细的每个任务资源使用信息，Infrastore 是一个可扩展的只读数据存储，通过 Dremel `[61]` 提供类似 SQL 的交互式界面。
此数据用于基于使用情况的计费、调试作业和系统故障以及长期容量规划。它还提供了 Google 集群工作负载跟踪的数据 `[80]`。

所有这些功能都可以帮助用户了解和调试 Borg 及其作业的行为，并帮助我们的 SRE 管理每人数万台机器。

### 3 Borg 的架构设计

![图 1：Borg 的高层架构。仅显示了数千个工作节点中的一小部分。](https://s2.loli.net/2021/12/28/i3jJ1DE2woGRkm7.png)

Borg 单元由一组机器、一个称为 Borgmaster 的逻辑集中控制器和一个称为 Borglet 的代理进程组成，该代理进程在单元中的每台机器上运行(参见图 1)。Borg 的所有组件都是用 C++ 编写的。

#### 3.1 Borgmaster

每个运行单元的 Borgmaster 由两个进程组成：主 Borgmaster 进程和一个单独的调度程序(参见第 3.2 节)。
主 Borgmaster 进程处理客户端 RPC，这些 RPC 要么改变状态(例如，创建作业)，要么提供对数据的只读访问(例如，查找作业)。
它还管理系统中所有对象(机器、任务、alloc 等)的状态机，与 Borglet 通信，并提供 Web UI 作为 Sigma 的备份。

Borgmaster 在逻辑上是一个单一的进程，但实际上被复制了五次。
每个副本都维护了大部分单元状态的内存副本，并且该状态也记录在副本本地磁盘上的高可用、分布式、基于 Paxos `[55]` 的存储中。
每个运行单元选出的单个 master 既充当 Paxos 的领导节点又充当状态修改器，处理所有改变运行单元状态的操作，例如提交作业或终止机器上的任务。
当运行单元被启动时以及当被选举的 master 失效时，一个 master 会被选举(使用 Paxos)；它会获取一个 Chubby 锁，以便其他系统可以找到它。
选举一个 master 并故障转移到新的 master 通常需要大约 10 秒，但在大的运行单元中可能需要长达一分钟的时间，因为必须重建一些内存中的状态。
当一个副本从中断中恢复时，它会从其他最新的 Paxos 副本动态地重新同步它的状态。

Borgmaster 在某个时间点的状态称为检查点，它采用定期快照和保存在 Paxos 存储中的更改日志的形式。
检查点有很多用途，包括将 Borgmaster 的状态恢复到过去的任意点(例如，就在接受触发 Borg 中软件缺陷的请求之前，以便对其进行调试)；在极端情况下手动修复；
为未来的查询建立一个持久的事件日志；和模拟离线情况。

一个名为 Fauxmaster 的高保真 Borgmaster 模拟器可用于读取检查点文件，并包含生产 Borgmaster 代码的完整副本，以及 Borglet 的存根接口。
它接受 RPC 以进行状态机更改并执行操作，例如“调度所有挂起的任务”，我们使用它来调试故障，方法是与它进行交互，就好像它是一个实时的 Borgmaster，模拟 Borglet 重放来自检查点文件的真实交互。
用户可以单步执行并观察过去实际发生的系统状态的变化。
Fauxmaster 还可用于容量规划(“这种类型的新工作有多少适合？”)，以及在对单元配置进行更改之前的健全性检查(“此更改会驱逐任何重要工作吗？”)

#### 3.2 定时任务

当一个作业被提交时，Borgmaster 将它持久地记录在 Paxos 存储中，并将作业的任务添加到待处理队列中。
调度程序会异步扫描它们，如果有足够的可用资源满足作业的约束，调度程序就会将任务分配给机器。(调度程序主要对任务(task)进行操作，而不是作业(job)。)
扫描从高优先级到低优先级进行，由优先级内的循环方案调制，以确保用户之间的公平性并避免大型作业背后的队头阻塞。
调度算法有两部分：可行性检查，寻找可以运行任务的机器，以及评分，选择一台可行的机器。

在可行性检查中，调度程序会找到一组满足任务约束条件并具有足够“可用”资源的机器——包括分配给可以被驱逐的低优先级任务的资源。
在评分时，调度器确定每个可行机器的“优点”。
该分数考虑了用户指定的偏好，但主要由内置标准驱动，例如最小化被抢占任务的数量和优先级、挑选已经拥有任务包副本的机器、跨电源域和故障域传播任务，以及打包质量(将高优先级和低优先级任务混合到一台机器上，以允许高优先级任务在负载高峰时扩展)。

Borg 最初使用 E-PVM `[4]` 的变体进行评分，它在异构资源中生成单一成本值，并在放置任务时最小化成本的变化。 在实践中，E-PVM 最终将负载分散到所有机器上，为负载峰值留出空间——但以增加碎片为代价，特别是对于需要大部分机器的大型任务；我们有时称其为“最糟糕的选择”。

频谱的另一端是“最佳拟合”，它试图尽可能紧密地填充机器。
这使得一些机器没有用户作业(它们仍然运行存储服务器)，因此放置大型任务很简单，但紧密包装会惩罚用户或 Borg 对资源需求的任何错误估计。
这会损害具有突发负载的应用程序，对于指定低 CPU 需求的批处理作业尤其不利，因此它们可以轻松调度并尝试在未使用的资源中机会性地运行：20% 的非生产任务请求少于 0.1 个 CPU 内核。

我们当前的评分模型是一种混合模型，它试图减少闲置资源的数量——因为机器上的另一个资源已完全分配而无法使用。
与最适合我们的工作负载相比，它提供了大约 3-5% 的打包效率(在 `[78]` 中定义)。

如果评分阶段选择的机器没有足够的可用资源来适应新任务，Borg 会抢占(杀死)较低优先级的任务，从最低到最高优先级，直到它完成。
我们将被抢占的任务添加到调度程序的支出队列中，而不是迁移或休眠它们。

任务启动延迟(从作业提交到任务运行的时间)是一个已经受到并将继续受到显着关注的区域。它是高度可变的，中位数通常约为 25 秒。
软件包安装约占总数的 80%：已知瓶颈之一是对写入软件包的本地磁盘的争用。
为了减少任务启动时间，调度程序更喜欢将任务分配给已经安装了必要包(程序和数据)的机器：大多数包是不可变的，因此可以共享和缓存。
(这是 Borg 调度器支持的唯一数据本地形式。)
此外，Borg 使用类似树和 torrent 的协议将包并行分发到机器。

此外，调度程序使用多种技术让它扩展到拥有数万台机器的单元(第 3.4 节)。

#### 3.4 Borglet

Borglet 是一个本地 Borg 代理，存在于运行单元中的每台机器上。
它负责启动和停止任务；如果发生故障，则重新启动它们；通过对操作系统内核的设置来管理本地资源；滚动调试日志；并将机器状态报告给 Borgmaster 和其他监控系统。

Borgmaster 每隔几秒钟轮询每个 Borglet 以检索机器的当前状态并向其发送任何未完成的请求。
这使 Borgmaster 可以控制通信速率，避免需要明确的流量控制机制，并防止恢复风暴 `[9]`。

选定的主节点负责准备要发送给 Borglet 的消息，并用它们的响应更新运行单元的状态。
为了性能的可扩展性，每个 Borgmaster 副本运行一个无状态链接分片来处理与一些 Borglet 的通信；每当 Borgmaster 选举发生时，就会重新计算分区。
为了弹性，Borglet 始终报告其完整状态，但链接分片通过仅向状态机报告差异来聚合和压缩此信息，以减少所选主节点的更新负载。

如果 Borglet 没有响应多个轮询消息，它的机器将被标记为停机，并且它正在运行的任何任务都将重新安排在其他机器上。
如果通信恢复，Borgmaster 会告诉 Borglet 终止那些已重新安排的任务，以避免重复。
即使 Borglet 与 Borgmaster 失去联系，它也会继续正常运行，因此即使所有 Borgmaster 副本都失败，当前正在运行的任务和服务也会保持正常运行。

#### 3.4 可伸缩性

我们不确定 Borg 中心化架构的最终可伸缩性的限制从何而来；到目前为止，每次我们接近极限时，我们都设法消除了它。
一个 Borgmaster 可以在一个运行单元中管理数千台机器，并且几个单元的到达率超过每分钟 10000 个任务。
繁忙的 Borgmaster 使用 10-14 个 CPU 内核和高达 50 GiB 的 RAM。我们使用了几种技术来达到这个规模。

Borgmaster 的早期版本有一个简单的同步循环，用于接受请求、计划任务并与 Borglet 通信。
为了处理更大的单元，我们将调度程序拆分为一个单独的进程，以便它可以与其他 Borgmaster 功能并行运行，这些功能被复制以实现容错。
调度程序副本对运行单元状态的缓存副本进行操作。
它会重复以下事件：从选定的主节点中检索状态更改(包括已分配的和未决的工作)；更新其本地副本；进行调度传递以分配任务；并将这些作业通知选定的主人。
Borgmaster 将接受并应用这些分配，除非它们不合适(例如，基于过时的状态)，这将导致它们在调度程序的下一次通过时被重新考虑。
这在本质上与 Omega `[69]` 中使用的乐观并发控制非常相似，实际上我们最近为 Borg 添加了针对不同工作负载类型使用不同调度程序的能力。

为了缩短响应时间，我们添加了单独的线程来与 Borglet 对话并响应只读 RPC。
为了获得更高的性能，我们将这些功能分片(分区)到 5 个 Borgmaster 副本(参见第 3.3 节)。
以上因素将 UI 的 99%ile (正态分布中的平均值的 99%) 响应时间保持在 1 以下，并将 Borglet 轮询间隔的 95%ile (正态分布中的平均值的 95%) 保持在 10 秒以下。

有几件事使 Borg 调度器更具可扩展性:

**分数缓存**：评估可行性并对机器进行评分是昂贵的，因此 Borg 会缓存分数，直到机器的属性或任务发生变化——例如，机器上的任务终止、属性改变或任务的要求发生变化。忽略资源数量的微小变化会减少缓存失效。

**等价类**：Borg 作业中的任务通常具有相同的要求和约束，因此与其为每台机器上的每个待处理任务确定可行性，并对所有可行机器进行评分，Borg 只对每个等价类的一个任务进行可行性和评分-一组具有相同要求的任务。

**宽松的随机化**：为一个运行单元中的所有机器计算可行性和分数是一种浪费，因此调度程序以随机顺序检查机器，直到找到“足够”的可行机器来评分，然后在该集合中选择最好的。
这减少了任务进入和离开系统时所需的评分和缓存失效量，并加快了将任务分配给机器的速度。
宽松随机化有点类似于 Sparrow `[65]` 的批量抽样，同时也处理优先级、抢占、异质性和包安装成本。

在我们的实验中(第 5 节)，从头开始调度一个单元的整个工作负载通常需要几百秒，但当上述技术被禁用时，超过 3 天后仍未完成。
但是，通常情况下，挂起队列上的在线调度会在不到半秒的时间内完成。

### 4 能力

![图 3：生产和非生产工作负载的任务驱逐率和原因。2013 年 8 月 1 日的数据](https://s2.loli.net/2021/12/29/WInUgwmZjkNBGJz.png)

故障是大规模系统中的常态 `[10, 11, 22]`。图 3 提供了 15 个样本单元中任务驱逐原因的细分。
运行在 Borg 上的应用程序应该使用诸如复制、在分布式文件系统中存储持久状态和(如果合适)偶尔保存检查点等技术来处理此类事件。
即便如此，我们仍会努力减轻这些事件的影响。例如，Borg 的处理方式如下：

- 如有必要，在新机器上自动重新安排被驱逐的任务
- 通过跨故障域(例如机器、机架和电源域)分散作业的任务来减少相关故障；
- 限制允许的任务中断率以及在维护活动(例如操作系统或机器升级)期间可以同时关闭的作业中的任务数量；
- 使用声明性的期望状态表示和幂等的变异操作，以便失败的客户端可以无害地重新提交任何被遗忘的请求；
- 限制提交速率，将无法传输到设备的任务寻找新的位置。因为它因为它无法区分大规模机器故障和网络分区；
- 避免重复 task::machine 配对导致任务或机器崩溃
- 通过反复重新运行日志保护程序任务(第 2.4 节)来恢复写入本地磁盘的关键中间数据，即使它所附加的 alloc 已终止或移动到另一台机器。用户可以设置系统重试时间(通常是几天)。

Borg 的一个关键设计特性是，即使 Borgmaster 或任务的 Borglet 出现故障，已经运行的任务也会继续运行。
但是保持 master 运行仍然很重要，因为当它宕机时，无法提交新作业或更新现有作业，并且无法重新安排来自故障机器的任务。

Borgmaster 使用了多种技术组合，使其能够在实践中实现 99.99% 的可用性：机器故障复制；准入控制以避免过载；并使用简单的低级工具部署实例以最大限度地减少外部依赖性。
每个运行单元都独立于其他运行单元，以最大限度地减少相关操作员错误和故障传播的机会。这些目标，而不是可扩展性限制，是反对更大运行单元的主要论据。

### 5 利用率

Borg 的主要目标之一是有效利用 Google 的机器群，这是一项重大的财务投资：将利用率提高几个百分点可以节省数百万美元。本节讨论和评估 Borg 用于这样做的一些策略和技术。

#### 5.1 评估方法

我们的作业有放置约束，需要处理罕见的工作负载峰值，我们的机器是异构的，我们在从服务作业回收的资源中运行批处理作业。
因此，为了评估我们的政策选择，我们需要一个比“平均利用率”更复杂的指标。
经过大量实验，我们选择了运行单元压缩的方式：给定一个工作负载，我们通过移除机器直到工作负载不再适合它来发现它可以安装到多小的运行单元中，从头开始反复重新打包工作负载，以确保我们不会被一个不走运的配置所困扰。
这提供了干净的终止条件，并促进了自动比较，而不存在合成额外产生工作负载和建模的陷阱 `[31]`。
评估技术的定量比较可以在 `[78]` 中找到：细节出奇地微妙。

不可能在实时生产运行单元上进行实验，但我们使用 Fauxmaster 获得高保真模拟结果，使用来自真实生产单元和工作负载的数据，包括它们的所有约束、实际限制、预留和使用数据(参见第 5.5 节)。
该数据来自于名美国太平洋夏令时间 2014-10-01 14:00 星期三拍摄的 Borg 检查点。
我们选择了 15 个 Borg 运行单元进行报告，首先消除了特殊用途的、测试的和小型(< 5000 台机器)运行单元，然后对剩余的群体进行采样，以在大小范围内实现大致均匀的分布。

为了保持压缩单元中的机器异质性，我们随机选择要移除的机器。
为了保持工作负载的异构性，我们保留了所有内容，除了与特定机器(例如 Borglet)相关的服务器和存储任务。
对于大于原始单元大小一半的作业，我们将硬约束更改为软约束，并允许多达 0.2% 的任务挂起，如果它们非常“挑剔”并且只能放置在少数机器上；大量实验表明，这产生了具有低方差的可重复结果。
如果我们需要一个比原始细胞更大的细胞，我们会在压缩前克隆原始细胞几次；如果我们需要更多细胞，我们就克隆原始细胞。

对于具有不同随机数种子的每个细胞，每个实验重复 11 次。
在图中，我们使用误差条来显示所需机器数量的最小值和最大值，并选择 90% 的值作为“结果”——平均值或中位数不会反映系统管理员会做什么如果他们想合理地确定工作量是否合适。
我们相信单元压缩提供了一种公平、一致的方式来比较调度策略，它直接转化为成本/收益结果：更好的策略需要更少的机器来运行相同的工作负载。

我们的实验侧重于从某个时间点调度(打包)工作负载，而不是重放长期工作负载跟踪。
这部分是为了避免处理开放和封闭队列模型的困难 `[71, 79]`，部分是因为传统的完成时间指标不适用于我们的长期运行服务的环境，部分是为了提供清晰的信号进行比较，部分是因为我们不相信结果会有显着不同，部分是因为实际问题：我们发现自己曾在某个时间点消耗 200 000 个 Borg CPU 内核用于我们的实验——即使在 Google 的规模下，这也是非常重要的投资。

在生产中，我们故意为工作负载增长、偶尔的“黑天鹅”事件、负载尖峰、机器故障、硬件升级和大规模局部故障(例如，电源总线故障)留出很大的空间。
图 4 显示了如果我们对它们应用运行单元压缩，我们的现实世界的运行单元会小多少。下图中的基线使用这些压缩尺寸。

![图 4：压缩的效果。压缩后获得的原始运行单元大小百分比的 CDF，跨越 15 个运行单元](https://s2.loli.net/2021/12/29/nPRjEWNYlkhiX16.png)

#### 5.2 运行单元共享

我们几乎所有的机器都同时运行生产和非生产任务：98% 的机器在共享的 Borg 单元中，83% 的机器在 Borg 管理的整个机器集中。(我们有一些特殊用途的专用运行单元。)

![图 5：将生产和非生产工作隔离到不同的运行单元中需要更多的机器。两个图表都显示了如果生产和非生产工作负载被发送到不同的单元需要多少额外的机器，表示为在单个运行单元中运行工作负载所需的最少机器数量的百分比。在这个和随后的 CDF 图中，每个运行单元显示的值来自我们的实验试验产生的不同运行单元大小的 90%；误差条显示了试验值的完整范围。](https://s2.loli.net/2021/12/29/WisuOEfKYg9McwS.png)

