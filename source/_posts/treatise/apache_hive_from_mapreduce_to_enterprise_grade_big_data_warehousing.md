---
title: Apache Hive: From MapReduce to Enterprise-grade Big Data Warehousing 中文翻译
date: 2022-01-10 22:26:13
tags:
- "论文"
- "Hive"
id: apache_hive_from_mapreduce_to_enterprise_grade_big_data_warehousing
no_word_count: true
no_toc: false
categories: 大数据
---

## Apache Hive: From MapReduce to Enterprise-grade Big Data Warehousing 中文翻译

作者：Jesús Camacho-Rodríguez, Ashutosh Chauhan, Alan Gates, Eugene Koifman, Owen O’Malley, Vineet Garg, Zoltan Haindrich, Sergey Shelukhin, Prasanth Jayachandran, Siddharth Seth, Deepak Jaiswal, Slim Bouguerra, Nishant Bangarwa, Sankar Hariappan, Anishek Agarwal, Jason Dere, Daniel Dai, Thejas Nair, Nita Dembla, Gopal Vijayaraghavan, Günther Hagleitner

### 摘要

Apache Hive 是一个用于分析大数据工作负载的开源关系型数据库。本文中，我们描述了从批处理工具到成熟的企业数据仓库系统的关键创新。
我们提出了一种混合架构，它将传统的 MPP 技术与最新的大数据和云概念相结合，以实现当今分析应用程序所需的规模和性能。
我们通过沿四个主轴详细说明增强功能来探索系统：事务、优化器、运行时(runtime)和联邦集群(federation)。然后，我们提供实验结果来展示系统在典型工作负载下的性能，并以查看社区路线图作为总结。

### 1. 简介

10 多年前首次引入 Hive 时 `[55]`，作者的动机是在 Hadoop MapReduce 之上公开一个类似 SQL 的接口，以将用户从处理并行批处理作业的低级实现细节中抽象出来。
Hive 主要专注于 ExtractTransform-Load (ETL) 或批处理报告工作负载，这些工作负载包括 (i) 读取大量数据，(ii) 对该数据执行转换(例如，数据整理、整合、聚合)以及最后 (iii) 加载(输出)到其他系统用于进一步分析。

随着 Hadoop 成为使用 HDFS 进行廉价数据存储的无处不在的平台，开发人员专注于增加可以在平台内高效执行的工作负载范围。
在 Hadoop 引入 YARN `[56]` 资源管理框架之后不久 Spark `[14,59]` 或 Flink `[5,26]` 等 MapReduce 之外的数据处理引擎也可以在支持 YARN 之后直接在 Hadoop 上运行。

用户也越来越关注将他们的数据仓库工作负载从其他系统迁移到 Hadoop。这些工作负载包括交互式和临时报告、仪表板和其他商业智能用例。
有一个共同要求使这些工作负载对 Hadoop 构成挑战：它们需要低延迟 SQL 引擎。实现这一目标的多项努力是并行启动的，并且出现了与 YARN 兼容的新 SQL MPP 系统，例如 Impala `[8, 42]` 和 Presto `[48]`。

Hive 社区没有实施新系统，而是得出结论，该项目的当前实施为支持这些工作负载提供了良好的基础。
Hive 是为 Hadoop 中的大规模可靠计算而设计的，它已经提供了 SQL 兼容性(只有一部分)和与其他数据管理系统的连接。
然而，Hive 需要发展并进行重大改造，采用多年来广泛研究的通用数据仓库技术以满足这些新用例的要求。

以前向研究界展示的关于 Hive 的工作主要集中在 (i) 它在 HDFS 和 MapReduce `[55]` 之上的初始架构和实现，以及 (ii) 改进以解决原始系统中的多个性能缺点，包括引入优化的列文件格式，物理优化以减少查询计划中 MapReduce 阶段的数量，以及矢量化执行模型以提高运行时效率 `[39]`。

相反，本文描述了在上一篇文章发表之后在 Hive 中引入的重要创新。特别是，它侧重于沿四个不同主轴改进系统的相关工作：

**SQL 和 ACID 支持(第 3 节)** SQL 合规性是数据仓库的一项关键要求。因此，Hive 中的 SQL 支持得到了扩展，包括相关的子查询、完整性约束和扩展的 OLAP 操作等。
反过来，仓库用户需要支持来按需插入、更新、删除和合并他们的个人记录。Hive 使用构建在 Hive Metastore 之上的事务管理器通过快照隔离策略来提供 ACID 保证。

**优化技术(第 4 节)** 查询优化与使用声明性查询语言(如 SQL)的数据管理系统尤其相关。Hive 没有从头开始实现自己的优化器，而是选择与 Calcite `[3, 19]` 集成，并将其优化功能带入系统。
此外，Hive 还包括数据仓库环境中常用的其他优化技术，例如查询重新优化、查询结果缓存和物化视图重写。

**运行时的延迟(第 5 节)** 为了涵盖更广泛的用例，包括交互式查询，改善延迟至关重要。Hive 支持优化的列数据存储方式和运算符的矢量化在之前的文章中已经描述过了 `[39]`。
除了这些改进之外，Hive 已经从 MapReduce 转移到 Tez `[15, 50]`，这是一个与 YARN 兼容的运行时，它比 MapReduce 提供了更多的灵活性来实现任意数据处理应用程序。
此外，Hive 包括 LLAP，这是一个额外的持久性长期运行的执行程序层，可提供数据缓存、设施运行时优化，并避免启动时的 YARN 容器分配开销。

**联邦集群性能(第 6 节)** Hive 最重要的特性之一是能够在过去几年出现的许多专业数据管理系统之上提供统一的 SQL 层。
由于其 Calcite 集成和存储处理程序的改进，Hive 可以无缝地推送计算并从这些系统读取数据。反过来，该实现很容易扩展以支持将来的其他系统。

本文的其余部分安排如下。第 2 节提供了 Hive 架构和主要组件的背景。第 3-6 节描述了我们对沿上述主轴改进系统的主要贡献。第 7 节介绍了 Hive 的实验评估。
第 8 节讨论了新功能的影响，而第 9 节简要介绍了项目的路线图。最后，第 10 节总结了我们的结论。

### 2 系统架构

在本节中，我们将简要介绍 Hive 的架构。图 1 描述了系统中的主要组件。

![图 1：Apache Hive 架构图](https://s2.loli.net/2022/01/10/ud1qtVUvL2G7D5a.png)

**数据存储** Hive 中的数据可以使用任何支持的文件格式存储在与 Hadoop 兼容的任何文件系统中。
截至今天，最常见的文件格式是 ORC `[10]` 和 Parquet `[11]`。反过来，兼容的文件系统包括最常用的分布式文件系统实现 HDFS，以及所有主要的商业云对象存储，如 AWS S3 和 Azure Blob 存储。
此外，Hive 还可以读取和写入数据到其他独立处理系统，例如 Druid `[4, 58]` 或 HBase `[6]`，我们将在第 6 节中详细讨论。

**数据目录** Hive 使用 Hive Metastore(简称 HMS)存储有关其数据源的所有信息。简而言之，HMS 是 Hive 可查询的所有数据的目录。
它使用 RDBMS 来持久化信息，并依赖 Java 对象关系映射实现 DataNucleus `[30]` 来简化后端对多个 RDBMS 的支持。对于需要低延迟的调用，HMS 可以绕过 DataNucleus 直接查询 RDBMS。
HMS API 支持多种编程语言，该服务使用 Thrift `[16]` 实现，这是一个提供接口定义语言、代码生成引擎和二进制通信协议实现的软件框架。

**可更换的数据处理引擎** Hive 已成为 Hadoop 之上最受欢迎的 SQL 引擎之一，它已逐渐远离 MapReduce，以支持与 YARN `[50]` 兼容的更灵活的处理运行时。
虽然仍然支持 MapReduce，但目前 Hive 最流行的运行时是 Tez `[15, 50]`。
Tez 通过将数据处理建模为 DAG 提供比 MapReduce 更大的灵活性，其中顶点表示应用程序逻辑，边表示数据传输，类似于 Dryad `[40]` 或 Hyracks `[22]` 等其他系统。
此外，Tez 与第 5 节中介绍的持久执行和缓存层 LLAP 兼容。

**查询服务器** HiveServer2(或简称 HS2)允许用户在 Hive 中执行 SQL 查询。HS2 支持本地和远程 JDBC 和 ODBC 连接；Hive 发行版中包括一个名为 Beeline 的 JDBC 简易客户端。

![图 2：HiveServer2 中的查询准备阶段](https://s2.loli.net/2022/01/10/tYSki4HVAsbOWTe.png)

图 2 描述了 SQL 查询在 HS2 中经过的各个阶段，以成为可执行计划。一旦用户向 HS2 提交查询，该查询由驱动程序处理，驱动程序解析语句并从其 AST 生成 Calcite `[3, 19]` 逻辑计划。
然后优化 Calcite 计划。请注意，HS2 访问有关 HMS 中数据源的信息以进行验证和优化。随后，计划被转换为物理计划，可能会引入额外的操作符用于数据分区、排序等。
HS2 对物理计划 DAG 执行额外的优化，如果支持计划中的所有运算符和表达式，则可以从中生成矢量化计划 `[39]`。
物理计划被传递给任务编译器，它将操作符树分解为可执行任务的 DAG。Hive 为每个支持的处理运行时实现了一个单独的任务编译器，即 Tez、Spark 和 MapReduce。
生成任务后，驱动程序将它们提交给 YARN 中的运行时应用程序管理器，由其处理执行。对于每个任务，首先初始化该任务中的物理操作符，然后它们以流水线方式处理输入数据。
执行完成后，驱动程序获取查询结果并将其返回给用户。

### 3 SQL 和 ACID 支持

标准 SQL 和 ACID 事务是企业数据仓库中的关键要求。在本节中，我们将介绍 Hive 更广泛的 SQL 支持。
此外，我们描述了对 Hive 所做的改进，以便在 Hadoop 之上提供 ACID 保证。

#### 3.1 SQL 支持

为了替代传统数据仓库，需要扩展 Hive 以支持标准 SQL 的更多功能。Hive 使用嵌套数据模型，支持所有主要的原子 SQL 数据类型以及非原子类型，例如 STRUCT、ARRAY 和 MAP。
此外，每个新的 Hive 版本都增加了对作为 SQL 规范一部分的重要构造的支持。
例如，扩展了对相关子查询的支持，即引用外部查询列的子查询、高级 OLAP 操作(如分组或窗口函数)、集合操作和完整性约束等。
另一方面，Hive 保留了其原始查询语言的多个功能，这些功能对其用户群很有价值。最流行的功能之一是能够在创建表时使用 PARTITIONED BY 列子句指定物理存储布局。
简而言之，该子句允许用户对表进行水平分区。然后 Hive 将每组分区值的数据存储在文件系统的不同目录中。为了说明这个想法，请考虑下表定义和图 3 中描述的相应物理布局：

![图 3：分区表的物理布局](https://s2.loli.net/2022/01/10/rHG5hRMJI6zk8El.png)

```text
CREATE TABLE store_sales (
  sold_date_sk INT, item_sk INT, customer_sk INT, store_sk INT,
  quantity INT, list_price DECIMAL(7,2), sales_price DECIMAL(7,2)
) PARTITIONED BY (sold_date_sk INT);
```

使用 PARTITIONED BY 子句的优点是 Hive 将能够轻松跳过扫描完整分区以查找过滤这些值的查询。

#### 3.2 ACID 支持

最初，Hive 仅支持从表中插入和删除完整分区 `[55]`。尽管对于 ETL 工作负载来说缺乏行级操作是可以接受的，但随着 Hive 演变为支持许多传统的数据仓库工作负载，对完全 DML 支持和 ACID 事务的需求越来越大。
因此，Hive 现在支持执行 INSERT、UPDATE、DELETE 和 MERGE 语句。
它通过 Snapshot Isolation `[24]` 为读取和定义明确的语义提供 ACID 保证，以防使用构建在 HMS 之上的事务管理器发生故障。
目前事务只能跨越一个语句； 我们计划在不久的将来支持多语句事务。但是，可以使用 Hive 多插入语句 `[55]` 在单个事务中写入多个表。

在 Hive 中支持行级操作需要克服的主要挑战是 (i) 系统中缺少事务管理器，以及 (ii) 底层文件系统中缺少文件更新支持。在下文中，我们提供了有关在 Hive 中实施 ACID 以及如何解决这些问题的更多详细信息。

**事务和锁管理** Hive 在 HMS 中存储事务和锁定信息状态。它为系统中运行的每个事务使用全局事务标识符或 TxnId，即 Metastore 生成的单调递增值。
反过来，每个 TxnId 映射到一个或多个写入标识符或 WriteId。WriteId 也是由 Metastore 生成的单调递增值，但在表范围内。
WriteId 与事务写入的每条记录一起存储；同一个事务写入同一个表的所有记录共享同一个 WriteId。
反过来，共享相同 WriteId 的文件使用 FileId 唯一标识，而文件中的每条记录由 RowId 字段唯一标识。
请注意，WriteId、FileId 和 RowId 的组合唯一标识了表中的每条记录。Hive 中的删除操作被建模为标记记录的插入，该记录指向被删除记录的唯一标识符。

为了实现快照隔离，HS2 在执行查询时获取需要读取的数据的逻辑快照。快照由一个事务列表表示，该列表包含当时分配的最高 TxnId，即高水位线，以及它下面的一组打开和中止的事务。
对于查询需要读取的每张表，HS2 首先通过联系 HMS 从事务列表中生成 WriteId 列表； WriteId 列表类似于事务列表，但在单个表的范围内。
计划中的每个扫描操作在编译期间都绑定到一个 WriteId 列表。该扫描中的读取器将跳过 WriteId (i) 高于高水位线或 (ii) 是打开和中止事务集的一部分的行。
保留全局和每个表标识符的原因是每个表的读取器保持较小的状态，当系统中有大量打开的事务时，这对性能至关重要。

对于分区表，锁定粒度是分区，而对于未分区表，需要锁定全表。HS2 只需要为破坏读写器的操作获取排他锁，例如 DROP PARTITION 或 DROP TABLE 语句。
所有其他常见操作只是获取共享锁。更新和删除通过跟踪其写入集并在提交时解决冲突来使用乐观冲突解决，让第一次提交获胜。

**数据和文件布局** Hive 将每个表和分区的数据存储在不同的目录中(回忆图 3)。
与 `[45]` 类似，我们在每个表或分区中使用不同的存储或目录来支持并发读写操作：base 和 delta，它们又可能包含一个或多个文件。
基本存储中的文件包含直到某个 WriteId 的所有有效记录。例如，文件夹 base_100 包含直到 WriteId 100 的所有记录。另一方面，增量目录包含具有 WriteId 范围内的记录的文件。
Hive 为插入和删除的记录保留单独的增量目录；更新操作分为删除和插入操作。插入或删除事务创建一个增量目录，其中记录绑定到单个 WriteId，例如 delta_101_101 或 delete_delta_102_102。
包含多个 WriteId 的增量目录是作为压缩过程的一部分创建的(如下所述)。

如前所述，查询中的表扫描具有与之关联的 WriteId 列表。扫描中的读取器丢弃完整目录以及基于当前快照无效的单个记录。
当增量文件中存在删除时，基本和插入增量文件中的记录需要与适用于其 WriteId 范围的删除增量反连接。
由于删除记录的增量文件通常很小，因此它们可以大部分时间保存在内存中，从而加速合并阶段。

**数据压缩(compaction)** 压缩是 Hive 中的过程，它将 delta 目录中的文件与 delta 目录中的其他文件合并(称为次要压缩)，或者将 delta 目录中的文件与基本目录中的文件合并(称为主要压缩)。
定期运行压缩的关键原因是(i) 减少表中目录和文件的数量，否则会影响文件系统性能，(ii)减少读取端在查询执行时合并文件的工作量，以及 (iii) 缩短与每个快照关联的打开和中止 TxnId 和 WriteId 的集合，即主要压缩删除历史记录，增加已知表中所有记录有效的 TxnId。

当超过某些阈值时，HS2 会自动触发压缩，例如，表中的 delta 文件数或 delta 文件中的记录与基本文件的比率。最后，请注意，压缩不需要对表进行任何锁定。
实际上，清理阶段与合并阶段是分开的，因此任何正在进行的查询都可以在文件从系统中删除之前完成其执行。

### 4 查询优化

虽然在 Hive 的初始版本中对优化的支持是有限的，但显然其执行内部的开发不足以保证高效的性能。因此，目前该项目包括关系数据库系统中通常使用的许多复杂技术。
本节介绍最重要的优化功能，这些功能可帮助系统生成更好的计划并改进查询执行，包括它与 Apache Calcite 的基本集成。

#### 4.1 基于规则和成本的优化器

最初，Apache Hive 在解析输入 SQL 语句时执行了多次重写以提高性能。此外，它包含一个基于规则的优化器，该优化器将简单的转换应用于查询生成的物理计划。
例如，许多优化的目标是尽量减少数据混洗的成本，这是 MapReduce 引擎中的一项关键操作。还有其他优化来下推过滤器谓词、投影未使用的列和修剪分区。
虽然这对某些查询很有效，但使用物理计划表示使得实现复杂的重写(例如连接重新排序、谓词简化和传播，或基于物化视图的重写)变得过于复杂。

因此，引入了由 Apache Calcite `[3, 19]` 提供支持的新计划表示和优化器。
Calcite 是一个模块化和可扩展的查询优化器，具有内置元素，可以以不同的方式组合以构建您自己的优化逻辑。其中包括不同的重写规则(rewriting rules)、计划者(planner)和成本模型(cost model)。

Calcite 提供了两种不同的规划器引擎：(i) 基于成本的规划器，它触发重写规则以降低整体表达式成本，以及 (ii) 穷举计划器，它穷举地触发规则，直到它生成不再被任何规则修改。转换规则对这两个规划引擎都不起作用。

Hive 实现类似于其他查询优化器 `[52]` 的多阶段优化，其中每个优化阶段使用一个计划器和一组重写规则。这允许 Hive 通过指导搜索不同的查询计划来减少整体优化时间。
Apache Hive 中启用的一些 Calcite 规则是连接重新排序、多个运算符重新排序和消除、常量折叠和传播以及基于约束的转换。

**统计数据** 表统计信息存储在 HMS 中，并在计划时提供给 Calcite。这些包括表基数、不同值的数量、每列的最小值和最大值。
存储统计信息以便它们可以以附加方式组合，即未来插入以及跨多个分区的数据可以添加到现有统计信息中。范围和基数可以简单地合并。
对于不同值的数量，HMS 使用基于 HyperLogLog++ `[38]` 的位数组表示，可以在不损失近似精度的情况下进行组合。

#### 4.2 查询重新优化

当执行期间抛出某些错误时，Hive 支持查询重新优化。特别是，它实现了两个独立的重新优化策略。

第一个策略，覆盖，更改所有查询重新执行的某些配置参数。例如，用户可以选择强制查询重新执行中的所有连接使用某种算法，例如，带有排序合并的哈希分区。当已知某些配置值可以使查询执行更加健壮时，这可能很有用。

第二种策略，重新优化，依赖于运行时捕获的统计信息。在计划查询时，优化器会根据从 HMS 检索到的统计信息来估计计划中中间结果的大小。如果这些估计不准确，优化器可能会犯计划错误，例如错误的连接算法选择或内存分配。
这反过来可能导致性能不佳和执行错误。Hive 为计划中的每个运算符捕获运行时统计信息。如果在查询执行期间检测到任何上述问题，则使用运行时统计信息重新优化查询并再次执行。

#### 4.3 查询结果缓存

仓库的事务一致性允许 Hive 通过使用参与表的内部事务状态来重用先前执行的查询的结果。在处理生成重复相同查询的 BI 工具时，查询缓存提供了可扩展性优势。

每个 HS2 实例都保留自己的查询缓存组件，该组件又保留从查询 AST 表示到条目的映射，该条目包含结果位置和回答查询的数据快照的信息。该组件还负责清除过时的条目并清理这些条目使用的资源。

在查询编译期间，HS2 在初步步骤中使用输入查询 AST 检查其缓存。查询中不合格的表引用在 AST 用于证明缓存之前被解析，因为根据查询执行时的当前数据库，具有相同文本的两个查询可能访问来自不同数据库的表。
如果缓存命中并且查询使用的表不包含新的或修改的数据，则查询计划将包含从缓存位置获取结果的单个任务。
如果该条目不存在，则查询照常运行，如果查询满足某些条件，则为查询生成的结果保存到缓存中；例如，查询不能包含非确定性函数(rand)、运行时常量函数(current_date、current_timestamp)等。

查询缓存有一个挂起的条目模式，当数据更新并且其中几个同时观察到缓存未命中时，它可以防止雷鸣般的相同查询群。
缓存将被第一个进入的查询重新填充。此外，该查询可能会获得更多的集群容量，因为它会将结果提供给所有其他遭受缓存未命中的并发相同查询。

